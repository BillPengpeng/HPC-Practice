{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cuda基本函数\n",
    "\n",
    "### 函数类型限定词\n",
    "\\_\\_global\\_\\_：在device上执行，从host中调用（一些特定的GPU也可以从device上调用），返回类型必须是void，不支持可变参数参数，不能成为类成员函数。注意用__global__定义的kernel是异步的，这意味着host不会等待kernel执行完就执行下一步。  \n",
    "\\_\\_device\\_\\_：在device上执行，单仅可以从device中调用，不可以和__global__同时用。  \n",
    "\\_\\_host\\_\\_：在host上执行，仅可以从host上调用，一般省略不写，不可以和__global__同时用，但可和__device__，此时函数会在device和host都编译。 \n",
    "\n",
    "### 内存相关\n",
    "设备分配内存：cudaMalloc  \n",
    "CPU分配内存：cudaMallocHost  \n",
    "分配统一内存，CPU/GPU均可访问 ：cudaMallocManaged  \n",
    "CPU/GPU内存拷贝（复制方向包括：cudaMemcpyHostToDevice/cudaMemcpyDeviceToHost）：cudaMemcpy  \n",
    "数据异步预取  cudaMemPrefetchAsync\n",
    "\n",
    "```\n",
    "void foo(cudaStream_t s) {\n",
    "  char *data;\n",
    "  cudaMallocManaged(&data, N);\n",
    "  init_data(data, N);                                   // execute on CPU\n",
    "  cudaMemPrefetchAsync(data, N, myGpuId, s);            // prefetch to GPU\n",
    "  mykernel<<<..., s>>>(data, N, 1, compare);            // execute on GPU\n",
    "  cudaMemPrefetchAsync(data, N, cudaCpuDeviceId, s);    // prefetch to CPU\n",
    "  cudaStreamSynchronize(s);\n",
    "  use_data(data, N);\n",
    "  cudaFree(data);\n",
    "}\n",
    "```\n",
    "\n",
    "### CUDA stream\n",
    "```\n",
    "cudaStream_t stream;       // CUDA streams are of type `cudaStream_t`.\n",
    "cudaStreamCreate(&stream); // Note that a pointer must be passed to `cudaCreateStream`.\n",
    "someKernel<<<number_of_blocks, threads_per_block, 0, stream>>>(); // `stream` is passed as 4th EC argument.\n",
    "cudaStreamDestroy(stream); // Note that a value, not a pointer, is passed to `cudaDestroyStream`.\n",
    "```\n",
    "\n",
    "### 工具相关\n",
    "安装NsightSystems: https://developer.nvidia.com/nsight-systems/get-started#platforms\n",
    "jupter配置nsys：https://pypi.org/project/jupyterlab-nvidia-nsight/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device ID: 0\tNumber of SMs: 20\n",
      "Error: invalid device ordinal\n",
      "Success! All values calculated correctly.\n",
      "WARNING: 01-vector-add and any of its children processes will be profiled.\n",
      "\n",
      "Collecting data...\n",
      "Device ID: 0\tNumber of SMs: 20\n",
      "Error: invalid device ordinal\n",
      "Success! All values calculated correctly.\n",
      "Generating '/tmp/nsys-report-9184.qdstrm'\n",
      "[1/7] [========================100%] report1.nsys-rep\n",
      "[2/7] [========================100%] report1.sqlite\n",
      "[3/7] Executing 'nvtx_sum' stats report\n",
      "SKIPPED: /home/chenpeng/github/HPC-Practice/HPC-Practice/course/CUDA/notes/01-cuda基础/report1.sqlite does not contain NV Tools Extension (NVTX) data.\n",
      "[4/7] Executing 'cuda_api_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)    Med (ns)   Min (ns)  Max (ns)   StdDev (ns)          Name         \n",
      " --------  ---------------  ---------  ----------  ----------  --------  ---------  -----------  ---------------------\n",
      "     72.1        292474470          3  97491490.0  51344784.0  48064180  193065506   82785777.7  cudaMallocManaged    \n",
      "     16.0         65053983          1  65053983.0  65053983.0  65053983   65053983          0.0  cudaDeviceSynchronize\n",
      "     11.1         44890306          3  14963435.3  14505000.0  14460764   15924542     832636.6  cudaFree             \n",
      "      0.6          2272023          3    757341.0      2863.0       657    2268503    1308705.1  cudaMemPrefetchAsync \n",
      "      0.2           891681          1    891681.0    891681.0    891681     891681          0.0  cudaLaunchKernel     \n",
      "\n",
      "[5/7] Executing 'cuda_gpu_kern_sum' stats report\n",
      "SKIPPED: /home/chenpeng/github/HPC-Practice/HPC-Practice/course/CUDA/notes/01-cuda基础/report1.sqlite does not contain CUDA kernel data.\n",
      "[6/7] Executing 'cuda_gpu_mem_time_sum' stats report\n",
      "SKIPPED: /home/chenpeng/github/HPC-Practice/HPC-Practice/course/CUDA/notes/01-cuda基础/report1.sqlite does not contain GPU memory data.\n",
      "[7/7] Executing 'cuda_gpu_mem_size_sum' stats report\n",
      "SKIPPED: /home/chenpeng/github/HPC-Practice/HPC-Practice/course/CUDA/notes/01-cuda基础/report1.sqlite does not contain GPU memory data.\n",
      "Generated:\n",
      "\t/home/chenpeng/github/HPC-Practice/HPC-Practice/course/CUDA/notes/01-cuda基础/report1.nsys-rep\n",
      "\t/home/chenpeng/github/HPC-Practice/HPC-Practice/course/CUDA/notes/01-cuda基础/report1.sqlite\n"
     ]
    }
   ],
   "source": [
    "!nvcc -o 01-vector-add 01-vector-add.cu -run\n",
    "!nsys nvprof ./01-vector-add\n",
    "!rm report*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
