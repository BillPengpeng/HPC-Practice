本文主要整理CUDA MODE lecture_002 (pmpp book ch. 1-3)的要点。

## 3.0 Ch 3: Multidimensional grids and data

**内容概括：**

本节介绍了 CUDA 如何利用**多维网格**来组织和映射线程，以高效处理**多维数据**（如图像、矩阵、体数据等）。核心是 CUDA 线程的**两级层次结构**：网格（Grid）由线程块（Blocks）组成，线程块又包含线程（Threads）。所有网格内的线程执行同一个内核（SPMD）。文本强调了线程块内线程可以通过**共享内存**协作，并重申了每个线程块的最大线程数限制（1024）。关键是通过内置的**三维坐标变量**（`blockIdx`, `threadIdx`）和**维度变量**（`gridDim`, `blockDim`），线程可以唯一确定自己在网格中的位置，从而知道自己应
该处理数据的哪一部分。理解网格和线程块的**形状**（维度配置）对于高效处理多维数据至关重要。

![Grid](https://i-blog.csdnimg.cn/direct/7927310d784c47d9ba423d685eba5327.png)

**要点总结：**

1.  **CUDA 线程组织核心：两级层次**
    *   **网格 (Grid):** 最高层级，包含执行一个内核的所有线程。
    *   **线程块 (Blocks):** 网格由多个线程块组成。线程块是线程分组和协作的基本单位。
    *   **线程 (Threads):** 线程块由多个线程组成。线程是执行计算的最小单位。

2.  **核心思想：线程映射到多维数据**
    *   CUDA 网格和线程块可以是**一维、二维或三维**的。
    *   这种多维结构是为了**自然地映射到多维数据结构**（如 2D 图像、3D 体数据、矩阵等）。
    *   每个线程通过其坐标知道自己负责处理数据中的哪个元素或区域。

3.  **执行模型：SPMD**
    *   网格中的所有线程**执行相同的内核代码** (Single Program Multiple Data)。

4.  **线程块内协作：共享内存**
    *   位于**同一个线程块 (Block)** 内的线程可以**高效地访问和协作**通过**共享内存 (Shared Memory)**。
    *   *(共享内存是位于 GPU SM 上的高速、低延迟内存，由同一线程块内的线程共享)*。

5.  **硬件限制：线程块大小**
    *   每个**线程块 (Block)** 最多可以包含 **1024 个线程** (这是当前主流 NVIDIA GPU 的常见限制)。

6.  **线程坐标与标识：**
    *   **`blockIdx` (`dim3`):** 内置变量，表示当前线程所在的**线程块 (Block)** 在**网格 (Grid)** 中的**三维索引** (`.x`, `.y`, `.z` 成员)。
    *   **`threadIdx` (`dim3`):** 内置变量，表示当前线程在其所属的**线程块 (Block)** 内部的**三维索引** (`.x`, `.y`, `.z` 成员)。
    *   通过 `blockIdx` 和 `threadIdx`，可以**唯一确定网格中的任何一个线程**及其在数据空间中的逻辑位置。

7.  **网格与线程块形状（维度）：**
    *   **`gridDim` (`dim3`):** 内置变量，表示**网格 (Grid)** 的**维度**，即网格在 x, y, z 方向上各包含多少个**线程块 (Blocks)**。
    *   **`blockDim` (`dim3`):** 内置变量，表示**线程块 (Block)** 的**维度**，即每个线程块在 x, y, z 方向上各包含多少个**线程 (Threads)**。
    *   内核启动时通过 `<<<...>>>` 语法指定 `gridDim` 和 `blockDim` 的值，决定了网格和线程块的**形状和大小**。

## 3.1 Grid continued

```c
dim3 grid(32, 1, 1);
dim3 block(128, 1, 1);
kernelFunction<<<grid, block>>>(..);
// Number of threads: 128 * 32=4096
```

**内容概括：**

本节进一步阐述了 CUDA 网格的灵活性和配置策略。它强调网格配置（`gridDim` 和 `blockDim`）可以**针对每次内核启动动态调整**，通常根据输入数据的形状（如尺寸、维度）来决定。文本指出典型的网格规模庞大，包含**数千至数百万个线程**。核心策略是**为每个输出元素分配一个线程**（例如，图像处理中一个线程处理一个像素，张量计算中一个线程处理一个张量元素）。它说明了线程的执行顺序是**不确定的**（由硬件调度器决定）。文本解释了 `dim3` 结构体的灵活性：开发者可以根据需要**使用少于 3 个维度**（将未使用的维度设置为 1）。最后，通过一个具体示例展示了如何配置一个包含 4096 个线程的网格（32 个线程块 x 每个块 128 个线程）。

**要点总结：**

1.  **网格配置的灵活性：**
    *   网格的形状和大小（`gridDim` 和 `blockDim`）**可以并且应该针对每次内核启动进行配置**。
    *   配置通常**依赖于输入数据的形状和大小**（例如，图像宽度/高度、矩阵维度、向量长度）。

2.  **网格规模：**
    *   典型的 CUDA 网格包含**非常多的线程**，范围从**数千到数百万**个。这充分利用了 GPU 的大规模并行处理能力。

3.  **核心映射策略：**
    *   **一个线程处理一个输出元素**是常见且有效的策略。
    *   例如：
        *   图像处理：**一个线程处理一个像素**。
        *   张量/数组计算：**一个线程处理一个张量/数组元素**。

4.  **线程执行顺序：**
    *   网格中的线程**可以按任何顺序执行**。
    *   执行顺序由 GPU 硬件调度器决定，**程序员无法也不应依赖特定的执行顺序**。

5.  **维度的灵活性：**
    *   CUDA 支持 **1D、2D 或 3D** 的网格和线程块。
    *   开发者**不必使用全部三个维度**。对于低维数据：
        *   可以将未使用的维度设置为 **1**。
        *   例如：
            *   处理一维序列（向量）：使用 **1D 网格和 1D 线程块**（`.y` 和 `.z` 维度设为 1）。
            *   处理二维图像：使用 **2D 网格和/或 2D 线程块**（`.z` 维度设为 1）。

6.  **配置示例：**
    *   **`dim3 grid(32, 1, 1);`**
        *   定义一个网格 (`gridDim`)，包含 **32 个线程块**。
        *   只在 `.x` 维度有大小 (32)，`.y` 和 `.z` 维度大小为 1（即一维网格）。
    *   **`dim3 block(128, 1, 1);`**
        *   定义一个线程块 (`blockDim`)，包含 **128 个线程**。
        *   只在 `.x` 维度有大小 (128)，`.y` 和 `.z` 维度大小为 1（即一维线程块）。
    *   **内核启动：`kernelFunction<<<grid, block>>>(..);`**
        *   使用配置好的 `grid` 和 `block` 启动内核。
    *   **总线程数计算：**
        *   总线程数 = `gridDim.x * gridDim.y * gridDim.z * blockDim.x * blockDim.y * blockDim.z`
        *   本例中：32 (blocks) * 1 * 1 * 128 (threads/block) * 1 * 1 = **4096 个线程**。

## 3.2 Built-in Variables

**内容概括：**

本节简洁明了地列出了在 CUDA 内核函数 (`__global__` 或 `__device__`) 内部可以直接使用的四个关键内置变量及其含义。这些变量为每个线程提供了其在网格和线程块层次结构中的位置信息，以及网格和线程块的维度信息。文本特别指出 `blockDim` 和 `gridDim` 的值在内核执行期间对于网格中的所有线程都是**相同且恒定**的。

**要点总结：**

1.  **核心目的：**
    *   这些内置变量为执行内核代码的**每个线程**提供其**执行上下文信息**，使其能够确定自己负责处理哪部分数据。

2.  **四个关键内置变量：**
    *   **`blockIdx` (类型 `dim3`):**
        *   表示当前线程所在的**线程块 (Thread block)** 在**网格 (Grid)** 中的**三维坐标 (索引)**。
        *   通过 `.x`, `.y`, `.z` 成员访问坐标分量。
    *   **`threadIdx` (类型 `dim3`):**
        *   表示当前线程在其所属的**线程块 (Thread block)** 内部的**三维坐标 (索引)**。
        *   通过 `.x`, `.y`, `.z` 成员访问坐标分量。
    *   **`blockDim` (类型 `dim3`):**
        *   表示**线程块 (Thread block)** 的**维度 (大小)**。
        *   它定义了启动内核时配置的每个线程块在 x, y, z 方向上包含的**线程数量**。
        *   通过 `.x`, `.y`, `.z` 成员访问各维度的大小。
    *   **`gridDim` (类型 `dim3`):**
        *   表示**网格 (Grid)** 的**维度 (大小)**。
        *   它定义了启动内核时配置的网格在 x, y, z 方向上包含的**线程块数量**。
        *   通过 `.x`, `.y`, `.z` 成员访问各维度的大小。

3.  **重要特性：**
    *   **`blockDim` 和 `gridDim` 的值在内核执行期间：**
        *   对于**网格中的所有线程**都是**相同的 (have the same values)**。
        *   在**内核执行期间是恒定的 (constant)**，不会改变。
    *   **`blockIdx` 和 `threadIdx` 的值：**
        *   对于网格中的**每个线程是唯一的**（组合起来唯一标识一个线程）。
        *   不同线程的 `blockIdx` 和 `threadIdx` 值不同。

**核心用途：**
这些变量通常结合使用来计算线程对应的全局数据索引或标识其处理的数据区域。例如：
*   1D 数据：`int idx = blockIdx.x * blockDim.x + threadIdx.x;`
*   2D 数据：`int row = blockIdx.y * blockDim.y + threadIdx.y; int col = blockIdx.x * blockDim.x + threadIdx.x;`

## 3.3 Image blur example (3.3, p. 60)

```c
__global__
void mean_filter_kernel(unsigned char* output, unsigned char* input, int width, int height, int radius) {
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int channel = threadIdx.z;

    int baseOffset = channel * height * width;
    if (col < width && row < height) {

        int pixVal = 0;
        int pixels = 0;

        for (int blurRow=-radius; blurRow <= radius; blurRow += 1) {
            for (int blurCol=-radius; blurCol <= radius; blurCol += 1) {
                int curRow = row + blurRow;
                int curCol = col + blurCol;
                if (curRow >= 0 && curRow < height && curCol >=0 && curCol < width) {
                    pixVal += input[baseOffset + curRow * width + curCol];
                    pixels += 1;
                }
            }
        }

        output[baseOffset + row * width + col] = (unsigned char)(pixVal / pixels);
    }
}
```

**内容概括：**

本节描述了一个使用 CUDA 实现的图像模糊（均值滤波）内核 (`blurKernel`) 的核心思想和关键实现点。核心策略是**每个线程负责计算并写入一个输出像素**的值。为了实现模糊效果，每个线程需要**读取输入图像中多个相邻像素**的值（通常是其周围的一个矩形区域，如 3x3 或 5x5 的邻域）。文本提到书中示例处理的是单通道（灰度）图像，但可以轻松扩展到多通道（如 RGB）。它强调了代码中展示了**行优先（Row-major）** 的内存访问模式（通过输入和输出图像指针 `in`, `out`）。内核内部使用一个**累加器（如 `pixVal`）** 来跟踪所读取像素值的总和，并最终计算平均值写入输出。特别重要的是，代码**处理了图像边界条件**（例如第 5 行和第 25 行或其等价逻辑），确保边界线程不会访问图像外的无效内存区域。

**要点总结：**

1.  **核心策略：一线程一输出元素**
    *   **每个线程负责计算并写入输出图像中的一个像素**的模糊值。
    *   这是 CUDA 数据并行处理的典型模式。

2.  **输入依赖：邻域操作**
    *   为了计算一个输出像素的模糊值，线程需要**读取输入图像中该像素周围一个邻域（如 3x3, 5x5）内的多个像素值**。
    *   这与向量加法（每个线程只读两个输入元素）相比，**输入访问模式更复杂，访问量更大**。

3.  **图像表示：**
    *   示例中处理的是**单通道（Single plane）** 图像（如灰度图）。
    *   该设计**可以轻松扩展（can be extended easily）** 到**多通道（Multi-channel）** 图像（如 RGB），例如对每个颜色通道独立执行相同的模糊操作。

4.  **内存访问模式：行优先（Row-major）**
    *   代码展示了如何通过指针（`in`, `out`）访问图像数据。
    *   访问模式遵循**行优先（Row-major）** 存储布局，这是图像处理中常见的内存组织方式。
    *   计算像素索引需要根据图像宽度（`width`）进行偏移：`index = row * width + col`。

5.  **计算过程：求和与平均**
    *   内核内部使用一个变量（如 `pixVal`）作为**累加器（Accumulator）** 来**跟踪（track）** 所读取的邻域内所有有效像素值的**总和**。
    *   同时，通常需要一个计数器（如 `cells`）来记录实际求和的**有效像素数量**（因为边界像素的邻域可能不完整）。
    *   最终，输出像素值计算为 `pixVal / cells`（平均值）。

6.  **关键实现：边界条件处理**
    *   **处理边界条件是图像处理内核的关键和难点。**
    *   文本特别指出代码在**第 5 行和第 25 行（或其等价逻辑位置）** 处理了边界。
    *   常见处理方法：
        *   在循环遍历邻域像素时，检查当前邻域像素的坐标 `(blurCol, blurRow)` 是否在图像有效范围内 `(0 <= blurRow < height && 0 <= blurCol < width)`。
        *   只累加有效像素的值和计数。
        *   避免访问图像边界外的内存（防止越界错误）。

**总结：** 这个图像模糊示例展示了 CUDA 如何高效处理需要邻域操作的多维数据（图像）。它结合了“一线程一输出”的核心并行策略、复杂的输入访问模式（邻域读取）、行优先内存访问、累加求和以及至关重要的边界条件处理。