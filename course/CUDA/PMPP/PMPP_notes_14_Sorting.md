本文主要整理PMPP Chapter 13 Sorting的要点。

## 13.0 前言

### 内容概况

排序算法旨在将列表中的数据元素按特定顺序进行排列。排序是现代数据和信息服务的基础，因为经过排序的数据集能显著降低信息检索的计算复杂度，同时也能提升许多数据处理的效率。然而，即使使用高效的算法，对大规模数据列表进行排序仍然非常耗时，因此需要借助并行计算来加速。但高效排序算法的并行化本身具有挑战性，需要精心的设计。本章节主要介绍了两种高效排序算法（基数排序和归并排序）的并行设计方案。

### 要点总结

1.  **重点明确**：本章的核心与重点是**基数排序的并行设计**，大部分篇幅都用于讨论此算法。
2.  **简要介绍**：对于**归并排序**的讨论相对简略，其并行设计是基于第12章已介绍过的“并行归并模式”展开的。
3.  **提及其他**：除上述两种算法外，本章还简要提及了其他流行的并行排序算法，如**转置排序和采样排序**。

## 13.1 Background

**1. 排序的基本概念与要求**
*   **核心目标**：将列表元素按特定顺序（如非递减或非递增）排列。
*   **必须满足两个条件**：
    *   输出结果有序。
    *   输出是输入元素的一个排列（即不丢失、不新增元素）。
*   **用例**：从简单的数值排序，到基于键值对中某个“键”进行排序的复杂用例（例如，按收入对人员信息进行排序）。

**2. 排序算法的关键分类**
*   **稳定排序 vs. 不稳定排序**：
    *   **稳定排序**：当两个元素的键值相等时，能保持它们在原始输入中的相对顺序。这对于进行多级排序（先按次键排序，再按主键排序）至关重要。
    *   **不稳定排序**：不保证相等键值元素的原始顺序。
*   **基于比较的排序 vs. 非基于比较的排序**：
    *   **基于比较的排序**（如归并排序）：其时间复杂度下限为 O(N·log N)。
    *   **非基于比较的排序**（如基数排序）：可能突破 O(N·log N) 的限制，但通用性可能较低。

**3. 本章的重点与意义**
*   **主要内容**：本章将详细讲解两种排序算法的并行实现：
    *   **基数排序**：一种非基于比较的算法，将是本章的**重点**。
    *   **归并排序**：一种基于比较的算法。
*   **教学目的**：排序算法是讲解计算机科学核心概念的经典载体。本章延续这一传统，旨在通过这两个具体案例来阐释**并行化技术和性能优化方法**。
*   **参考文献**：本章的技术内容主要基于 Satish 等人 2009 年的研究。

## 13.2 Radix sort

### 内容概况

本部分内容详细介绍了**基数排序算法**。文字部分（13.2 Radix sort）从原理上阐述了基数排序作为一种**非比较型、高度可并行化**的排序算法，其核心在于根据键值的**基数**（即数位）进行多轮迭代的“分配”和“收集”。文中特别指出了选择2的幂次作为基数的优势，并重点解释了**稳定性**在排序过程中的关键作用。附图13.1则通过一个对**4位二进制数**使用**1位基数**进行排序的完整示例，直观地展示了四轮迭代（从最低有效位LSB到最高有效位MSB）中数据的流动和排序过程，完美印证了文字描述的原理。

### 要点总结

**1. 算法核心原理**
*   **非比较排序**：不通过直接比较元素大小来排序，而是通过分析键值的各个“数位”来分配。
*   **基于数位迭代**：从**最低有效位**开始，到**最高有效位**结束，逐位进行排序。
*   **稳定性**：这是算法的关键要求。每一轮排序时，对于当前数位值相同的元素，必须保留它们在上一轮排序后的相对顺序。这是保证高位排序有效性的基础。

**2. 处理逻辑与过程**
*   **分桶操作**：在每一轮迭代中，根据当前处理的数位值，将元素分配到对应的“桶”中（例如，二进制下就是0和1两个桶）。
*   **收集合并**：将各桶中的元素按顺序（如0桶在前，1桶在后）收集起来，形成下一轮的输入列表。
*   **迭代完成**：当所有数位（比特位）都处理完毕后，整个列表即成为有序状态。

**3. 基数选择的重要性**
*   文中指出，对于二进制表示的键值，选择**2的幂次（如2, 4, 8...）作为基数**非常方便。使用1位基数（Radix=2）最简单，但迭代次数多。使用更大的基数（如2位、4位）可以减少迭代次数，是常用的性能优化手段。

**4. 图例展示的关键点**
*   图13.1清晰地展示了：
    *   **迭代过程**：经过4轮迭代，无序的16个4比特数字最终被正确排序。
    *   **稳定性体现**：可以观察到，在每一轮中，当前数位相同的元素，其顺序与上一轮的结果完全一致（例如，Iteration 2中，第二LSB为1的所有数字，其顺序与Iteration 1的输出顺序相同）。
    *   **结果正确性**：最终结果是一个按数值从小到大排列的有序序列。

## 13.3 Parallel radix sort

### 内容概况

这组图片系统地阐述了**并行基数排序算法**的设计与实现，特别是其核心部分——**单个迭代的并行化**。内容从揭示算法固有的“迭代间串行、迭代内并行”的特性开始，逐步展开：首先提出让GPU每个线程处理一个键的基本并行化模型；然后深入分析计算每个键在输出列表中目标索引的关键问题，并推导出基于“映射到1的键的数量”的通用公式；最后，通过展示具体的CUDA内核代码，说明了如何利用**独占扫描** 这一并行原语来高效解决上述问题，从而完成整个并行排序迭代。

### 要点总结

**1. 核心特性：迭代间串行，迭代内并行**
*   基数排序的多个迭代（如从最低位到最高位）必须**顺序执行**，因为后一个迭代依赖于前一个迭代的完整排序结果。
*   并行化的机会存在于**每个迭代内部**。因此，本章重点在于如何并行化实现单个迭代的核函数。

**2. 基本并行化模型**
*   采用“每个线程处理一个输入键”的直观并行策略。
*   每个线程的责任是：确定其负责的键在当前迭代中应被放入哪个桶（0或1），并计算该键在输出列表中的正确位置（目标索引），最后将其写入该位置。

```c
__global__
void radix_sort_iter(unsigned int* input, unsigned int* output,
                     unsigned int* bits, unsigned int N, unsigned int iter) {

    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
    unsigned int key, bit;

    if (i < N) {
        key = input[i];
        bit = (key >> iter) & 1;
        bits[i] = bit;
    }

    exclusiveScan(bits, N);

    if (i < N) {
        unsigned int numOnesBefore = bits[i];
        unsigned int numOnesTotal = bits[N];
        unsigned int dst = (bit == 0) ? (i - numOnesBefore) : (N - numOnesTotal + numOnesBefore);
        output[dst] = key;
    }
}
```

**3. 目标索引计算的关键**
*   计算目标索引是并行化的核心挑战。公式根据键映射到的桶不同而略有差异，但都依赖于两个关键值：
    *   **`#ones_before`**：在当前键**之前**，所有映射到1桶的键的数量。
    *   **`#ones_total`**：整个输入列表中，映射到1桶的键的总数。
*   **映射到0桶的键**：`目标索引 = #zeros_before = 键的索引 - #ones_before`
*   **映射到1桶的键**：`目标索引 = #zeros_total + #ones_before = (输入大小 - #ones_total) + #ones_before`

**4. 独占扫描的核心作用**
*   上述计算中的非平凡部分（即获取 `#ones_before` 和 `#ones_total`）可以通过对一个由每个键的当前位（0或1）组成的数组进行**独占扫描** 来高效完成。
*   独占扫描的结果数组直接提供了每个位置的 `#ones_before` 值，而扫描结果的最后一个元素加上最后一个键的位值即可得到 `#ones_total`。

**5. 内核代码实现要点**
*   内核代码（图13.4）清晰地体现了这一流程：
    1.  **提取位**：每个线程从自己负责的键中提取当前迭代所关注的位。
    2.  **全局同步与扫描**：所有线程协作，对存储这些位的数组执行全局独占扫描操作。
    3.  **计算目标索引**：每个线程利用扫描结果（`#ones_before[i]` 和 `#ones_total`）根据上述公式计算其键的目标索引。
    4.  **分散写入**：将键写入到计算出的输出数组的目标位置。

## 13.4 Optimizing for memory coalescing

### 内容概况

这三张图片共同阐述了如何通过**利用共享内存**来优化并行基数排序算法中的**全局内存访问效率**。内容首先指出了最初直接写入全局内存的方案存在**内存访问无法合并**的关键性能问题。随后，提出了一种核心优化策略：将全局排序改为**先在线程块内部利用共享内存进行局部排序**，然后再将排好序的本地数据块**以合并访问的方式写入全局内存**。最后，详细介绍了确定各线程块本地数据在全局内存中正确写入位置的方法，即通过构建一个包含所有线程块本地桶大小的表格并对其执行**独占扫描** 来计算出每个本地桶的全局起始地址。

### 要点总结

**1. 问题：直接全局排序的内存合并问题**
*   在最初的并行方案中，各个线程直接将其键写入全局内存的对应桶（0或1）中。
*   这导致**相邻线程的写入操作可能指向不连续的内存地址**（例如，线程0写0桶，线程1写1桶，线程2又写0桶），从而无法实现内存访问的合并。
*   结果是，每个线程束（Warp）需要发出多次内存事务，严重降低了内存带宽的利用效率。

**2. 解决方案：两阶段排序与共享内存缓冲**
*   **核心思想**：采用“先局部，后全局”的两阶段策略，利用共享内存作为缓冲区来重组访问模式。
*   **阶段一：块内局部排序**：每个线程块在其共享内存中，独立地对所分配到的键执行一次完整的基数排序迭代（包括局部独占扫描），将键分离到本地的0桶和1桶中。
*   **阶段二：合并写入全局**：将每个线程块本地排好序的桶（先是所有0桶的键，然后是所有1桶的键）**整体地、连续地**写入全局内存。这样，块内线程在写入时访问的是连续内存地址，实现了高效的**内存合并**。

**3. 关键挑战与实现：确定本地桶的全局地址**
*   **挑战**：每个线程块需要知道其本地0桶和1桶在全局内存中的起始写入位置。
*   **解决方法**：
    1.  **收集桶大小**：每个线程块计算其本地0桶和1桶的大小（即包含的键的数量）。
    2.  **构建大小表**：将所有线程块的桶大小信息存入一个线性表中，顺序为：`[块0的0桶大小, 块1的0桶大小, ..., 块N的0桶大小, 块0的1桶大小, 块1的1桶大小, ..., 块N的1桶大小]`。
    3.  **执行独占扫描**：对该线性表执行**独占扫描**操作。扫描结果表中的每个值，即对应了该线程块本地桶在全局内存中的**起始写入地址**。
        *   本地0桶的全局地址：位于扫描结果表的前半部分。
        *   本地1桶的全局地址：位于扫描结果表的后半部分，其基础偏移量为所有线程块的0桶大小之和。

总结来说，这部分内容展示了如何通过引入共享内存和两阶段处理，将无序的、无法合并的内存访问模式，转换为有序的、可高效合并的访问模式，从而显著提升并行基数排序在GPU上的执行效率。确定全局写入地址的独占扫描方法是实现此优化的技术关键。

## 13.5 Choice of radix value

### 内容概况

这组图片深入探讨了在并行基数排序中**如何选择基数值** 这一关键问题。内容从回顾1位基数排序入手，指出了其迭代次数较多的缺点，进而引入使用**更大基数（如2位）** 作为优化手段。图片详细解释了多位基数排序的原理、并行化实现方法（特别是在GPU上利用共享内存优化内存访问），并通过示意图（图13.7, 13.8, 13.9）直观展示了2位基数排序的两轮迭代过程以及如何确定各线程块本地桶在全局内存中的位置。最后，内容重点分析了选择更大基数所带来的**优势与代价**，强调了需要在减少迭代次数和维持内存访问效率、控制全局操作开销之间取得平衡。

### 要点总结

**1. 使用更大基数的核心优势：减少迭代次数**
*   **1位基数**：对N位的键需要进行N次迭代。
*   **R位基数**：将R个位视为一个整体，每次迭代将键分配到 2^R 个桶中。迭代次数减少为 N/R 次。
*   **好处**：更少的迭代意味着更少的内核启动、全局内存访问和全局独占扫描操作，理论上能提升性能。

**2. 多位基数排序的并行化实现机制**
*   **基本流程一致**：与1位基数排序类似，每个迭代仍包含“分配”和“收集”两个阶段，并可并行化。
*   **块内局部排序**：为实现合并内存访问，每个线程块先在共享内存中完成局部排序。对于R位基数，块内局部排序是通过**连续执行R次1位基数排序**来实现的，从而将键排序到 2^R 个本地桶中。
*   **确定全局地址**：所有线程块将其本地桶的大小记录到一个全局表中，该表有 2^R 行。对该表执行**全局独占扫描**，扫描结果即为每个线程块的每个本地桶在全局输出数组中的起始地址（如图13.9所示）。

**3. 使用更大基数的代价与权衡**
*   **代价一：内存合并效率降低**
    *   基数越大，每个线程块拥有的本地桶数量（2^R）越多，但每个桶平均包含的键数越少。
    *   在写入全局内存时，线程块需要将数据写入更多、更小的不连续内存块中，这降低了内存访问的合并程度，影响了内存带宽的利用率。
*   **代价二：全局操作开销增加**
    *   执行全局独占扫描操作所处理的表大小随基数指数增长（从2行增至2^R行），该操作的开销会显著增加。

**4. 核心结论：需要在利弊之间取得平衡**
*   基数值的选择是一个**权衡**：
    *   **小基数**：迭代次数多，但内存合并性好，全局扫描开销小。
    *   **大基数**：迭代次数少，但内存合并性差，全局扫描开销大。
*   因此，不能无限制地增大基数。最优的基数值需要根据具体的硬件架构和问题规模，在**减少迭代次数的收益**与**内存访问效率下降、全局扫描开销增加的损失**之间找到最佳平衡点。

## 13.6 Thread coarsening to improve coalescing

### 内容概况

这两张图片（13.6节文字与图13.10）共同阐述了一种名为**线程粗化** 的优化技术，用以解决在GPU上并行化基数排序时出现的**内存访问合并效率下降**和**全局操作开销增加**的问题。文字部分首先分析了问题的根源：将工作分配给过多线程块会导致每个线程块处理的数据量变小，进而使其本地桶变小，写入全局内存时难以合并，且增加了全局独占扫描操作的开销。随后，提出了“线程粗化”的解决方案，即让每个线程处理多个键值而非一个。图13.10则通过示意图直观地对比了优化后的效果，展示了线程粗化如何通过增加每个线程块的工作负载，来创造更连续的内存访问模式，从而提升性能。

### 要点总结

**1. 问题：过度并行化带来的两个性能瓶颈**
*   **内存访问合并效率下降**：当使用大量线程块时，每个线程块处理的键值减少，其内部的本地桶也随之变小。在将这些小桶写入全局内存时，访问模式变得零散，导致**内存访问无法有效合并**，降低了内存带宽利用率。
*   **全局操作开销增加**：用于计算各线程块本地桶全局地址的**全局独占扫描**操作，其输入表的大小与“桶的数量 × 线程块的数量”成正比。线程块数量越多，该扫描操作的开销就越大。

**2. 解决方案：线程粗化**
*   **核心思想**：减少线程块的数量，但增加每个线程块（以及每个线程）的工作负载。即，**让每个线程处理输入列表中的多个键**，而不是仅仅一个。
*   **实现方式**：如图13.10所示，通过线程粗化，原本可能由两个小线程块处理的工作被合并到一个更大的线程块中处理。

**3. 线程粗化带来的双重好处**
*   **改善内存合并**：每个线程块负责的键值更多，其本地桶的尺寸也随之变大。当这些更大的本地桶被写入全局内存时，**连续线程写入连续内存位置的可能性大大增加**，从而显著改善了内存访问的合并程度。
*   **降低全局扫描开销**：由于线程块的总数减少，进行全局独占扫描时所处理的表尺寸也相应变小，从而**直接降低了这一全局同步操作的开销**。

总结来说，线程粗化是一种通过牺牲一定程度的并行度（减少线程块数量），来换取更高效的内存访问模式（改善合并）和更低的全局同步开销的经典优化策略，从而在整体上提升像基数排序这类数据密集型并行算法的性能。

## 13.7 Parallel merge sort

**1. 归并排序的适用场景与优势**
*   **对比基数排序的局限性**：当排序需要遵循复杂的比较规则（而非简单的字典序）时，基数排序不适用。
*   **核心优势**：基于比较的归并排序**通用性更强**。通过简单地更换比较运算符，同一份实现就能轻松适配不同类型键或复杂的排序规则，这在某些场景下比基数排序更具优势。

**2. 并行归并排序的基本策略**
*   **分治与合并**：算法分为两个主要阶段：
    1.  **分割与局部排序**：将输入列表分成多个小段，**并行地**对每一段进行排序（可以使用任何高效的排序算法，甚至是归并排序自身）。
    2.  **迭代归并**：递归地将已排序的段两两归并成更大的有序段，直到最终合并成一个完整的有序列表。

**3. 并行化的层次与阶段特性**
*   **双重并行性**：计算可以在两个层面上并行：
    *   **归并操作间并行**：在同一阶段内，多个独立的归并操作可以**同时进行**。
    *   **归并操作内并行**：单个归并操作内部（合并两个有序序列）也可以利用第12章所学的并行合并技术进行并行化。
*   **并行性的动态变化**：
    *   **早期阶段**：归并操作的数量多，但每个操作处理的数据量小。**并行性主要体现在多个操作之间**。
    *   **后期阶段**：归并操作的数量少，但每个操作处理的数据量巨大。**并行性主要转移到每个操作内部**。

**总结**：这部分内容指出，归并排序因其灵活性而成为并行排序中的重要选择。其并行化策略巧妙地利用了分治思想，通过在不同计算阶段动态调整并行重心（操作间并行 vs. 操作内并行）来充分利用硬件资源。

## 13.8 Other parallel sort methods

### 内容概况

本节作为对前述基数排序和归并排序的补充，旨在拓宽读者的知识面，简要介绍了多种其他的并行排序算法。内容涵盖了从简单但低效的**奇偶换位排序**，到结构固定的**排序网络**（如双调排序），再到主流的基于比较的并行排序算法的两大分类策略（以归并排序为代表的“自底向上”合并策略和以样本排序为代表的“自顶向下”划分策略），并最终将**基数排序**也纳入这一策略框架中进行讨论，比较了LSB（自底向上）和MSD（自顶向下）两种实现路径的优劣。

### 要点总结

**1. 多种并行排序算法简介**
*   **奇偶换位排序**：一种简单的算法，类似冒泡排序的并行版本，通过交替比较偶-奇和奇-偶索引对进行排序。**优点**是简单易懂；**缺点**是效率低，时间复杂度为O(N²)。
*   **排序网络**：使用**固定的比较模式**进行排序的一类算法，易于并行化。
    *   **代表算法**：巴彻尔双调排序、奇偶归并排序。
    *   **特点**：虽然渐近复杂度（O(N·log²N)）不如归并排序等，但因实现简单，**在小规模序列上往往非常高效**。

**2. 基于比较的并行排序的两大策略**
*   **第一类：自底向上 / 先排序后合并**
    *   **核心思想**：先将未排序输入分成小块，**并行排序各小块**，然后将主要工作量放在**合并这些已排序块**上。
    *   **典型代表**：**归并排序**。
*   **第二类：自顶向下 / 先划分后排序**
    *   **核心思想**：将主要工作量放在**划分输入序列**上，使得后续的合并变得简单。
    *   **典型代表**：**样本排序**。其通过采样得到分割点，将数据划分到多个桶中，确保桶间有序，然后各桶可独立排序。它尤其适合**超大规模**且数据分布在多个物理内存（如多GPU）的场景。

**3. 基数排序的策略归类与比较**
*   本节将基数排序的策略与上述分类进行类比。
*   **LSB基数排序** 对应 **自底向上** 策略：从最低位开始，每轮迭代都需要全局数据交换（洗牌），最后合并成有序序列。
*   **MSD基数排序** 对应 **自顶向下** 策略：从最高位开始划分，后续处理集中在更局部的数据区域内，避免了全局洗牌。因此，**MSD基数排序常在处理海量数据时更具优势**。

总结来说，本节揭示了并行排序算法设计的多样性与核心权衡，即在于选择“先局部排序再复杂合并”还是“先智能划分再简单合并”的不同路径。

## 13.9 Summary

### 内容概况

该总结系统性地回顾了本章的核心内容，重点概括了**基数排序（Radix Sort）在GPU上的并行化策略、关键优化技术及其权衡**，并简要提及了**归并排序（Merge Sort）** 作为基于比较的通用排序算法的并行化思路。最后，总结了在实际应用中利用现有高性能库（如Thrust）的实用性，并点明学习并行排序对于理解并行编程中的各种权衡（trade-offs）具有重要意义。

### 要点总结

**1. 并行基数排序的核心回顾**
*   **基本原理**：通过逐位（digit）将键分配（distribute）到不同的桶（buckets）中进行排序。每一轮迭代处理一个位，并**保持前一轮迭代的顺序（稳定性）**，最终完成整体排序。
*   **并行化实现**：为输入列表中的每个键分配一个线程，由线程负责计算其键在输出列表中的目标位置。这一过程的核心是线程间的**协作**，通过**独占扫描（exclusive scan）** 操作来实现。

**2. 关键优化策略与权衡**
*   **优化内存合并访问**：为实现高效的**合并内存访问（coalesced memory access）**，核心优化是让每个线程块（thread block）先在**共享内存（shared memory）** 中进行局部排序，将数据整理到本地桶中，然后再以合并访问的方式写入全局内存（global memory）。
*   **调整基数大小**：增大基数（radix size）可以减少迭代次数，但需**权衡利弊**。基数过大会导致：
    *   内存访问的**合并效果变差**。
    *   用于计算全局地址的**全局独占扫描操作的开销增加**。
*   **应用线程粗化**：此优化能有效**提升内存合并效率**，并**减少全局扫描操作的开销**。

**3. 算法选择与实用建议**
*   **算法比较**：
    *   **基数排序优势**：计算复杂度低于O(NlogN)，对于整数等特定类型键非常高效。
    *   **基数排序局限**：仅适用于整数等有限类型的键。
    *   **归并排序优势**：作为一种基于比较的算法，**通用性强**，可并行化（包括并行执行独立的归并操作以及在单个归并操作内部进行并行化）。
*   **实践建议**：在GPU上实现和优化并行排序算法是复杂的，因此对于大多数用户，更实际的做法是直接使用成熟的**GPU并行排序库（如Thrust）**，而非从头实现。
*   **学习价值**：尽管实践中多用库，但并行排序的实现过程本身是一个极佳的案例研究，深刻揭示了并行模式优化中需要考虑的**各种权衡（trade-offs）**。