本文主要整理PMPP Chapter 8 Stencil的要点。

## 8.0 前言

### 内容概况

首先阐述了模板在求解偏微分方程中的基础性作用及其广泛应用领域（如流体动力学、气象预报等），然后解释了模板算法处理的数据本质（离散化的物理量）。文章的核心部分重点对比了**模板与卷积的相似性与关键差异**，并基于这些差异（如迭代求解、数据依赖性、高精度要求等）指出二者在优化策略上存在显著不同。

### 要点总结

1.  **核心定义与作用**：
    *   **模板** 是求解偏微分方程数值方法的基础工具。
    *   其常见用途是基于函数在一系列输入变量值内的值，来**近似计算该函数的导数值**。

2.  **应用领域**：
    *   广泛应用于多个科学工程领域，包括流体动力学、热传导、燃烧、天气预报、气候模拟和电磁学等。

3.  **处理的数据**：
    *   处理的是具有物理意义的**离散化量**，如质量、速度、温度、电场等，这些量之间的关系由微分方程支配。

4.  **与卷积的相似性**：
    *   两者都是基于多维数组中某个元素及其邻域的值来计算该位置的新值。
    *   因此都需要处理**边界单元（Halo/Ghost Cells）** 的问题。

5.  **与卷积的关键差异**：
    *   **目的不同**：模板用于**迭代求解**连续可微函数在感兴趣域内的值；而卷积更多用于特征提取、滤波等。
    *   **系数来源**：模板的权重系数由所求解的**微分方程决定**；卷积的核通常是预设或学习得到的。
    *   **数据依赖与顺序**：在迭代求解过程中，输出值的计算可能存在**数据依赖关系**，需要遵循特定的计算顺序。
    *   **数据精度**：为满足数值精度要求，模板处理的数据通常是**高精度浮点数**，这对片上内存缓存技术提出了更高要求。

6.  **核心结论**：
    *   由于上述差异（求解目的、数据依赖性、高精度要求），模板计算所驱动的**优化策略与卷积不同**。一些适用于模板的优化方法可能不适用于卷积，反之亦然。

## 8.1 Background

### 内容概况

容从使用计算机求解科学计算问题的第一步——将连续函数离散化开始（图1），逐步深入到离散表示的精度与代价（图2），并详细定义了“模板”这一用于数值近似计算导数/偏导数的核心工具（图2，图3），最后扩展到多维情况（如二维网格），说明了如何利用模板求解偏微分方程，并总结了“模板扫描”这一核心计算模式（图4）。整个过程由浅入深，逻辑清晰，构成了理解科学计算基础的重要章节。

---

### 要点总结

#### 1. 离散化 - 数值计算的基础
*   **目的**：将连续的函数、模型和方程转换为计算机可处理的离散表示。
*   **过程**：如`Figure 8.1`所示，在一个定义域内，将连续函数在其离散网格点上的值存储下来。
*   **网格类型**：
    *   **规则网格**：网格点间距恒定，主要用于**有限差分法**。
    *   **非规则网格**：更复杂，用于有限元和有限体积法。
*   **精度与代价的权衡**：
    *   **网格密度**：网格点间距越小，离散表示的精度越高，但所需的存储空间和计算量也越大。
    *   **数值精度**：可使用双精度、单精度、半精度浮点数。高精度（如双精度）保真度高，但计算吞吐量低且对存储/带宽要求更高。

#### 2. 模板 - 数值近似的核心工具
*   **定义**：一个应用于**结构化网格**的**几何权重模式**，用于通过邻近点的值来数值近似目标点的导数值。
*   **数学表达**：以一维一阶导数为例，其近似公式为：
    $ f'(x) \approx \frac{f(x+h) - f(x-h)}{2h} $
    对应的模板系数为 $ [ -\frac{1}{2h}, 0, \frac{1}{2h} ] $。
*   **模板的阶**：由模板中心点**一侧**所使用的邻近点数量决定，反映了所能近似的**导数阶数**。
    *   **一阶模板（三点模板）**：用于近似一阶导数。
    *   **二阶模板（五点模板）**：用于近似二阶导数。
    *   **三阶模板（七点模板）**：用于近似三阶导数。

#### 3. 从一维到多维的扩展
*   **多维问题**：求解多变量偏微分方程需要在多维网格上进行离散。
*   **多维模板**：模板维度与网格维度对应。例如，二维偏微分方程需要使用二维模板。
    *   **五点模板**：用于计算仅含一阶偏导数的方程。
    *   **九点模板**：用于计算包含二阶偏导数的方程。

#### 4. 核心计算模式：模板扫描
*   **定义**：将同一个模板应用于网格中**所有相关点**的计算过程，称为一次**模板扫描**。这是求解偏微分方程迭代过程中的基本操作。
*   **输入与输出**：如`Figure 8.4`所示，输入是存储在多维数组中的网格点函数值，输出是每个网格点上计算得到的近似导数值。

## 8.2 Parallel stencil: a basic algorithm

### 内容概况

这两张图片承接了之前对模板计算概念的介绍，**重点阐述了一个基础的三维模板扫描并行算法、其实现内核以及初步的性能分析**。第一张图（图8.5）通过示意图明确了在迭代求解中简化边界条件的处理方式（边界值固定），并展示了对应的基础内核代码（图8.6）。第二张图则对该内核进行了深入分析，指出其核心性能瓶颈在于**计算强度过低**（浮点运算与全局内存访问的比率过低），并引出了后续需要采用**分块技术** 来进行优化的方向。

---

### 要点总结

```c
// 建议：将系数通过常量内存传递
__constant__ float coeffs[7]; // c0, c1, c2, c3, c4, c5, c6

__global__ void stencil_kernel(float* in, float* out, unsigned int N) {
    // 使用size_t防止溢出
    size_t i = blockIdx.z * blockDim.z + threadIdx.z;
    size_t j = blockIdx.y * blockDim.y + threadIdx.y;
    size_t k = blockIdx.x * blockDim.x + threadIdx.x;

    // 边界检查
    if (i >= 1 && i < N - 1 && j >= 1 && j < N - 1 && k >= 1 && k < N - 1) {
        // 计算中心索引
        size_t center = i * N * N + j * N + k;
        
        // 使用常量内存中的系数进行计算
        out[center] = coeffs[0] * in[center]                  // c0 * center
                    + coeffs[1] * in[center - 1]              // c1 * (k-1)
                    + coeffs[2] * in[center + 1]              // c2 * (k+1)
                    + coeffs[3] * in[center - N]              // c3 * (j-1)
                    + coeffs[4] * in[center + N]              // c4 * (j+1)
                    + coeffs[5] * in[center - N * N]          // c5 * (i-1)
                    + coeffs[6] * in[center + N * N];         // c6 * (i+1)
    }
}
```

#### 1. 基础并行算法的核心假设
*   **独立性假设**：在一次模板扫描内，各个输出网格点的计算之间**没有依赖关系**，因此可以完全并行计算。
*   **边界条件简化**：如图8.5所示，网格边界单元的值存储的是边界条件，在迭代过程中**保持不变**。因此，每次模板扫描只需计算内部的网格点，边界点直接保留输入值。

#### 2. 基础内核的实现要点
*   **线程映射**：基于CUDA编程模型，每个线程被分配负责计算一个输出网格点的值。通过 `blockIdx`， `blockDim` 和 `threadIdx` 变量计算线程对应的三维网格坐标。
*   **计算模式**：以**七点模板**（用于3D网格）为例，每个线程的执行流程为：
    1.  定位到分配给它的三维网格点。
    2.  读取该点及其六个直接相邻点（前、后、左、右、上、下）的输入值。
    3.  将这七个值分别乘以对应的系数（c0至c6，由所求解的微分方程决定）。
    4.  将七个乘积结果相加，得到该输出点的值。

#### 3. 性能分析与优化方向
*   **关键性能指标：计算强度**
    *   **定义**：浮点运算次数与全局内存访问字节数的比率（OP/B， Operations per Byte）。
    *   **计算**：对于所述的七点模板内核，每个线程执行 **13次浮点运算**（7次乘法 + 6次加法），但需要从全局内存加载 **7个单精度浮点数**（占28字节）。因此，其计算强度为 13 OP / 28 B ≈ **0.46 OP/B**。
*   **性能瓶颈**：0.46 OP/B是一个非常低的值，表明该内核的性能受限于全局内存的带宽，而非计算单元。大部分时间都花在了等待数据从内存传输上，计算单元处于闲置状态。
*   **优化策略**：为了解决这个瓶颈，需要采用与卷积优化类似的**分块技术**。该技术旨在将数据块加载到共享内存中，使得每个数据可以被多个线程复用，从而显著减少对全局内存的访问次数，最终**提高计算强度**，释放计算单元的潜力。

## 8.3 Shared memory tiling for stencil sweep

### 内容概况

这组内容承接了之前对基础模板计算内核的介绍，深入探讨了其关键优化技术——**共享内存分块**。它首先将模板的分块与卷积进行了类比，并指出了其核心差异（图1, 2, 3）。随后，展示了一个具体的三维七点模板的共享内存分块内核代码（图4, 5）。最后，文章重点分析了该方法的**严重局限性**：由于硬件对线程块大小的限制，三维分块的尺寸（T）无法做大，这导致了**数据复用率低**和**内存访问无法合并**两大性能瓶颈，从而引出了对更先进优化技术（如寄存器分块）的需求（图6, 7, 8）。

---

### 要点总结

#### 1. 模板分块 vs. 卷积分块：相似但关键差异
*   **相似性**：共享内存分块的基本策略（将数据从全局内存协作加载到共享内存中复用）与卷积高度相似。
*   **关键差异**：模板的“足迹”更小。
    *   例如，一个二维五点模板的输入块**不包含四个角点**（图2），而对应的3x3卷积则需要整个3x3区域。
    *   这直接导致模板的**理论计算强度上限**远低于同尺寸的卷积。例如，三维七点模板的理论上限是3.25 OP/B，而对应的7x7x7卷积理论上限高达171.5 OP/B（图1, 3）。

#### 2. 共享内存分块内核的实现
*   图4和图5展示并解释了一个三维七点模板的内核实现。
*   **核心机制**：
    *   **输入块与输出块**：线程块加载一个比所需输出区域更大的输入块（包含光环/Halo），以容纳模板计算所需的邻域数据。
    *   **线程映射**：每个线程负责将全局内存中的一个点加载到共享内存中。通过调整索引（`-1`）来确保输入块能完整覆盖输出块及其光环。
    *   **边界处理**：使用条件判断防止线程加载网格边界外的数据。
    *   **同步**：使用`__syncthreads()`确保所有数据加载完毕后再进行计算。
    *   **计算**：活跃线程从共享内存中读取数据，执行模板运算，并将结果写回全局内存。

#### 3. 共享内存分块的严重局限性（核心瓶颈）
文章的重点在于揭示该方法在三维场景下的不足。

*   **瓶颈一：低计算强度 due to 小分块尺寸 (T)**
    *   **硬件限制**：GPU线程块大小通常限制在1024线程内。对于一个三维分块，T最大只能为8（因为8x8x8=512），否则会超出限制。
    *   **光环开销巨大**：当T=8时，输入块有512个元素，但输出块只有6x6x6=216个元素。这意味着**高达58%的元素（296个）是仅被使用一次的光环元素**（图7）。
    *   **实际性能差**：计算强度公式为 `(13/4) * (1 - 2/T)^3`。当T=8时，强度仅为1.37 OP/B，远低于3.25 OP/B的理论上限，也表明内存带宽仍是主要瓶颈（图6）。

*   **瓶颈二：内存访问无法合并**
    *   由于分块太小（8x8x8），一个线程束（32个线程）在加载数据时，需要访问内存中**多个不连续的行**（图7, 8）。
    *   这种非连续的访问模式无法利用GPU的**内存合并访问** 特性，导致DRAM带宽利用率极低。

#### 4. 核心结论与后续方向
*   **结论**：传统的、基于线程块的共享内存分块策略对于三维模板计算效果有限，无法有效提升计算强度和解决内存带宽瓶颈。
*   **出路**：必须采用**更激进的优化技术**来突破线程块大小的限制，实现更大的有效分块尺寸（T）。这自然引向了下一节的主题：**通过线程粗化和寄存器分块**，在单个线程内处理多个数据点，从而在逻辑上实现更大的“分块”，并显著提高数据复用率和内存访问效率。

## 8.3 三维七点模板的理论上限是3.25 OP/B，而对应的7x7x7卷积理论上限高达171.5 OP/B ?

这个看似反直觉的差异（3.25 OP/B vs. 171.5 OP/B）源于两种计算模式在**数据复用**机制上的根本区别，尤其是在使用**共享内存分块**优化策略时。核心原因在于：

### 1. **计算模式与数据需求量的差异**
*   **三维七点模板 (7-Point Stencil)**：
    *   **每个输出点**的计算只需要访问**7个输入点**：中心点本身 + 沿x, y, z轴正负方向的6个直接邻居。
    *   **计算量**：每个输出点通常需要 `7次乘法 + 6次加法 = 13次浮点运算 (FLOP)`。
*   **三维7x7x7卷积 (7x7x7 Convolution)**：
    *   **每个输出点**的计算需要访问一个 **7x7x7 = 343个输入点** 的立方体区域。
    *   **计算量**：每个输出点需要 `343次乘法 + 342次加法 = 685次浮点运算 (FLOP)`。

**关键点：** 卷积每个输出点需要访问的输入数据量（343个点）远大于模板（7个点）。

### 2. **共享内存分块策略下的数据复用**
当使用共享内存分块时，线程块协作加载一个**输入块**到共享内存中，然后从这个共享内存块中计算**输出块**。计算强度的上限取决于**输出块中的每个输入点平均被使用了多少次**。

*   **三维七点模板 (7-Point Stencil)**：
    *   **输入块大小**：为了计算一个 `T x T x T` 的输出块，需要加载一个 `(T+2) x (T+2) x (T+2)` 的输入块。这是因为输出块边界上的点需要访问其邻居（即“光环/Halo”区域）。
    *   **输入点总数**：`(T+2)^3`
    *   **输出点总数**：`T^3`
    *   **总计算量 (FLOP)**：`13 * T^3`
    *   **总输入字节数 (Bytes)**：假设单精度浮点数 (4 Bytes/point)，则输入数据量为 `4 * (T+2)^3` Bytes。
    *   **计算强度上限 (OP/B)**：
        `(13 * T^3) / (4 * (T+2)^3) = (13/4) * (T^3 / (T+2)^3) = (13/4) * (1 / (1 + 2/T)^3)`
    *   **当 T 很大时**：`(1 + 2/T)^3 ≈ 1`，因此理论强度上限趋近于 `13/4 = 3.25 OP/B`。
    *   **实际限制**：由于线程块大小限制（通常 ≤ 1024 线程），`T` 无法做得很大（例如 `T=8` 时，`(8+2)^3 = 1000` 点，接近线程块大小限制）。此时 `(1 + 2/8)^3 = (1.25)^3 = 1.953125`，强度上限仅为 `(13/4) / 1.953125 ≈ 1.66 OP/B`。更小的 `T` 导致更低的实际上限。

*   **三维7x7x7卷积 (7x7x7 Convolution)**：
    *   **输入块大小**：为了计算一个 `T x T x T` 的输出块，需要加载一个 `(T+6) x (T+6) x (T+6)` 的输入块。这是因为输出块边界上的点需要访问其周围 3 个点（(7-1)/2=3）的邻域。
    *   **输入点总数**：`(T+6)^3`
    *   **输出点总数**：`T^3`
    *   **总计算量 (FLOP)**：`685 * T^3` (假设每个输出点685 FLOP)
    *   **总输入字节数 (Bytes)**：`4 * (T+6)^3` Bytes。
    *   **计算强度上限 (OP/B)**：
        `(685 * T^3) / (4 * (T+6)^3) = (685/4) * (T^3 / (T+6)^3) = (685/4) * (1 / (1 + 6/T)^3)`
    *   **当 T 很大时**：`(1 + 6/T)^3 ≈ 1`，因此理论强度上限趋近于 `685/4 = 171.25 OP/B`。
    *   **实际潜力**：即使 `T` 受限于线程块大小（例如 `T=8`），`(1 + 6/8)^3 = (1.75)^3 ≈ 5.359`，强度上限仍有 `(685/4) / 5.359 ≈ 31.9 OP/B`。这**远高于**相同 `T` 下模板的 1.66 OP/B。更大的 `T` 会使其更接近理论极限。

### 3. **核心差异：数据复用率**
*   **模板复用率低**：在 `(T+2)^3` 的输入块中，只有位于 `(T x T x T)` 核心区域内的点**有可能**被多次使用（作为其邻居的中心点）。然而：
    *   位于输入块最外层（光环层）的点**只被使用一次**（作为某个输出点的邻居）。
    *   随着 `T` 增大，光环点占总输入点的比例 `≈ (6T^2) / T^3 = 6/T` 会减小，但受限于硬件 `T` 无法很大，导致光环开销占比很高（如 `T=8` 时，光环点占 `(10^3 - 8^3)/1000 = (1000-512)/1000 = 48.8%`），严重拉低复用率。
*   **卷积复用率高**：在 `(T+6)^3` 的输入块中，**几乎每一个输入点**都会被用于计算**多个**输出点（最多可达 `min(7, T)^3` 次，具体取决于点在块内的位置）。卷积核在输入块上滑动，使得块内大部分点都参与了多个输出点的计算。
    *   即使有光环点（占比 `≈ (18T^2) / T^3 = 18/T`），其复用次数也远高于模板的光环点。
    *   核心区域内的点复用次数极高（例如中心点被用于所有 `T^3` 个输出点的计算）。

### 总结：为什么差异如此巨大？
1.  **基础计算需求不同**：卷积每个输出点需要多得多的输入数据（343 vs 7）。
2.  **分块光环开销比例不同**：模板的光环相对其核心输出块更大（`(T+2)/T vs (T+6)/T`），且受限于小 `T`，光环占比极高。
3.  **数据复用潜力天壤之别**：这是最根本的原因。卷积计算模式**天然具有极高的数据局部性和复用性**。共享内存中的**每一个输入点**都可能被用于计算输出块中的**多个甚至所有输出点**。而模板计算中，一个输入点（除了中心点本身）通常**只影响其直接邻居的输出点**，复用次数非常有限（通常≤6次，且边界点只被用1次）。

## 8.4 Thread coarsening

### 内容概况

这组内容承接了之前对基础共享内存分块法的讨论，针对其存在的**分块尺寸（T）小、数据复用率低**的核心瓶颈，提出并详细阐述了一种关键的优化技术——**线程粗化**。

具体而言，它介绍了一种在**Z轴方向上进行线程粗化**的方法，用于优化三维七点模板计算。内容通过示意图（图8.9, 8.11）和完整的代码示例（图8.10）解释了该技术的设计思想、实现细节（包括共享内存的管理、迭代计算流程和数据复用策略）以及所带来的显著性能收益。

---

### 要点总结

#### 1. 核心思想：改变工作粒度以突破瓶颈
*   **问题**：传统共享内存分块法中，线程块大小限制（~1024线程）迫使三维分块的尺寸T不能太大（如T=8），导致“光环”数据占比高，计算强度低。
*   **解决方案：Z方向线程粗化**。将每个线程的工作从计算**一个**网格点，粗化为计算Z轴上的**一列**网格点。
*   **效果**：线程块只需覆盖一个X-Y平面（大小为T×T），即可通过迭代的方式处理Z方向上多个平面，从而在逻辑上实现一个更大的三维分块（T×T×OUT_TILE_DIM），且**线程数量仅需T²**。

```c
__global__ void stencil_kernel(float* in, float* out, unsigned int N) {
    int iStart = blockIdx.z*OUT_TILE_DIM;
    int j = blockIdx.y*OUT_TILE_DIM + threadIdx.y - 1;
    int k = blockIdx.x*OUT_TILE_DIM + threadIdx.x - 1;
    
    __shared__ float inPrev_s[IN_TILE_DIM][IN_TILE_DIM];
    __shared__ float inCurr_s[IN_TILE_DIM][IN_TILE_DIM];
    __shared__ float inNext_s[IN_TILE_DIM][IN_TILE_DIM];
    
    if(iStart-1 >= 0 && iStart-1 < N && j >= 0 && j < N && k >= 0 && k < N) {
        inPrev_s[threadIdx.y][threadIdx.x] = in[(iStart-1)*N*N + j*N + k];
    }
    
    if(iStart >= 0 && iStart < N && j >= 0 && j < N && k >= 0 && k < N) {
        inCurr_s[threadIdx.y][threadIdx.x] = in[iStart*N*N + j*N + k];
    }
    
    for(int i = iStart; i < iStart + OUT_TILE_DIM; ++i) {
        if(i+1 >= 0 && i+1 < N && j >= 0 && j < N && k >= 0 && k < N) {
            inNext_s[threadIdx.y][threadIdx.x] = in[(i+1)*N*N + j*N + k];
        }
        
        __syncthreads();
        
        if(i >= 1 && i < N - 1 && j >= 1 && j < N - 1 && k >= 1 && k < N - 1) {
            if(threadIdx.y >= 1 && threadIdx.y < IN_TILE_DIM - 1
               && threadIdx.x >= 1 && threadIdx.x < IN_TILE_DIM - 1) {
                out[i*N*N + j*N + k] = c0*inCurr_s[threadIdx.y][threadIdx.x]
                                      + c1*inCurr_s[threadIdx.y][threadIdx.x-1]
                                      + c2*inCurr_s[threadIdx.y][threadIdx.x+1]
                                      + c3*inCurr_s[threadIdx.y+1][threadIdx.x]
                                      + c4*inCurr_s[threadIdx.y-1][threadIdx.x]
                                      + c5*inPrev_s[threadIdx.y][threadIdx.x]
                                      + c6*inNext_s[threadIdx.y][threadIdx.x];
            }
        }
        
        __syncthreads();
        
        inPrev_s[threadIdx.y][threadIdx.x] = inCurr_s[threadIdx.y][threadIdx.x];
        inCurr_s[threadIdx.y][threadIdx.x] = inNext_s[threadIdx.y][threadIdx.x];
    }
}
```

#### 2. 关键实现机制：三层面板滑动窗口
*   **共享内存策略**：内核不使用一个大的三维共享内存数组，而是巧妙地为每个X-Y平面维护三个二维共享内存数组：`inPrev_s`, `inCurr_s`, `inNext_s`。它们分别存储计算当前输出层所需的**前一层、当前层、后一层**输入数据。
*   **迭代计算**：线程块在Z方向上迭代。每次迭代中：
    1.  **加载**：协作将下一次迭代所需的“后一层”数据加载到 `inNext_s`。
    2.  **同步**：确保所有数据加载完毕。
    3.  **计算**：每个活跃线程利用三个面板中的数据计算当前Z位置输出点的值（七点模板计算）。
    4.  **滑动**：计算完成后，将 `inCurr_s` 的数据滑到 `inPrev_s`，将 `inNext_s` 的数据滑到 `inCurr_s`，为下一次迭代做准备。这形成了一个高效的“滑动窗口”，复用了数据。

#### 3. 技术优势与收益
*   **巨大的分块尺寸**：线程块大小从T³降为T²，因此可以使用更大的T值（例如T=32，线程块大小为1024）。这使得逻辑上的三维分块尺寸（32×32×OUT_TILE_DIM）远大于之前的方法。
*   **显著提升的计算强度**：
    *   公式：`(13/4) * (1 - 2/T)³`
    *   当T=32时，计算强度从原来的约**1.37 OP/B** 提升至约**2.68 OP/B**，更接近3.25 OP/B的理论上限。
*   **可控的共享内存开销**：内存需求从存储整个三维输入块（T³个元素）变为仅需存储三个二维面板（3×T²个元素）。当T=32时，共享内存消耗约为12KB，处于合理水平。
*   **改善的内存访问模式**：由于T值变大，线程块中的线程在加载X-Y平面数据时，更容易实现**合并内存访问**，从而更高效地利用显存带宽。

### 核心结论
通过将并行维度从三维（X, Y, Z）降为二维（X, Y），并在第三个维度（Z）上通过线程粗化进行串行迭代，该技术成功地**突破了硬件对线程块数量的限制**，实现了更大的有效分块尺寸，从而显著提高了数据复用率和计算强度，是优化三维模板计算的一种非常有效的方法。

## 8.5 Register tiling

### 内容概况

这四张图片共同阐述了在三维七点模板计算中，在**线程粗化** 基础上进一步引入**寄存器分块** 的高级优化技术。第一张图（8.5节）从理论上分析了该技术的动机与核心思想；第二张图（图8.12）展示了完整的实现代码；第三、四张图则深入分析了该技术的优势、代价及其在设计范式上的意义。

---

### 要点总结

```c
__global__ void stencil_kernel(float* in, float* out, unsigned int N) {
    int iStart = blockIdx.z * OUT_TILE_DIM;
    int j = blockIdx.y * OUT_TILE_DIM + threadIdx.y - 1;
    int k = blockIdx.x * OUT_TILE_DIM + threadIdx.x - 1;
    
    __shared__ float inCurr_s[IN_TILE_DIM][IN_TILE_DIM];
    
    float inPrev, inCurr, inNext;
    
    if(iStart-1 >= 0 && iStart-1 < N && j >= 0 && j < N && k >= 0 && k < N) {
        inPrev = in[(iStart-1)*N*N + j*N + k];
    }
    
    if(iStart >= 0 && iStart < N && j >= 0 && j < N && k >= 0 && k < N) {
        inCurr = in[iStart*N*N + j*N + k];
    }
    
    if(iStart >= 0 && iStart < N && j >= 0 && j < N && k >= 0 && k < N) {
        inCurr_s[threadIdx.y][threadIdx.x] = inCurr;
    }
    
    for(int i = iStart; i < iStart + OUT_TILE_DIM; ++i) {
        if(i+1 >= 0 && i+1 < N && j >= 0 && j < N && k >= 0 && k < N) {
            inNext = in[(i+1)*N*N + j*N + k];
        }
        
        if(i+1 >= 0 && i+1 < N && j >= 0 && j < N && k >= 0 && k < N) {
            inCurr_s[threadIdx.y][threadIdx.x] = inCurr;
        }
        
        __syncthreads();
        
        if(i >= 1 && i < N - 1 && j >= 1 && j < N - 1 && k >= 1 && k < N - 1) {
            if(threadIdx.y >= 1 && threadIdx.y < IN_TILE_DIM - 1
               && threadIdx.x >= 1 && threadIdx.x < IN_TILE_DIM - 1) {
                out[i*N*N + j*N + k] = c0*inCurr
                                      + c1*inCurr_s[threadIdx.y][threadIdx.x-1]
                                      + c2*inCurr_s[threadIdx.y][threadIdx.x+1]
                                      + c3*inCurr_s[threadIdx.y+1][threadIdx.x]
                                      + c4*inCurr_s[threadIdx.y-1][threadIdx.x]
                                      + c5*inPrev
                                      + c6*inNext;
            }
        }
        
        __syncthreads();
        
        inPrev = inCurr;
        inCurr = inNext;
    }
}
```

#### 1. 优化动机：识别特殊的数据访问模式
*   对于**七点模板**这类仅涉及中心点及其在x, y, z轴方向上直接邻居的模板，其数据访问模式具有一个关键特性：
    *   存储在 `inPrev_s`（前一层）和 `inNext_s`（后一层）数组中的每个数据（z方向邻居），在计算过程中**只被一个特定的线程使用**（即拥有相同x-y索引的线程）。
    *   只有存储在 `inCurr_s`（当前层）中的数据（x-y平面内的邻居）才需要被**多个线程共享**访问。
*   这一发现意味着，真正需要放入**共享内存**的只有 `inCurr_s`，而 `inPrev_s` 和 `inNext_s` 中的数据可以存放在**延迟更低、速度更快的寄存器**中。

#### 2. 核心技术：寄存器分块
*   **实现方式**：在线程粗化内核（图8.10）的基础上进行修改（图8.12）：
    1.  **创建寄存器变量**：为每个线程创建寄存器变量 `inPrev`, `inCurr`, `inNext`，用于替代原来的共享内存数组 `inPrev_s` 和 `inNext_s`。
    2.  **保留必要的共享内存**：仅保留 `inCurr_s` 共享内存数组，用于存储当前平面数据，以供线程块内线程间共享x-y方向的邻居数据。
*   **数据流动**：初始加载和每次迭代前的“下一平面”数据加载，其目标地址都是寄存器变量。同时，内核会始终在共享内存中维护当前平面的一个副本，以确保x-y邻居数据的可共享性。

#### 3. 优势与代价
*   **两大优势**：
    1.  **性能提升**：将大量对共享内存的读写操作转移至寄存器。由于寄存器具有更低的延迟和更高的带宽，代码运行速度预期会更快。
    2.  **共享内存消耗降低**：该内核的共享内存使用量降至原线程粗化内核的**三分之一**，这有助于容纳更多的线程块并发执行。
*   **相应代价**：
    *   **寄存器使用量增加**：每个线程需要额外使用3个寄存器。对于一个32x32的线程块，整个块将多占用3072个寄存器。
    *   **潜在问题**：对于更高阶的模板，寄存器使用量会进一步增加。如果寄存器使用过多，可能会限制GPU上可同时活跃的线程块数量，影响并行性。如果成为问题，可能需要回溯，将部分数据存回共享内存。

#### 4. 核心结论与设计思想
*   **不影响全局内存带宽**：增加寄存器分块**并未改变**全局内存的访问次数和数据复用总量，因此对全局内存带宽的消耗没有影响。其优化目标在于利用更快的片上存储来加速计算本身。
*   **经典的权衡**：这体现了一个在GPU优化中常见的**权衡**：在**共享内存使用**和**寄存器使用**之间进行取舍。
*   **并非全新概念**：寄存器分块的思想并非首创。在之前的矩阵乘法和卷积优化中，我们已经将**输出块**存储在块的线程寄存器中。此处的新意在于，将这种技术明确地应用于存储**输入块**的一部分，并清晰地展示了在寄存器和共享内存之间协同分布数据的策略。

## 8.6 Summary

### 1. 核心对比：模板扫描 vs. 卷积
*   **相似点**：从计算模式上看，模板扫描类似于一种具有特殊滤波器模式（即模板）的卷积运算。
*   **根本差异**：模板源于**求解微分方程时对导数的离散化和数值近似**。这一数学背景赋予了它独特的特性。

### 2. 驱动模板优化的两个关键特性

*   **特性一：典型的数据维度与应用场景**
    *   **模板**：通常作用于**三维网格**（如物理空间模拟）。
    *   **卷积**：通常作用于**二维图像**（或少量2D图像的时间切片）。
    *   **优化启示**：这种维度差异使得两者的分块策略不同。对于三维模板，直接进行三维分块会受限于线程块大小，从而催生了**线程粗化** 技术。该技术通过处理Z维上的一列数据，实现了更大的逻辑分块和更高的数据复用。

*   **特性二：独特的数据访问模式**
    *   **模板**：其访问模式（如七点模板）有时允许将部分输入数据（如Z方向的前后层数据）的访问权限完全限定给单个线程。
    *   **优化启示**：这一特性使得**输入数据的寄存器分块** 成为可能。将这部分数据存入寄存器而非共享内存，可以进一步提升访问吞吐量，并有效缓解共享内存的资源压力。

### 3. 总结
本章揭示，正是由于模板计算在**应用维度**和**数据局部性**方面的独特性质，才激发并使得**线程粗化** 和**寄存器分块** 这类专属于模板的深度优化成为必要且可行的手段。