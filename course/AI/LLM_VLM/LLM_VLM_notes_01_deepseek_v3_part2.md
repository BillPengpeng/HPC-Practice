本文主要整理《DeepSeek-V3 Technical Report》的主要内容。

## 3.2 - Auxiliary-Loss-Free Load Balancing

### **内容概括**

其核心创新在于：**为每个专家引入一个动态可调的偏差项**。在决定每个 Token 应路由至哪些专家时，系统会将这个偏差项加到原始的亲和力分数上，以此来影响路由决策。训练过程中，系统持续监控各专家的负载情况：对**过载**专家调低其偏差，对**欠载**专家调高其偏差，从而实现专家使用率的动态平衡。关键在于，这个偏差**仅用于路由选择**，而在计算最终专家输出的权重时，仍使用原始的亲和力分数，从而在维持模型表达能力和实现负载均衡之间取得了更优的权衡。

### **要点总结**

1.  **问题背景**：MoE模型中，专家负载不均衡会导致**路由崩溃**（部分专家被过度使用，部分被闲置）和**计算效率下降**（在专家并行场景下尤为严重）。
2.  **传统方案**：普遍依赖**辅助损失**来鼓励负载均衡，但过强的辅助损失会直接**损害模型的主任务性能**。
3.  **本方案核心**：提出一种**无需辅助损失**的负载均衡策略，通过引入一个**动态调整的专家偏差**来引导路由。
4.  **工作原理**：
    *   **路由决策**：使用 `亲和力分数 + 专家偏差` 来决定 Top-K 专家。
    *   **输出计算**：计算专家输出的权重（门控值）时，**仅使用原始的亲和力分数**，偏差不参与。
    *   **动态调整**：根据专家在每一步训练的负载情况（过载或欠载），以固定步长 `γ` 反向调整其偏差值。
5.  **核心优势**：实现了**负载均衡与模型性能之间更好的权衡**，避免了辅助损失对模型能力的潜在伤害。

### **公式解释**

图片中的核心公式定义了如何利用偏差项进行路由选择：

**公式 (16) - 基于偏差调整的 Top-K 路由**
$$
g_{i,t}^{\prime}=\begin{cases}s_{i,t}, & s_{i,t}+b_{i} \in \text{Topk}(\{s_{j,t}+b_{j}|1\leqslant j\leqslant N_{r}\}, K_{r}), \\
0, & \text{otherwise}.
\end{cases}
$$

*   **公式目的**：确定第 $t$ 个 Token 是否应路由给第 $i$ 个专家，并给出其原始权重。
*   **符号解释**：
    *   $g_{i,t}'$：第 $i$ 个专家在第 $t$ 步的**原始门控值**（在后续会归一化为最终权重）。
    *   $s_{i,t}$：第 $i$ 个专家在第 $t$ 步的**原始亲和力分数**（由公式15的Sigmoid计算得出）。
    *   $b_i$：第 $i$ 个专家的**可学习偏差项**，是本方法的核心。
    *   $N_r$：路由专家的总数。
    *   $K_r$：每个 Token 激活的路由专家数量（Top-K的值）。
    *   $Topk(...)$：从集合中选出值最大的 $K_r$ 个元素的函数。
*   **计算逻辑**：
    1.  **评分调整**：为每个专家的原始亲和力分数 $s_{i,t}$ 加上其对应的偏差 $b_i$，得到调整后的分数 $(s_{i,t} + b_i)$。
    2.  **竞争选择**：所有专家的调整后分数组成集合 ${s_{j,t} + b_j}$。系统从中选出分数最高的 $K_r$ 个专家。
    3.  **条件赋值**：
        *   **如果** 第 $i$ 个专家的调整后分数 $(s_{i,t} + b_i)$ 位于这 Top-K 集合内，则它被选中。此时，$g_{i,t}'$ 被赋予其**原始亲和力分数** $s_{i,t}$。
        *   **否则**，该专家未被选中，$g_{i,t}' = 0$。
*   **关键点**：
    *   偏差 $b_i$ **仅用于路由决策**（决定谁进入Top-K）。
    *   决定专家最终输出贡献的权重基础，仍然是**原始的、未加偏差的亲和力分数** $s_{i,t}$。这保证了模型能力不受平衡操作的影响。
    *   偏差 $b_i$ 本身在训练中根据专家负载动态调整：过载则 $b_i$ 减小，降低其被选中的概率；欠载则 $b_i$ 增大，增加其被选中的概率。

## 3.2 - 负载情况判断

DeepSeek-V3中判断专家**过载（overloaded）** 或**欠载（underloaded）** 的逻辑，其核心是基于在**每个训练步骤（step）的整个批次（batch）** 上，对**每个专家被激活（即被选入Top-K）的频率**进行实时监控和统计。

具体判断逻辑可推断如下：

### **1. 核心指标：专家的“负载”**
*   **负载的定义**：在一个训练步骤中，对于一个给定的专家，其**负载**可以理解为在该批次所有输入Token中，有多少个Token将它选入了自己的Top-K专家集合。简单说，就是**该专家在这个批次中被选中的总次数**。

### **2. 判断过载与欠载的基准**
系统需要判断一个专家的负载是“过高”还是“过低”，这需要一个**参考基准值**。虽然没有在图中明确给出公式，但业界常见的做法通常基于以下计算：
*   **理想平均负载**：`期望负载 = （批次中的总Token数 × 每个Token激活的专家数 K_r） / 路由专家总数 N_r`
    *   这个值代表了在**完全均匀分配**的理想情况下，每个专家平均应该处理的Token数量。
*   **判断逻辑**：
    *   **过载专家**：该专家在当前步骤的实际负载**持续**或**显著**高于这个理想平均负载。
    *   **欠载专家**：该专家在当前步骤的实际负载**持续**或**显著**低于这个理想平均负载。

### **3. 动态调整机制（如图所示）**
判断的目的是为了驱动对偏差项 $ b_i $ 的动态调整：
1.  **监控**：在每个训练步骤的前向传播过程中，系统记录下每个路由专家被选中的次数（负载）。
2.  **判断**：在步骤结束时，根据上述负载统计与基准的比较，判定每个专家处于“过载”还是“欠载”状态。
3.  **调整**：
    *   如果专家 $i$ 被判定为 **过载**，则将其偏差项 $b_i$ **减少** 一个固定的步长 $γ$（超参数，偏差更新速度）。
    *   如果专家 $i$ 被判定为 **欠载**，则将其偏差项 $b_i$ **增加** $γ$。

### **总结判断过程**
| 步骤 | 关键操作 | 说明 |
| :--- | :--- | :--- |
| **前向计算** | 统计负载 | 对于当前批次，记录每个专家被Top-K选中的总次数。 |
| **步骤结束时** | 计算与比较 | 将每个专家的实际负载与预期的平均负载（或其他阈值）进行比较。 |
| **步骤结束时** | 状态判定 | 判定该专家是 **过载**（负载过高）还是 **欠载**（负载过低）。 |
| **步骤结束时** | 更新偏差 | 根据判定结果，按规则增加或减少该专家的偏差项 $b_i$。 |

**简单来说**：判断的依据就是**看每个专家在当前一批数据里“活”干得太多还是太少**。干得太多（过载），下次就给它“减点分”（降低b_i），让它被选中的概率变小；干得太少（欠载），就给它“加点分”（提高b_i），鼓励更多Token选择它。通过这种持续的微调，最终实现专家间工作量的均衡分配。

## 3.3 - Complementary Sequence-Wise Auxiliary Loss

### **内容概括**

这段文字描述的是DeepSeek-V3模型训练中一个**辅助性的、精细化的正则化技术**。

尽管DeepSeek-V3的核心策略是前述的 **“无辅助损失负载均衡”**，该策略能有效平衡整个训练批次（batch）中所有专家的使用率。但作者们发现，这仍不能完全避免在**单个输入序列内部**出现极端不平衡的情况，即某个序列的所有Token可能都集中在少数几个专家上，导致序列内的专家利用率极低。

为了解决这个更细粒度的问题，论文提出并采用了一个**互补的序列级平衡损失**。这个损失的计算以单个序列为单位，其目标是鼓励模型在**每个独立的序列内**也能相对均衡地使用各个专家。值得注意的是，为了避免这个额外的损失函数干扰模型的主要学习目标，其权重系数α被设置为一个**极小的值**，因此它仅作为一种温和的、预防性的正则化手段。

### **要点总结**

1.  **定位与目的**：这是一个**补充性**的技术，旨在**防止单个序列内部的专家使用出现极端不平衡**，是对核心的“无辅助损失负载均衡”策略的补充和完善。
2.  **核心思想**：通过引入一个极低权重的辅助损失函数，对模型施加一个轻微的约束，鼓励其每个序列的Token能更均匀地“咨询”不同的路由专家。
3.  **关键特性**：
    *   **序列级别**：损失的计算基于单个序列，而不是整个批次。
    *   **极小权重**：平衡因子α被赋予一个**极小的值**，确保该损失仅作为微调，绝不会主导训练过程。
    *   **互补性**：它与主要的无辅助损失策略协同工作，分别从“批次全局”和“序列局部”两个层面优化负载均衡。

### **公式解释**

图片中给出了该损失的计算过程，其设计非常精巧，旨在度量单个序列内专家使用的均衡程度。

**公式 (17) - 总体平衡损失**
$$\mathcal{L}_{\text{Bal}}=\alpha\sum_{i=1}^{N_{r}}f_{i}P_{i}$$
*   **解读**：这是最终加到总损失函数中的平衡损失项。它对所有 \(N_r\) 个路由专家求和。乘积 \(f_i P_i\) 度量了专家 $i$ 在序列中**实际被使用的频率**与其**平均被选中的倾向性**之间的关系。


**公式 (18) - 专家使用频率**
$$f_{i}=\frac{N_{r}}{K_{r}T}\sum_{t=1}^{T}1\left(s_{i,t}\in\text{Topk}(\{s_{j,t}|1\leqslant j\leqslant N_{r}\},K_{r})\right)$$
*   **解读**：计算专家 $i$ 在**当前长度为T的序列**中的**实际使用频率**。
    *   $1(·)$ 是指示函数，当专家 $i$ 在第 $t$ 个Token的Top-K集合中时值为1，否则为0。
    *   $∑$ 求和后，得到专家 $i$ 在该序列中被选中的总次数。
    *   乘以 $N_r/(K_r T)$ 是为了进行**归一化**。$K_r T$ 可以理解为序列中总的“专家槽位”数。$f_i$ 的值越接近1，表示该专家的使用率越接近全局平均期望。

**公式 (19) - 归一化亲和力分数**
$$s_{i,t}^{\prime}=\frac{s_{i,t}}{\sum_{j=1}^{N_{r}}s_{j,t}}$$
*   **解读**：将原始亲和力分数 $s_{i,t}$ 在**当前序列的当前Token层面**进行归一化，得到 $s_{i,t}'$。这可以理解为，在第 $t$ 个Token处，专家 $i$ **相对于所有其他专家**的“相对吸引力”或“被选中的倾向性概率”。

**公式 (20) - 专家平均激活概率**
$$P_{i}=\frac{1}{T}\sum_{t=1}^{T}s_{i,t}^{\prime}$$
*   **解读**：计算专家 $i$ 在整个序列中**平均的、相对的被选中倾向性**。它是对序列中所有Token位置上的归一化亲和力分数 $s_{i,t}'$ 求平均。

## 3.4 - Node-Limited Routing

### **内容概括**

其核心思想是：对每个输入Token可以路由到的**物理节点数量施加一个硬性上限（M个）**，而不是允许它自由地发送到网络中的任何专家。具体的选择逻辑是，系统会为每个节点计算其内部所有专家的“最佳部分”的亲和力分数之和，然后根据这个总和来挑选出最佳的M个节点。通过这种**通信受限的路由机制**，结合精心设计的训练框架，系统能够将大部分必要的通信时间与计算过程重叠起来，从而近乎实现**完全的计算-通信重叠**，极大地提升了超大规模MoE模型的训练效率。

---

### **要点总结**

1.  **问题起源**：在分布式MoE训练中，Token需要根据路由结果被发送到存放对应专家的不同计算节点上，这个过程会产生大量**跨节点通信**，成为训练效率的主要瓶颈。
2.  **技术目标**：**显著限制和降低训练过程中的通信开销**。
3.  **核心机制**：
    *   **节点数量限制**：设定一个上限值 $M$，确保每个Token最多只被发送到 $M$ 个物理节点。
    *   **智能节点选择**：选择节点时，并非随机，而是基于一个聚合分数：对于一个候选节点，取出其内部部署的所有专家中，**亲和力分数最高的前 $K_r/M$ 个分数**，并将它们**求和**。这个总和代表了该节点对于当前Token的“潜在价值”。系统为所有节点计算这个值，并选择总分最高的 $M$ 个节点。
    *   **计算-通信重叠**：由于通信模式受到限制且可预测，训练框架能够提前调度数据传输，使其与GPU计算同时进行，从而隐藏了大部分通信延迟。
4.  **技术关联**：此技术是DeepSeek-V2中“设备限制路由”思想的延续与演进，专门针对超大规模训练集群进行了优化。
5.  **最终效果**：这是实现DeepSeek-V3**极致训练效率**（如前文提到的仅消耗278.8万GPU小时）的关键系统级优化之一，使得训练如此庞大的模型在经济上变得可行。

### **核心优势与原理总结**

| 方面 | 传统MoE分布式训练 | DeepSeek-V3的节点限制路由 | 带来的好处 |
| :--- | :--- | :--- | :--- |
| **通信模式** | **全连接式**：每个Token可能被路由到集群中任何节点上的专家，通信目标不可预测。 | **受限制式**：每个Token最多只访问$M$个节点，通信模式规整、可预测。 | **大幅减少通信量**，为优化调度奠定基础。 |
| **选择逻辑** | 基于**单个专家**的亲和力分数选择专家，专家所属节点是随结果决定的。 | 基于**节点级聚合分数**选择节点，节点内再选专家。更符合分布式系统的物理约束。 | **通信决策更高效**，优先保证最有价值的节点参与计算。 |
| **系统优化** | 计算与通信争抢资源，通信延迟直接增加训练耗时。 | 框架可实现**近乎完全的计算-通信重叠**，将通信时间“隐藏”起来。 | **极大提升训练吞吐率**，降低总体训练时间与成本。 |

## 3.5 - No Token-Dropping

### **内容概括**

这张图片强调了DeepSeek-V3模型在**训练和推理全流程中的一个重要优势：不丢弃任何Token**。

在许多混合专家模型中，为了保证处理效率（尤其是在专家负载不均时），常常会采用“Token丢弃”策略，即忽略或跳过对某些Token的路由计算。然而，DeepSeek-V3得益于其**有效的负载均衡策略**，在完整的训练过程中始终保持了良好的专家负载平衡。因此，**在训练阶段，模型无需丢弃任何Token**，确保了训练数据的完整性和模型学习的全面性。

此外，团队还通过实施**特定的部署策略**来保障推理时的负载平衡。因此，**在推理/服务阶段，DeepSeek-V3同样不会丢弃任何Token**，从而保证了每次预测都基于完整的输入信息，提升了输出的质量和可靠性。

---

### **要点总结**

**核心结论：DeepSeek-V3 在训练和推理中均实现了“零Token丢弃”。**

**支撑要点：**
1.  **训练阶段不丢Token**：
    *   **根本原因**：模型采用了**有效的负载均衡策略**（如前文详解的“无辅助损失负载均衡”与“互补序列级辅助损失”）。
    *   **带来的效果**：专家负载始终保持良好平衡，因此**无需**通过丢弃Token来缓解负载压力，保障了训练数据的充分利用。

2.  **推理阶段不丢Token**：
    *   **关键措施**：除了模型自身的负载平衡能力，团队还设计了**特定的部署策略**（如前文提到的“节点限制路由”等系统级优化）。
    *   **带来的效果**：在服务时也能维持高效的负载分配，从而**无需**在推理时丢弃Token，确保了每次生成都基于完整的上下文。

**意义总结：**
“零Token丢弃”是DeepSeek-V3设计先进性和高效性的一个综合体现。它意味着：
*   **更高的数据效用**：在训练和推理中均使用了100%的输入信息，无信息损失。
*   **更稳定的性能**：避免了因丢弃Token可能带来的输出质量波动或偏差。
*   **端到端的优化**：这一优势是模型算法（负载均衡策略）与系统工程（部署策略）协同设计、共同优化的结果。


