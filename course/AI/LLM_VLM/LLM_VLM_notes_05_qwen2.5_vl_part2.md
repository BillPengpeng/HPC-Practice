本文主要整理《Qwen2.5-VL Technical Report》的主要内容。

## 6.0 - Comparison with the SOTA Models

### 内容概括
本节通过一个综合性能对比表格，系统评估了 **Qwen2.5-VL 系列模型与当前最先进的闭源和开源视觉语言模型在多个权威基准测试上的表现**。核心目的是通过量化分数，客观展示Qwen2.5-VL，特别是其72B版本，在多项任务上的综合竞争力。

### 要点总结
从对比中可以总结出以下几个关键要点：

#### 1. **核心结论：达到顶尖水平**
- **整体领先**：**Qwen2.5-VL-72B** 在绝大多数评估数据集上表现优异，综合性能与**GPT-4o、Claude-3.5-Sonnet、Gemini-1.5-Pro** 等当前顶尖闭源模型**持平或超越**，确立了其作为全球第一梯队视觉语言模型的地位。
- **开源领先**：在开源模型中，Qwen2.5-VL系列（72B， 7B， 3B）**全面领先**，展现了其作为开源社区最强VLM之一的实力。

#### 2. **优势领域：数学、图表与文档理解**
- **数学与图表推理**：在 **MathVista**（数学视觉推理）和 **ChartQA**（图表问答）等需要强推理和理解的复杂任务上，Qwen2.5-VL-72B 取得了**显著优势**，这印证了其在技术报告中强调的复杂文档与图表解析能力。
- **通用视觉问答**：在 **MMMU**（跨学科知识问答）、**MMBench** 等综合视觉理解基准上，也取得了顶尖分数，证明了其广泛而强大的多模态理解能力。

#### 3. **模型规模与效率的平衡**
- **规模效应明显**：72B版本作为旗舰模型，性能全面最强，代表了该系列的最高水平。
- **中小模型表现出色**：**7B** 和 **3B** 版本在同类规模的模型中表现极为突出，甚至在多项测试中超越了其他更大的模型（如某些34B模型），为资源受限的边缘或移动端部署提供了高性能选择。

**总结**：该性能对比表有力地证明，**Qwen2.5-VL 不仅在技术上具有创新性，其最终性能也达到了业界最顶尖的水平**。它在维持全尺寸模型（72B）与顶尖闭源模型竞争的同时，其轻量化版本（7B/3B）也提供了极具竞争力的性能，实现了能力与效率的全面覆盖。

## 6.1 - PerformanceonPureTextTasks

### 内容概括
本节旨在评估经过指令微调的 **Qwen2.5-VL-72B** 模型在**纯文本任务**上的能力。研究选取了涵盖通用知识、数学与科学、代码生成及指令跟随四大领域的代表性基准测试，并将其与同规模（约720亿参数）的顶尖大语言模型进行对比。核心结论是：**Qwen2.5-VL不仅在多模态任务上领先，在纯文本任务上也展现了顶尖的性能，证明了其作为通用模型的强大 versatility（多功能性）与 robustness（鲁棒性）。**

### 要点总结
从对比数据中可以提炼出以下关键要点：

#### 1. **核心结论：多功能顶尖模型**
- **全能表现**：作为一个视觉语言模型，**Qwen2.5-VL-72B 在纯文本任务上达到了与当前最先进专用大语言模型（LLaMA-3.1-405B， Qwen2.5-72B）相媲美甚至超越的水平**。这证明了其架构与训练方法的有效性，使其成为真正意义上的“通才”模型。

#### 2. **对比细节：超越前代与竞品**
- **相比前代**：在绝大多数任务上，其性能**显著超越**了同参数规模的纯文本前代模型 **Qwen2-72B**。
- **相比同代纯文本版**：与同系列的纯文本模型 **Qwen2.5-72B** 相比，Qwen2.5-VL-72B 的表现**基本持平，部分领先**。例如，在 **LiveBench**（通用）、**MultiPL-E**（多语言代码）和 **IFEval**（指令跟随）任务上得分更高，这尤其令人印象深刻，因为它意味着增加视觉能力**并未牺牲**其语言核心能力。

#### 3. **优势领域：数学推理与代码能力**
- **数学推理**：在 **MATH** 数据集上取得了 **83.0** 的极高分数，与Qwen2.5-72B并列，大幅领先其他对比模型，凸显了其强大的逻辑与数学解题能力。
- **代码生成**：在 **HumanEval** 和 **MultiPL-E** 上的优秀表现，特别是MultiPL-E的 **79.5** 分在所有模型中最高，证明了其出色的编程与多语言代码生成能力。

**总结**：该评估强有力地表明，**Qwen2.5-VL-72B 并非一个“偏科”的视觉专家，而是一个在视觉和语言两大核心领域均达到顶尖水平的全能模型**。其在纯文本任务上媲美甚至超越顶级LLMs的表现，消除了对视觉语言模型可能削弱文本能力的顾虑，奠定了其作为下一代通用基础模型的地位。

## 6.2 - General Visual Question Answering

### 内容概括
本节通过在一系列广泛的基准数据集上进行测试，全面评估了 Qwen2.5-VL 在**通用视觉问答和对话**方面的能力。评估涵盖了通用VQA、主观评测、多语言场景及多图像理解等多个维度。结果显示，Qwen2.5-VL 在该领域实现了**最先进的性能**，其强大的**细节理解、推理和泛化能力**在不同规模、不同场景的模型版本上都得到了验证。

### 要点总结
从评估描述中可以总结出以下几个关键要点：

#### 1. **综合性能达到顶尖水平**
- 模型在**MMBench、MMStar、MME、MuirBench** 等涵盖不同侧重点的权威基准测试中均表现优异，综合性能处于行业领先地位。

#### 2. **核心能力的具体体现**
- **细节理解与推理**：在专注于视觉细节和推理的 **MMBench-EN-V1.1** 数据集上，Qwen2.5-VL-72B 取得了 **88.4%** 的准确率，超越了包括InternVL2.5和Claude-3.5 Sonnet在内的先前最优模型。
- **高分辨率真实场景适应**：在 **MME-RealWorld** 这种高分辨率真实世界图像基准上取得 **63.2** 分，证明了其处理复杂现实场景的强大适应力。
- **多图像理解**：在 **MuirBench** 多图像理解任务上获得 **70.7** 的领先分数，凸显了其整合和分析跨图像信息的高级泛化能力。

#### 3. **架构具有强大的可扩展性**
- 不仅旗舰模型强大，其**轻量级版本也极具竞争力**。例如，在MMStar数据集上，**Qwen2.5-VL-7B** 和 **Qwen2.5-VL-3B** 分别取得了 **63.9%** 和 **55.9%** 的分数。这表明其模型架构在参数规模缩减时仍能保持强大的性能，为不同计算资源需求的应用提供了高效选择。

**总结**：评估结果表明，Qwen2.5-VL 在通用视觉问答与对话任务上具备**全面而顶尖的能力**。无论是复杂的细节推理、真实的开放场景，还是需要跨图像分析的任务，它都表现出了卓越的性能。同时，其**性能在不同模型规模上的良好保持**，验证了该技术方案的有效性和可扩展性。

## 6.3 - Document Understanding and OCR

### 内容概括
1.  **第1张图（评估范围）**：列举了进行评估的一系列关键基准测试，涵盖了**OCR相关的解析、理解和综合任务**，包括AI2D（图表理解）、TextVQA（场景文本问答）、DocVQA（文档问答）、InfoVQA（信息图问答）、ChartQA（图表问答）、CharXiv（图表推理）以及专注于综合能力的OCRBench、OCRBench_v2等。
2.  **第2张图（性能结论与数据）**：结合表5的详细数据，总结了Qwen2.5-VL模型在上述评估中的**卓越表现**。其72B版本在多项任务中创下新记录，在综合基准上大幅领先顶级竞争对手，其轻量级版本（7B、3B）也表现出色。

### 要点总结
综合评估，Qwen2.5-VL在文档与OCR领域展现出了全面且领先的能力，核心要点如下：

#### 1. **旗舰模型创下多项新纪录**
- **解析任务**：凭借精心策划的训练数据和强大的语言模型能力，**Qwen2.5-VL-72B** 在专注于多场景、多语言、多元素（手写、表格、图表等）文档解析的**CC-OCR**和**OmniDocBench**基准上，均取得了**新的最先进水平**。
- **理解任务**：在图表、信息图、文档等各类OCR理解任务中表现优异。特别是在综合理解基准 **OCRBench** 上显著超越强劲对手 InternVL2.5-78B，并在需要复杂推理的**InfoVQA**（信息图）和**VCR**（视觉常识推理）等任务上也取得了**最优或接近最优的成绩**。

#### 2. **综合能力全面大幅领先**
- **性能大幅提升**：在涵盖广泛OCR解析与理解任务的**综合基准OCRBench_v2**上，Qwen2.5-VL-72B实现了对顶级闭源模型的**巨大优势**，在英文和中文赛道上分别大幅超越**Gemini-1.5-Pro 9.6%** 和 **20.6%**。

#### 3. **轻量级模型极具竞争力**
- 性能优势不仅限于最大模型。从表5数据可见，**Qwen2.5-VL-7B** 和 **Qwen2.5-VL-3B** 在几乎所有评估任务中都展现了强大且极具竞争力的性能，**全面超越或接近同等甚至更大规模的竞争对手**，为实际部署提供了高效的选项。

**总结**：Qwen2.5-VL在文档理解与OCR领域确立了**全面领先的地位**。这不仅体现在其旗舰模型在多个单项和综合基准上刷新记录，更体现在其技术方案的成功——能够将强大的语言模型能力与经过精心设计的视觉理解和数据训练有效结合，并将这一优势**有效下放至轻量化模型**，实现了性能与效率的完美平衡。

## 6.4 - Spatial Understanding

### 内容概括
本节系统评估了 **Qwen2.5-VL 在视觉定位方面的卓越性能**。视觉定位允许模型基于自然语言描述精确识别图像中的物体、区域或元素，这超越了传统的目标检测，建立了视觉内容与语言上下文之间的语义关系。评估涵盖了指代表达式理解、开放词汇目标检测、点定位以及计数等多个基准。结果显示，Qwen2.5-VL在与包括Gemini、Grounding-DINO在内的领先模型对比中，在各项任务上均取得了顶尖或极具竞争力的成绩。

### 要点总结
评估表明，Qwen2.5-VL在空间理解方面实现了全面而强大的能力，核心要点如下：

#### 1. **核心能力：语义化视觉定位**
- **定义**：模型的核心能力是**基于自然语言查询，在图像中进行精确的语义化定位**。这不仅是找到物体，更是理解语言所指与视觉元素之间的对应关系。
- **价值**：此能力是实现更细致、更具上下文感知的视觉推理的关键。

#### 2. **评估维度：全面覆盖定位任务**
模型在四个关键维度上接受了评估：
- **框定位**：在指代表达式理解基准上表现领先。
- **开放词汇目标检测**：在 **ODinW-13** 基准上取得 **43.1 mAP**，超越了大多数通用视觉语言模型，并正在快速缩小与专用检测模型的差距。
- **点定位**：解锁了基于点的精确定位能力，能够定位物体上难以用边界框表示的细微部分，这是一项重要的技术突破。
- **计数能力**：在 **CountBench** 基准上，**Qwen2.5-VL-72B** 使用“先检测再计数”的提示方式，取得了 **93.6** 的领先准确率。

#### 3. **综合性能：全面领先**
- **对比优势**：与 **Gemini、Grounding-DINO、Molmo、InternVL2.5** 等领先模型相比，Qwen2.5-VL 在从框定位、点定位到计数的不同基准上均展现了**领先的性能**。
- **技术突破**：通过同时装备**框定位和点定位**能力，模型能够理解、定位并推理图像中特定部分的细节。

**总结**：Qwen2.5-VL 在空间理解方面不仅实现了 **“全能”**（覆盖框、点、计数等多种定位任务），更在多项任务上达到了 **“顶尖”** 水平。其强大的开放词汇检测和创新的点定位能力，使其在理解和交互视觉世界细节方面迈出了重要一步，为开发更智能、更精确的视觉AI应用奠定了坚实基础。

## 6.5 - Video Understanding and Grounding

### 内容概括

1.  **第1张图（评估范围）**：说明了评估涵盖**多样化的视频理解与定位任务**，使用的基准测试视频长度跨度极大。并预告了表8将展示与顶级闭源模型的对比。
2.  **第2张图（补充说明与定位数据）**：该图片在展示空间理解（表6、表7）数据后，附有一段关键文字，进一步阐述了**Qwen2.5-VL-72B在长视频理解基准（LVBench, MLVU）上的卓越表现**，以及其**在时间定位任务（Charades-STA）上超越GPT-4o**的成果。这归功于其**同步的多模态旋转位置编码技术**。
3.  **第3张图（详细性能数据）**：即**表8**，详细列出了Qwen2.5-VL系列与Gemini 1.5-Pro、GPT-4o在十余个视频理解与定位基准上的量化分数对比，直观展示了模型的竞争优势。

### 要点总结

#### 1. **长视频理解能力突出**
- **显著优势**：在专门评估长视频理解的 **LVBench** 和 **MLVU** 基准上，**Qwen2.5-VL-72B** 取得了 **47.3** 和 **74.6** 的分数，**大幅领先于GPT-4o（30.8, 64.6）和Gemini 1.5-Pro（33.1）**。
- **技术支撑**：这一优势得益于其**同步的多模态旋转位置编码**，该技术增强了模型对时间敏感内容的理解，包括时间戳引用和时序定位。

#### 2. **时间定位精度达到新高度**
- **关键突破**：在评估精确时间定位能力的 **Charades-STA** 数据集上，Qwen2.5-VL-72B 取得了 **50.9** 的mIoU分数，**显著超越GPT-4o的35.7**，证明了其在视频中精确定位事件发生时间的能力。
- **全系列覆盖**：即使是轻量级的7B和3B模型，在该任务上也分别取得了 **43.6** 和 **38.8** 的优异成绩，展现了强大的技术下放能力。

#### 3. **综合视频理解性能全面领先**
- **多项第一**：根据表8，Qwen2.5-VL-72B在 **MVBench、MMBench-Video、EgoSchema、TempCompass** 等多个综合性或专业性视频理解基准上，均取得了**所有对比模型中的最高分**。
- **效率与性能平衡**：**Qwen2.5-VL-7B** 在多数任务上表现紧追顶级闭源模型，甚至在 **MVBench** 上超越了它们，为资源受限场景提供了顶级性能。

#### 4. **评估设置统一高效**
- 所有评估均将每段视频分析的**最大帧数限制在768帧**，**总视频token数不超过24,576**。这表明模型在**统一的、可管理的计算预算内**实现了上述卓越性能，体现了其处理效率。

**总结**：Qwen2.5-VL 的视频理解评估证实，其不仅在**通用视频问答**上表现优异，更在**长视频深度理解**和**毫秒级时间定位**这两个关键且富有挑战性的任务上建立了显著优势。这得益于其创新的时序位置编码技术，并使全系列模型（从72B到3B）都成为了高效、强大的视频理解工具。

## 6.6 - Agent

### 内容概括
本节评估了 **Qwen2.5-VL 作为智能体与真实世界设备（如手机、电脑）交互的能力**。评估涵盖多个维度：
1.  **基础定位能力**：在 **ScreenSpot** 和更复杂的 **ScreenSpot Pro** 基准上，测试模型理解和定位屏幕界面元素的能力。
2.  **离线任务评估**：在 **Android Control** 基准上，评估模型在模拟环境中执行离线任务的能力。
3.  **在线任务评估**：在 **AndroidWorld、MobileMiniWob++ 和 OSWorld** 平台上，评估模型在更真实、动态的在线环境中完成任务的能力。

评测将 **Qwen2.5-VL-72B** 与包括 GPT-4o、Gemini 2.0 在内的多个前沿模型进行了对比，详细结果见**表9**。

### 要点总结
从评估数据和结论分析看，Qwen2.5-VL-72B 展现出了卓越的智能体潜力，核心要点如下：

#### 1. **界面元素定位能力实现巨大飞跃**
- **基础任务**：在 ScreenSpot 基准上取得 **87.1%** 的准确率，与 Gemini 2.0 (84.0%) 和 Claude (83.0%) 性能相当，处于顶尖水平。
- **复杂任务**：在更具挑战性的 ScreenSpot Pro 基准上，以前代模型 **Qwen2-VL-72B 仅1.6%** 的表现为起点，实现了**突破性进展，达到43.6%**，不仅远超 Aguvis-72B (23.6%)，更为该基准**设立了新的性能标准**。这证明了其在复杂、真实屏幕理解上的巨大进步。

#### 2. **离线任务执行综合性能领先**
- 凭借强大的基础定位能力，Qwen2.5-VL-72B 在 **Android Control** 的离线评估中全面领先。
- 尤其在 **LowEM**（宽松匹配）设置下，以 **93.7%** 的成功率大幅超越所有基线模型，显示出极高的任务完成精度。

#### 3. **在线动态环境中展现实用潜力**
- 在线评估中，部分基线模型因定位能力有限，需要依赖**辅助标记**才能完成任务。
- **Qwen2.5-VL-72B 在无需任何辅助标记的情况下**，在 **AndroidWorld** 和 **MobileMiniWob++** 上超越了使用辅助标记的基线模型，并在 **OSWorld** 上取得了可比性能。
- 这一观察结果表明，**Qwen2.5-VL-72B 具备在真实、动态的交互环境中作为智能体独立运作的潜力**，而不仅仅是在受控的模拟环境中。

**总结**：Qwen2.5-VL-72B 在GUI智能体能力评估中表现突出，其**核心的屏幕理解与元素定位能力，特别是处理复杂场景的能力，取得了质的提升**。这使其不仅在标准离线测试中全面领先，更在无需外部辅助的在线环境中展现了作为实用智能体的强大实力，为开发能够与真实数字世界交互的AI助手奠定了坚实基础。

## 7 - Conclusion

### 内容概括
本章节是整份技术报告的总结，**全面概括了 Qwen2.5-VL 系列模型的核心贡献、关键特性与卓越性能**。报告指出，该系列模型在多模态理解与交互领域实现了显著进步，其增强的视觉识别、文档解析、长视频理解等能力，使其在动态与静态任务上均表现出色。通过原生动态分辨率处理、绝对时间编码与窗口注意力等技术，模型能够高效处理多样化的输入。旗舰模型性能比肩或超越业内顶尖模型，而较小的变体则在效率与多功能性上表现出色，为视觉语言模型树立了新的标杆。

### 要点总结
报告结论部分可归纳为以下四个核心要点：

#### 1. **模型定位：先进的多模态模型系列**
- Qwen2.5-VL 被定位为一个在**多模态理解与交互**方面取得显著进展的**先进视觉语言模型系列**。

#### 2. **核心技术：三大关键创新**
- **增强的核心能力**：在视觉识别、目标定位、文档解析和**长视频理解**等方面具备显著增强的能力。
- **高效的输入处理**：通过**原生动态分辨率处理**和**绝对时间编码**，能够鲁棒地处理多样化的视觉与时序输入。
- **优化的计算效率**：采用**窗口注意力**机制，在不牺牲分辨率保真度的前提下，降低了计算开销。

#### 3. **性能表现：全面领先且高效**
- **旗舰模型顶尖**：旗舰模型 **Qwen2.5-VL-72B** 在多项任务上**匹配或超越了 GPT-4o、Claude 3.5 Sonnet 等领先模型**，尤其在文档和图表理解方面表现突出，同时在纯文本任务上也保持强劲性能。
- **轻量模型高效**：较小的 **Qwen2.5-VL-7B 和 3B 变体** 在同类尺寸模型中表现出色，提供了优异的**效率与多功能性**。
- **广泛应用覆盖**：模型系列可服务于从边缘AI到高性能计算的广泛应用场景。

#### 4. **总体贡献：树立新标杆**
- Qwen2.5-VL 为视觉语言模型**设立了新的性能基准**，在跨领域任务中展现了**卓越的泛化与执行能力**。
- 其创新为开发**更智能、更具交互性的系统**铺平了道路，架起了感知与现实世界应用之间的桥梁。

