本文主要整理CS336 Lecture 7 Parallelism 章节的主要内容。

## 8 - Issues remain with data parallel

![Issues remain with data parallel – compute scaling](https://i-blog.csdnimg.cn/direct/3cf8dcf7503144caa5359f85a53e5ff4.png)
![Issues remain with data parallel – models don’t fit](https://i-blog.csdnimg.cn/direct/a4ba07e67d13436fbe2b1bf8116a514c.png)

这两张图从 **计算扩展（Compute Scaling）** 和 **内存适配（Model Fitting）** 两个维度，深刻地揭示了**纯数据并行策略（Naïve Data Parallelism）** 在训练超大规模模型时遇到的根本性瓶颈。

---

### 内容概括

1.  **第一张图：计算扩展的效率瓶颈**
    *   **核心问题**：即使通信开销（如ZeRO）可以优化，数据并行在**计算扩展**上也存在理论极限。
    *   **关键发现**：随着批量大小（Batch Size）和机器（GPU）数量的增加，训练速度的提升会出现**边际效益递减（Diminishing Returns）**，无法实现理想的线性加速。

2.  **第二张图：内存与效率的实践瓶颈**
    *   **核心问题**：即使采用ZeRO-3（FSDP）这样的内存优化技术，在实践中依然面临**性能下降**和**激活内存**的新问题。
    *   **关键发现**：纯数据并行在超大规模集群上扩展时，计算效率（TFLOP/s）会显著下降，表明需要引入**模型并行（Model Parallelism）** 等更高级的并行策略。

---

### 要点总结

#### 1. 瓶颈一：计算扩展的边际效益递减（第一张图）

*   **“完美扩展”不存在**：图中“Perfect scaling”曲线是一种理想情况，现实中无法达到。随着批量尺寸（B）增大（对应横轴），为了达到最佳优化效果所需的有效计算量（纵轴 $\epsilon_{opt}(B) / \epsilon_{max}$）的回报越来越低。
*   **核心限制**：
    *   **机器数 < 批量大小**：GPU数量的上限受限于批量大小。当GPU数量接近批量大小时，每个GPU分到的数据样本极少，使得通信开销（同步梯度）占总时间的比例过高，效率急剧下降。
    *   **批量大小的收益递减**：单纯增加批量大小并不能一直换来训练速度的线性提升。过大的批量甚至会损害模型的优化效果和泛化能力。
*   **结论**：纯数据并行在计算扩展上存在**天然的天花板**，无法通过无限增加GPU数量来无限加速训练。

#### 2. 瓶颈二：内存与效率的实践挑战（第二张图）

该图对比了两种并行策略在超大规模集群上的性能：
*   **ZeRO-3 (FSDP)**：一种**纯数据并行**的极致优化（分片一切）。
*   **PTD-P (Pipeline Tensor Parallelism)**：一种**混合并行**策略，结合了**流水线并行（Pipeline）** 和**张量并行（Tensor Parallelism）**。

*   **ZeRO-3的缺陷**：
    1.  **Stage 1 & 2 内存扩展不足**：它们无法分片模型参数本身，对于超大模型（如175B/530B），内存仍然是瓶颈。
    2.  **Stage 3 的性能与激活内存问题**：
        *   **速度慢**：虽然解决了参数内存，但其依赖频繁的`All-Gather`/`Reduce-Scatter`通信，在节点数非常多时（横轴GPU数从768到1920），**通信开销巨大**，导致每个GPU的实际算力利用率（TFLOP/s）显著下降（曲线暴跌）。
        *   **不减少激活内存**：在前向传播中计算的**激活（Activations）** 仍然需要完整地存储在每个GPU上，这对于深层大模型来说也是一笔巨大的内存开销，ZeRO-3对此无能为力。

*   **混合并行的优势**：
    *   图中“PTD-P”代表的混合并行策略，其性能曲线下降平缓，在大规模下显著优于ZeRO-3。
    *   这表明，**将模型本身（而不仅仅是数据）拆分到多个GPU上**的并行策略（模型并行），在超大规模训练中比纯数据并行更具可扩展性。

### 总结

这两张图共同指向一个结论：**纯数据并行（即使是ZeRO-3）不再是训练超大规模模型的“银弹”**。

1.  **在计算上**，它受限于扩展的边际效益递减。
2.  **在内存和效率上**，它在超大规模集群上面临通信瓶颈和激活内存问题。

因此，业界普遍采用 **“混合并行”** 方案，即**同时采用数据并行、张量并行和流水线并行**，根据模型和集群的特点灵活组合，以在内存、计算和通信之间取得最佳平衡。这正是第二张图底部所指的“Better ways to split up the model”（更好的模型拆分方式）。

## 9 - model parallelism

![model parallelism](https://i-blog.csdnimg.cn/direct/9c9878d8e49f412e993f62353a67c6e9.png)
![Layer-wise parallel](https://i-blog.csdnimg.cn/direct/2f39f3c5fbfc498fb4942512e1d901aa.png)
![What’s wrong with layer-wise parallel](https://i-blog.csdnimg.cn/direct/7c454ced6455442f9f3028d565bb13e5.png)

### 内容概括

这三张图是一个连贯的叙事，清晰地阐述了一种并行策略的“是什么”、“为什么”和“怎么办（不好）”。

1.  **第一张图：模型并行导论（The "What"）**
    *   引入了“模型并行”的概念，作为超越“数据并行”的、用于解决内存瓶颈的更高级策略。它明确了模型并行的核心是**拆分模型参数**，并预告了两种实现方式。

2.  **第二张图：层间并行原理（The "How"）**
    *   详细展示了第一种模型并行策略——**层间并行**（也称为**流水线并行，Pipeline Parallelism**）的工作原理。它通过将模型的不同层分配到不同的GPU上，通过传递激活值和梯度来实现并行。

3.  **第三张图：层间并行缺陷（The "Why Not"）**
    *   尖锐地指出了层间并行策略的最大问题：**极低的设备利用率（Utilization）**。并通过时间序列图直观地展示了其缺陷成因。

---

### 要点总结

#### 1. 核心思想：模型并行 (Model Parallelism)
*   **目标**：在不改变批量大小（Batch Size）的前提下，**扩展内存容量**，以训练更大的模型。
*   **方法**：不再将整个模型复制到每个GPU上（数据并行），而是**将模型本身（参数）拆分**到多个GPU上。每个GPU只保存和计算模型的一部分。
*   **与ZeRO-3的区别**：ZeRO-3（FSDP）也拆分参数，但它是**动态地**在需要时通过通信（All-Gather）获取参数，用完即弃。而模型并行是**静态地**将模型的一部分固定分配给某个GPU，计算时需要**传递激活值（Activations）**。

#### 2. 策略一：层间/流水线并行 (Layer-wise / Pipeline Parallel)
*   **工作原理**：如第二张图所示，**按模型的层（Layer）进行纵向切割**。
    *   将模型的前几层（如Layer 0）分配给GPU 0，中间几层（Layer 1）分配给GPU 1，最后几层（Layer 3）分配给GPU 3。
    *   **前向传播**：数据从GPU 0（Layer 0）开始计算，产生的激活值传递给GPU 1（Layer 1）作为输入，依次类推，直到最后。
    *   **反向传播**：梯度从最后一层（GPU 3）开始计算，产生的梯度反向传递给前一层（GPU 2），依次类推，直到最前。

#### 3. 致命缺陷：极低的设备利用率 (Terrible Utilization)
这是第三张图的核心内容，也是层间并行最严重的问题。
*   **“气泡”（Bubble）问题**：在训练的任何时刻，**只有一个GPU在工作，其他GPU都在空闲等待**。
    *   **前向传播时**：只有GPU 0先工作，计算完后GPU 1开始工作，此时GPU 0、2、3都在空闲。
    *   **反向传播时**：只有GPU 3先工作，计算完后GPU 2开始工作，此时GPU 0、1、3都在空闲。
*   **量化损失**：如图中公式所示，在有 `n` 个GPU的情况下，**每个GPU的平均利用率只有 `1/n`**。例如，使用4个GPU并行，理论上的加速比是4倍，但实际由于大部分时间都在等待，可能只能达到2倍左右的加速，效率极低。

### 总结与启示

这三张图解释了为什么单纯的层间并行（流水线并行）在实践中很少单独使用：
*   **它解决了内存问题**：允许将超大模型拆开到多个设备上。
*   **但它引入了严重的效率问题**：造成了大量的计算资源空闲和浪费。

因此，现代的解决方案是：
1.  **引入微批次（Micro-batching）**：将一个大批次分成多个微批次，像流水线一样填入不同的GPU，从而减少“气泡”，提高利用率。
2.  **采用混合并行（Hybrid Parallelism）**：**结合使用数据并行、流水线并行和张量并行**。例如，在节点内使用更高效的张量并行，在节点间使用流水线并行，同时使用数据并行来复制多个这样的流水线。这种组合方式才能在内存、计算和通信效率之间找到最佳平衡，用于训练当今的超大规模模型。

## 10 - Pipeline parallel

![A solution: pipeline parallel](https://i-blog.csdnimg.cn/direct/c7e760027bc849b0bf429ec21037851d.png)
![Why pipeline parallel?](https://i-blog.csdnimg.cn/direct/fe644715c9d04973b7dc835fd944c3c4.png)
![Pipeline performance is highly dependent on batch size](https://i-blog.csdnimg.cn/direct/4249f739e6934d2790421c32f130beee.png)
![Trading communication bandwidth for utilization](https://i-blog.csdnimg.cn/direct/c868976960aa43f397c00aab7a0ae2ba.png)
![‘Zero bubble’ pipelining](https://i-blog.csdnimg.cn/direct/aa45f3fbe527433893e2b282d9bb433c.png)

### 内容概括

这五张图层层递进，完整揭示了流水线并行的全貌：

1.  **第一张图：基础方案与核心问题**
    *   提出了用**微批次（Micro-batches）** 填充的流水线并行方案，作为解决纯层间并行利用率低下的方法，并首次量化了其固有的 **“气泡”（Bubble）** 开销。

2.  **第二张图：存在价值与独特优势**
    *   回答了“为何要使用一个有缺陷的方案”这一核心问题，从**内存**和**通信**两个角度，阐述了流水线并行相比其他策略的不可替代性。

3.  **第三张图：性能表现与关键制约**
    *   通过性能数据图表，揭示了流水线并行性能的**决定性因素**——批次大小（Batch Size），并直观展示了其在不同规模下的性能表现。

4.  **第四张图：优化方向与设计权衡**
    *   指出了进一步的优化方向：通过设计更复杂的调度模式，可以用**额外的通信带宽为代价，换取更高的设备利用率**。

5.  **第五张图：高级优化与终极目标**
    *   展示了一种逼近理论极限的高级优化思想——**“零气泡”（Zero Bubble）流水线**，其核心是通过解耦计算任务，实现计算资源的极致利用。

---

### 要点总结

#### 1. 核心方案：流水线并行与微批次 (Pipeline Parallelism with Micro-batches)
*   **方法**：将一个大训练批次（Batch）拆分成许多**微批次（Micro-batches）**，并连续注入到由多个GPU组成的处理序列中（每个GPU负责模型的一部分）。
*   **目标**：让不同的GPU同时处理不同微批次的任务（如GPU0计算微批次2的前向，而GPU1计算微批次1的前向），从而**减少GPU的空闲等待时间（“气泡”）**，提高整体利用率。
*   **固有开销**：气泡时间与有效计算时间的比率为 `(n_stages - 1) / n_micro`。此公式表明，要降低气泡占比，**必须使用大的批次大小（Big Batch Size）** 来获得足够多的微批次。

#### 2. 存在价值：为何流水线并行不可替代？
尽管有气泡问题，但流水线并行在分布式训练中占据关键地位，因其两大优势：
1.  **内存效率高（Memory Efficient）**：与数据并行（DDP）每个GPU都存储完整模型副本相比，流水线并行每个GPU只存储模型的若干层，**极大降低了内存开销**。
2.  **通信友好（Communication Efficient）**：与ZeRO-3（FSDP）需要全局通信（All-Gather/Reduce-Scatter）相比，流水线并行是**点对点（Point-to-Point）** 通信，只传递激活值（Activation，尺寸为 `b * s * h`），**对网络带宽要求更低、延迟更小**。
*   **结论**：因此，流水线并行非常适合在**网络速度较慢的节点间（inter-node）** 使用，是扩展模型内存容量的重要手段。

#### 3. 性能关键：批次大小是成败之手
*   第三张图的性能数据清晰表明：**批次大小（Batch Size）是决定流水线并行性能的唯一最关键因素**。
*   **大批次（如128）**：微批次数量多，能有效填充流水线，掩盖通信和依赖延迟，性能曲线随规模扩大**下降平缓**。
*   **小批次（如8）**：微批次数量少，无法隐藏气泡，性能随规模扩大**急剧下降**。
*   **实践指导**：必须使用**大批次训练**才能发挥流水线并行的价值，否则其性能甚至不如单卡训练。

#### 4. 优化方向：带宽与利用率的经典权衡
*   **设计哲学**：如第四张图标题所示——**“用通信带宽换取利用率”（Trading communication bandwidth for utilization）**。
*   **方法**：设计更复杂、更激进的流水线调度模式（如1F1B及其变体），通过增加额外的通信次数（如下半部分时间轴的任务更密集），让GPU更加“忙碌”，从而进一步挤压气泡，提高利用率。
*   **代价**：更高的利用率来自于更精细的任务调度和更频繁的通信，这会**消耗更多的通信带宽**。

#### 5. 高级演进：迈向“零气泡”流水线
*   **终极目标**：最大化设备利用率，理想状态是**“零气泡”（Zero Bubble）**，即所有GPU在任何时刻都在进行有效计算。
*   **实现思路**：如第五张图所示，将计算任务进一步**拆解和解耦**。例如，将反向传播拆分为：
    1.  反向传播激活值（计算量大，依赖性强）
    2.  计算权重梯度（计算量相对小，可延迟执行）
*   通过灵活调度这些被解耦的任务，可以像拼图一样填满所有空闲时间隙，逼近零气泡的理想状态。图中的 ZB-H1 和 ZB-H2 模式就是这种思路的手工设计范例。

### 总结

这五张图揭示了流水线并行是一种在**内存、通信、计算效率**之间进行精密权衡的分布式训练策略。它不是完美的，但其在**横向扩展模型大小**方面的独特优势，使其成为构建万卡乃至十万卡超大规模AI集群的**核心基础架构**之一。现代大模型训练通常将其与数据并行、张量并行结合，形成混合并行方案，以应对不同的挑战。

## 11 - Tensor parallel

![Model parallel along the width axes](https://i-blog.csdnimg.cn/direct/945840a899864bb497af4c0aa0d52357.png)
![Tensor parallel – GPUs have submatrices](https://i-blog.csdnimg.cn/direct/455a252e4d7d42b3a0b4cf7fe11a6c7e.png)
![When do we tensor parallel?](https://i-blog.csdnimg.cn/direct/94bbc2b4be0b4804b2ab0ef968730bde.png)
![Tensor parallel – pros and cons vs pipeline parallel](https://i-blog.csdnimg.cn/direct/bd44319ff0394af58c2d969a7404b2c0.png)

### 内容概括

这四张图从概念到实践，完整阐述了张量并行这一关键的模型并行策略：

1.  **第一张图：核心思想与启发（The "Idea"）**
    *   提出了不同于流水线并行（沿模型深度切割）的新思路：**沿模型宽度方向（Width）** 进行模型并行，并指出其理论基础源于简单的矩阵乘法分解。

2.  **第二张图：工作原理与流程（The "How"）**
    *   具体展示了张量并行在一个计算模块（如前馈层FFN）中的工作流程，详细说明了在前向传播和反向传播中，计算如何分解、通信如何协同。

3.  **第三张图：性能表现与适用场景（The "Performance"）**
    *   通过性能数据图表，揭示了张量并行的扩展性规律及其最佳适用场景——在**高速互联的单个节点内**使用。

4.  **第四张图：优劣对比与总结（The "Trade-off"）**
    *   系统性地对比了张量并行与流水线并行的优缺点，并给出了明确的实践指导：根据硬件互联条件选择并行策略。

---

### 要点总结

#### 1. 核心思想：分解矩阵运算
*   **方向**：与流水线并行**纵向切分（按层）** 不同，张量并行是**横向切分**。它将**单个层（Layer）** 内部的参数矩阵（如Linear层的权重矩阵）**按行或按列分割**到不同的GPU上。
*   **理论基础**：基于矩阵乘法的结合律。例如，计算 `Y = X * A` 时，可以将矩阵A按列分成`[A1, A2]`，分配到两个GPU上分别计算 `X * A1` 和 `X * A2`，再将两个部分结果（Partial Sums）拼接或相加，得到最终结果Y。
*   **目标**：让所有参与并行的GPU**同时计算**一个层的不同部分，从根本上避免流水线并行中的“气泡”等待问题。

#### 2. 工作流程：All-Reduce 是关键
第二张图以一个包含两个线性层和GeLU激活函数的模块为例，展示了张量并行的工作流程：
*   **前向传播（Forward）**：
    1.  **并行计算**：GPU0计算 `Y1 = X * A1`，GPU1计算 `Y2 = X * A2`。
    2.  **同步汇总**：通过 **All-Reduce（求和）** 操作将Y1和Y2相加，得到完整的 `Y = Y1 + Y2`，供下一层使用。
    3.  后续计算（如GeLU）在各GPU上独立完成。
*   **反向传播（Backward）**：
    1.  反向传播梯度时，在需要同步的点同样通过 **All-Reduce** 操作来聚合梯度。
*   **通信模式**：其核心通信模式是**每层一次All-Reduce**。

#### 3. 性能与适用场景：依赖高速互联
第三张图的性能数据揭示了张量并行的关键特性：
*   **性能趋势**：随着TP维度（GPU数量）增加，**每个GPU的吞吐量（Tokens/sec/GPU）会下降**。图中显示，TP=4时性能下降约11%，TP=8时下降约12%，但TP=32时性能暴跌约66%。
*   **根本原因**：虽然计算被完美并行化了，但**每层一次的All-Reduce通信开销**随着GPU数量增加而变大。
*   **最佳场景**：因此，张量并行必须运行在**具有高速互联**的环境中，以最小化通信开销。如图中标题所述：**“在GPU上，由于有高速互联，张量并行 within a node (最多8个GPU)”** 。它非常适合在NVLink/NVSwitch连接的单个服务器内使用。

#### 4. 与流水线并行的对比：权衡的艺术
第四张图进行了精辟的总结：

| 对比维度 | **张量并行 (Tensor Parallelism)** | **流水线并行 (Pipeline Parallelism)** |
| :--- | :--- | :--- |
| **利用率** | **高 (No Bubble)** <br>无空闲等待，所有GPU持续计算。 | **低 (Has Bubble)** <br>存在空闲等待，利用率天然有损耗。 |
| **通信量** | **大** <br>**每层**都需要一次All-Reduce，通信量大。 | **小** <br>只在**层间**传递激活值（Activation），通信量小。 |
| **通信模式** | **集体通信 (All-Reduce)** <br>依赖高带宽、低延迟网络。 | **点对点通信 (P2P)** <br>对网络延迟和带宽要求相对较低。 |
| **使用难度** | **低** <br>模型代码改造较小，易于封装。 | **高** <br>需要复杂的调度策略来优化气泡。 |
| **批次大小** | **无要求** <br>性能不依赖于大批次。 | **强依赖** <br>必须使用大批次才能有效隐藏气泡。 |
| **适用场景** | **节点内（高速互联）** <br>如单台服务器内的8个GPU。 | **节点间（低速互联）** <br>如通过以太网连接的多个服务器。 |

### 总结与核心结论

这四张图共同指向一个清晰的结论：**不存在完美的并行策略，只有最适合的权衡（Trade-off）**。

*   **张量并行**用**更大的通信量**换取了**更高的设备利用率（无气泡）** 和**更简单的使用方式**。
*   **流水线并行**用**更低的设备利用率（有气泡）** 换取了**更小的通信量**和**对低速网络的友好性**。

因此，现代大规模模型训练普遍采用 **混合并行（Hybrid Parallelism）**：
*   在**节点内**（高速NVLink环境），使用**张量并行**来高效利用8个GPU。
*   在**节点间**（相对低速的InfiniBand/以太网环境），使用**流水线并行**来扩展模型层数。
*   同时，在以上基础上，再叠加**数据并行**来扩展微批次的数量。

## 12 - activation memory

![A final complexity – memory is dynamic!](https://i-blog.csdnimg.cn/direct/b0e8b7387d8c41a9892e1e51f7eb585c.png)
![What’s the activation memory per layer?](https://i-blog.csdnimg.cn/direct/49a1e23e68314078b2ad2911aeece7bb.png)
![Activation under tensor parallel](https://i-blog.csdnimg.cn/direct/a3f5120f45c044579c3118e6f1640be4.png)


### 内容概括

这四张图系统性地揭示了超越静态参数存储的、经常被忽视的动态内存消耗源——激活内存，并提供了定量的分析方法和优化思路。

1.  **第一张图：问题提出（The "Problem"）**
    *   指出内存消耗是**动态变化**的，而不仅仅是存储静态的模型参数和优化器状态。**激活值（Activations）** 在前向传播过程中产生，并在反向传播中被使用，其内存占用可能非常巨大。

2.  **第二张图：问题严重性（The "Scale"）**
    *   通过柱状图量化对比了在不同规模的模型（22B, 175B, 530B, 1T）下，**激活内存（绿色部分）** 与参数/优化器状态内存（蓝色部分）的对比。结果显示，对于超大模型，激活内存是一个与参数内存同等量级甚至更主要的开销。

3.  **第三张图：理论分析（The "Theory"）**
    *   给出了在**未进行任何优化**的情况下，Transformer模型**单层**激活内存占用的精确计算公式，并拆分了公式中各项的来源，同时指出了主要的优化方向。

4.  **第四张图：并行优化（The "Optimization"）**
    *   展示了在引入了**张量并行（Tensor Parallelism）** 后，激活内存计算公式发生的变化，量化了并行化带来的内存收益，并指出了剩余的内存瓶颈。

---

### 要点总结

#### 1. 核心问题：激活内存是动态且巨大的开销
*   **激活值（Activations）**：是前向传播过程中，每个计算层的中间计算结果。为了在反向传播中计算梯度，这些中间结果必须保存在内存中。
*   **动态性**：如第一张图所示，内存使用峰值会出现在前向传播完成、反向传播开始前的那一刻，此时所有中间激活值都驻留在内存中。
*   **严重性**：第二张图表明，对于175B参数以上的模型，激活内存（绿色）与参数+优化器状态内存（蓝色）的规模**处于同一数量级**，是训练超大模型时必须考虑的核心瓶颈。

#### 2. 激活内存的定量计算
第三张和第四张图提供了精确的计算公式：

*   **基础公式（无并行）**：
    `Activations memory per layer = s * b * h * (34 + 5 * a * s / h)`
    *   `s`: 序列长度 (sequence length)
    *   `b`: 微批次大小 (microbatch size)
    *   `h`: 隐藏层维度 (hidden dimension)
    *   `a`: 注意力头数 (number of attention heads)
*   **公式解读**：
    *   **`5 * a * s / h` 项**：来源于注意力机制中的**二次项**（如QK^T矩阵），其大小与序列长度`s`的平方相关，是内存增长的主要瓶颈。
    *   **常数项（34或10）**：来源于层归一化 (LayerNorm)、Dropout、以及输入到注意力/MLP层的输入等。这些项与模型规模（`s, b, h`）线性相关。

*   **张量并行下的公式**：
    `Activations memory per layer = s * b * h * (10 + 24/t + 5 * a * s / (h * t))`
    *   `t`: 张量并行大小 (tensor parallel size)
    *   **解读**：张量并行（`t > 1`）可以**线性减少**注意力二次项的内存（除以`t`），但**常数项部分减少有限**。因此，常数项代表的线性部分成为新的主要瓶颈。

#### 3. 核心优化方向
*   **重计算（Recomputation）**：也称为梯度检查点（Gradient Checkpointing）。这是最主流的优化方法，如第三张图所述：“**we can drop this term via recomputation**”。策略是：在前向传播时**不保存**那些计算量巨大的中间结果（尤其是注意力二次项），在反向传播需要时**重新计算**它们。这是一种**用计算时间换内存空间**的经典权衡。
*   **模型并行**：
    *   **张量并行（Tensor Parallelism）**：如第四张图所示，可以**线性降低**注意力机制带来的激活内存开销（公式中的`/t`）。
    *   **流水线并行（Pipeline Parallelism）**：通过将模型分到多个设备上，每个设备只存储部分层的激活值，从而减少单个设备的峰值内存压力。
*   **专用优化算法**：如 **Flash Attention**。其核心思想是通过重构计算顺序，避免实例化巨大的中间注意力矩阵，从而从根本上消除二次项的内存峰值。

### 总结

这四张图揭示了在训练超大Transformer模型时的一个关键洞察：
**最终的内存瓶颈可能不再是静态的模型参数（Parameters）和优化器状态（Optimizer States），而是动态产生的激活内存（Activations）。**

*   **激活内存**与**批量大小（b）** 和**序列长度（s）** 直接相关，尤其后者会带来二次方增长。
*   必须采用**重计算（Recomputation）** 和**模型并行（Model Parallelism）** 等高级优化技术来管理激活内存，否则将无法训练超大模型。
*   张量并行等策略虽然有效，但主要优化的是计算密集型部分（注意力机制），而像层归一化等操作带来的线性开销依然存在，并可能成为新的瓶颈。

理解并优化激活内存，是成功进行大规模深度学习训练的一项至关重要的工程挑战。

## 13 - sequence parallel

![Making memory truly linear – sequence parallel](https://i-blog.csdnimg.cn/direct/0ea9f285336146888755eedd310c80eb.png)
![Making activation memory fully scale with more machines](https://i-blog.csdnimg.cn/direct/b4ae5e73e123457a81226a14432c0c10.png)

### 内容概括

这两张图是一个完整的“问题-解决方案-效果”叙事：

1.  **第一张图：解决方案的原理（The "How"）**
    *   针对之前分析中无法通过张量并行优化的“10”项内存瓶颈，提出了**序列并行（Sequence Parallelism）** 的创新思想。它通过沿**序列维度（Sequence Dimension, `s`）** 对模型进行切割，来分摊那些“不可并行”的操作所产生的内存开销。

2.  **第二张图：方案的最终效果（The "Result"）**
    *   通过一个清晰的对比表格，量化了从“无并行”到“组合优化”等多种配置下，每层Transformer的激活内存占用公式。最终证明，**结合张量并行、序列并行和选择性重计算**，可以实现激活内存随GPU数量（`t`）**完美线性下降**的理想效果。

---

### 要点总结

#### 1. 核心洞察与新技术：序列并行 (Sequence Parallelism)

第一张图的核心是提出了一个关键观察（Observation）并给出了解决方案：

*   **洞察**：此前无法被张量并行优化的“10”项内存开销（来自LayerNorm, Dropout等），其对应的操作都是**序列上的逐点操作（pointwise ops over the sequence）**。这意味着，这些操作对序列中每个token的处理是相互独立的。
*   **解决方案**：因此，可以**沿着序列轴（s-axis）** 来拆分这些层（如LayerNorm、Dropout层），而不仅仅是沿着隐藏维度（h-axis）进行张量并行。这就是**序列并行**。
*   **工作流程**：
    *   **前向传播**：使用 **All-Gather（‘g’）** 操作来收集所有GPU上的序列碎片，以完成计算。
    *   **反向传播**：使用 **Reduce-Scatter** 操作来聚合梯度。
    *   它与张量并行交替进行，共同分担计算和内存压力。

#### 2. 组合优化与完美缩放 (The Perfect Scaling)

第二张图的表格展示了不同技术组合带来的内存收益，其演进路径和最终结果非常清晰：

| 配置 | 激活内存公式 | 解读与意义 |
| :--- | :--- | :--- |
| **1. 无并行** | `sbh(34 + 5as/h)` | **基线**。内存占用巨大，尤其是与序列长度平方相关的项（`5as/h`）。 |
| **2. 张量并行 (基线)** | `sbh(10 + 24/t + 5as/ht)` | **解决了计算部分**。通过`/t`优化了“24”和二次项，但**留下了“10”的瓶颈**。 |
| **3. 张量 + 序列并行** | `sbh(34/t + 5as/ht)` | **重大突破**。序列并行成功地将“10”也分摊掉了！现在常数项“34”整体下降了`t`倍。 |
| **4. 张量并行 + 选择性重计算** | `sbh(10 + 24/t)` | **另一种思路**。通过重计算（Recomputation）**直接舍弃**了昂贵的二次项（`5as/ht`），但“10”的瓶颈仍在。 |
| **5. 三者结合** | **`sbh(34/t)`** | **终极方案**。结合了**张量并行**（分摊计算内存）、**序列并行**（分摊不可并行内存）和**选择性重计算**（消除二次项内存）。 |

#### 3. 最终结论：线性缩放实现

*   **终极公式 `sbh(34/t)` 的意义**：
    1.  **完美线性缩放**：内存占用与并行设备数量 `t` **成反比**。GPU数量翻倍，内存占用就减半。这是分布式系统追求的理想状态。
    2.  **瓶颈消除**：公式中不再有不受 `t` 影响的常数项（如“10”），也没有了可怕的二次项（`s²`）。剩下的只是一个与模型配置（`s, b, h`）和模型结构（“34”）相关的项，它可以被完美地分摊到所有设备上。
    3.  **工程上的胜利**：这表明通过精巧的模型切分和内存管理策略，**理论上可以训练无限大的模型**，只要拥有足够多的计算设备。它打破了“内存墙”的绝对限制，将其转变为“可通过增加设备来缓解”的可扩展性问题。

### 总结

这两张图展示了深度学习分布式训练优化的巅峰之作：

1.  **序列并行** 是对 **张量并行** 的完美补充，它通过挖掘模型结构中新的并行维度（序列维），解决了此前无法优化的内存瓶颈。
2.  **没有单一的神技**：训练万亿参数模型需要**组合拳**——结合**张量并行**、**序列并行**和**选择性激活重计算**，才能达到最优的内存缩放效果。
3.  **最终目标达成**：通过这种极致的优化，激活内存的占用实现了**随GPU数量增加而线性下降**（`O(1/t)`），这使得大规模扩展模型训练成为可能。这正是当前训练千亿乃至万亿参数大模型所依赖的核心技术栈。

## 14 - Recap: LLM parallelism table

![Recap: LLM parallelism table](https://i-blog.csdnimg.cn/direct/2f59fce2596a4384b8f181ad7865a692.png)

## 15 - Model vs Tensor parallel 

![Model vs Tensor parallel (TPU book)](https://i-blog.csdnimg.cn/direct/8df8184716cb4afda365c921e4d8f5ad.png)
![‘3D parallelism’ – putting it all together](https://i-blog.csdnimg.cn/direct/307f5ee7f2fe4a1e84259559118b4d97.png)
![Scaling strategies from Narayanan 2021](https://i-blog.csdnimg.cn/direct/452bdd0a48e54de0a6a2edd4ac75ae70.png)

### 内容概括

这六张图构成了一个完整的叙事，从理论到实践，从组件到系统：

1.  **图1 & 图2：核心思想与策略组合 (The "What & How")**
    *   图1（TPU视角）和图2（GPU视角）共同引入了**混合并行（Hybrid Parallelism）** 的概念。它们指出，没有单一的完美并行策略，必须根据硬件约束（内存、带宽）和模型规模，将**数据并行（DP/FSDP）、张量并行（TP/MP）、流水线并行（PP）** 组合使用。

2.  **图3 & 图5：实战策略与配置调优 (The "Strategy in Practice")**
    *   图3（Narayanan 2021）和图5（Tensor Parallel=8）提供了从真实大规模训练中总结出的**经验法则**和**配置指南**。它们量化了不同规模模型应如何配置并行维度，并指出张量并行大小通常优化为8。

3.  **图4 & 图6：性能验证与高级优化 (The "Proof & Advanced Tricks")**
    *   图4（线性增益）和图6（激活重计算）展示了混合并行策略的**有效性**和为了进一步提升其效率所需的**高级优化技术**。图4证明了混合并行可以近乎线性地提升算力，图6展示了如何用“计算换内存”来突破批次大小限制。

---

### 要点总结

#### 1. 核心思想：混合并行（Hybrid Parallelism）是必由之路
*   **单一策略的局限性**：
    *   **纯数据并行（DP/FSDP）**：内存开销大，通信量大。
    *   **纯模型并行（张量TP/流水线PP）**：存在计算“气泡”，设备利用率低。
*   **解决方案**：必须采用 **“3D并行”** （图2），即同时使用：
    *   **张量并行（TP）**：在**单个服务器节点内**（高速NVLink互联），沿模型宽度（如Transformer的FFN层或注意力头）拆分模型。**这是减少单卡内存压力的首选和最有效方法**（图5）。
    *   **流水线并行（PP）**：在**节点间**（相对低速的InfiniBand/以太网），沿模型深度（层数）拆分模型。用于扩展模型规模。
    *   **数据并行（DP）**：在以上基础上，复制多个相同的模型副本，用于处理不同的数据子集。用于扩展批量大小。
*   **工作流程**：如图2所示，一个训练批次的数据先在**数据并行组**间拆分，然后在**流水线并行组**的各个阶段间传递，每个阶段的计算又在**张量并行组**内协同完成。

#### 2. 实战策略：张量优先，流水线补充，数据扩展
*   **黄金法则**（来自图2和图3）：
    1.  **首先让模型拟合**：使用**张量并行（TP）** 在一台机器内（最多8个GPU）尽可能压缩内存占用。若仍放不下，则使用**流水线并行（PP）** 跨多台机器拆分层数。
    2.  **然后扩展算力**：在模型能放下后，使用**数据并行（DP）** 来增加GPU数量，以提升吞吐量。
*   **最优配置**（来自图3和图5）：
    *   **张量并行大小（TP size）通常设置为8**（即单机8卡）。这是NVLink带宽和计算效率之间的最佳平衡点（图5）。
    *   随着模型规模增大，优先增加PP维度，而DP维度会逐渐减小（图3图表）。

#### 3. 性能与优化：线性增益与内存交换
*   **有效性验证**：图4证明，精心设计的混合并行策略（PTD-P）可以实现在数千个GPU上**近乎线性的性能缩放**（每GPU吞吐量保持稳定），而纯通信优化方案（ZeRO-3）的性能会随着GPU数量增加而下降。
*   **高级技巧：激活重计算（Activation Recomputation）**：
    *   **问题**：训练过程中的中间计算结果（激活值）占用大量内存，限制了批量大小（Batch Size）。
    *   **解决方案**：如图6所示，**激活重计算**（或梯度检查点）策略选择不保存某些大型中间结果，在反向传播需要时重新计算它们。
    *   **收益**：这是一种经典的 **“以计算时间换取内存空间”** 的权衡。虽然增加了约20%的计算开销，但能支持**大得多的批量大小**，从而显著提升**整体吞吐量**（Throughput）。如图6，蓝色线（启用重计算）的吞吐量始终高于橙色线（未启用）。

#### 4. 关键权衡：计算、内存、通信的三角制约
所有策略都围绕三大资源的权衡：
*   **内存（Memory）**：TP和PP的核心目标是减少单卡内存压力。
*   **通信（Communication）**：DP和All-Reduce操作带来大量通信，需要高速带宽。
*   **计算（Computation）**：PP会引入气泡，激活重计算会增加计算量。
*   **成功的关键**在于根据硬件条件（机器内高速互联、机器间低速互联）和模型规模，找到这三者的最佳平衡点。

### 总结

这六张图描绘了一幅清晰的蓝图：要训练千亿乃至万亿参数的大模型，必须摒弃单一并行策略的思维，转而采用**以张量并行为核心、流水线并行为补充、数据并行为扩展**的混合并行方案，并辅以**激活重计算**等高级优化技术，最终在**内存、通信和计算**之间取得精妙的平衡。这是当前所有大型AI实验室和公司训练SOTA模型所依赖的基础架构。