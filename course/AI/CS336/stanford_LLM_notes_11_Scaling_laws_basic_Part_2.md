本文主要整理CS336 Lecture 9 Scaling laws章节的主要内容。

## 6.0 Scaling laws for model engineering

### 内容概况

这两张幻灯片是一个关于**模型工程缩放定律** 主题分享的开篇部分。它们旨在引出核心问题：在面对构建大型语言模型的复杂决策和有限资源时，如何做出科学、高效的选择。幻灯片指出，“缩放定律”将为这些决策提供一个系统性的、量化的指导框架。

*   **第一张图** 从宏观层面提出了模型工程中面临的**核心挑战和动机**，即如何在众多设计方案和有限资源下进行最优分配。
*   **第二张图** 将问题具体化，列出了几个关键的**超参数和模型配置选择**，并指出将在经典的Kaplan缩放定律论文的背景下讨论这些选择。

### 要点总结

#### 幻灯片1: Scaling laws for model engineering
1.  **核心动机**：寻求高效设计巨型语言模型的方法。幻灯片以历史上重要的模型架构（LSTMs vs Transformers）和优化器（Adam vs SGD）的选择为例，说明了做出正确工程决策的重要性。
2.  **核心问题**：在资源（如时间、算力、数据）有限的前提下，如何进行最优分配。具体表现为两个关键权衡：
    *   **训练时间 vs. 模型规模**：是延长现有模型的训练时间，还是增大模型参数规模？
    *   **数据量 vs. 算力**：是将资源用于收集更多数据，还是用于获取更强的计算能力（如更多GPU）？
3.  **提出解决方案**：幻灯片指出，“缩放定律”将提供一个简单的流程或方法论，来量化地回答上述问题，从而指导决策。

#### 幻灯片2: Hyperparameter questions
1.  **细化决策点**：承接上一张幻灯片，本片列出了在模型工程中需要具体考虑的几类**超参数和配置选择**：
    *   **架构**：模型的基础结构（如Transformer的不同变体）。
    *   **优化器**：训练模型所使用的算法（如Adam, SGD等）。
    *   **长宽比/深度**：模型形状的权衡，例如是设计得更“深”（层数多）还是更“宽”（每层神经元多）。
    *   **批次大小**：一次训练迭代中使用的样本数量。
2.  **提供分析框架**：幻灯片指明，将结合**Kaplan等人的经典缩放定律论文** 来分析和理解这些选择对模型性能的影响。这为后续的详细讨论设定了理论背景和基准。

## 6.1 Architecture: transformers vs LSTMs

### 内容概况

![Transformer vs. LSTM](https://pica.zhimg.com/v2-189327f37de6ff3b265174298f8c8aa6_1440w.jpg)

这两张幻灯片共同回答了“如何科学比较不同神经网络架构优劣”的核心问题。
*   **第一张图** 通过一个具体案例（Transformer vs. LSTM），展示了缩放定律方法的强大之处：**无需耗费巨资训练极致模型，即可通过小规模实验外推预测不同架构的极限性能**。
*   **第二张图** 将视野扩展至更广泛的模型架构（如ALBERT、Evolved Transformer等），通过对大量架构进行缩放分析，得出了一个关键结论：**架构的优劣并非绝对，而是与可用的计算预算紧密相关**。

---

### 要点总结

1.  **方法论革新：从“蛮力比较”到“缩放定律预测”**
    *   传统方法（Brute force）需要为每种架构投入巨大成本训练到最大规模才能比较，这在实践中不可行。
    *   缩放定律方法只需对不同架构进行一系列**小规模实验**，拟合出各自的缩放曲线，便可**外推预测**它们在大规模时的性能趋势，从而高效、低成本地做出决策。

2.  **核心结论一：Transformer架构显著优于LSTM**
    *   第一张图明确显示，在相同的参数量或计算量下，Transformer的性能（测试损失更低）始终优于LSTM，且随着规模扩大，优势越来越明显。这从理论上解释了Transformer成为大模型基石的必然性。

3.  **核心结论二：没有“绝对最优”的架构，只有“适合预算”的架构**
    *   第二张图的研究表明，不同的架构有不同的缩放曲线。有些架构在**小计算预算**下表现更优（计算效率高），而另一些架构则在**大计算预算**下潜力更大（缩放性能好）。因此，最佳架构选择取决于你的计算资源。

4.  **指导意义：为模型设计提供定量依据**
    *   缩放定律将架构选择从一个依赖直觉的“艺术”问题，转变为一个可量化、可预测的“科学”决策过程，能够有效指导研发资源的分配。

## 6.2 Depth/Width: and other Transformer hypers

### 内容概况

这三张幻灯片是一个连贯的整体，旨在回答关于模型架构设计的几个核心问题：
1.  **深度的重要性**：增加层数（深度）有多大影响？
2.  **参数的非等价性**：在计算参数规模时，是否所有参数都同样重要？
3.  **形状的灵活性**：在总参数量固定的情况下，模型的深度和宽度等“形状”超参数是否需要精细调整？

### 要点总结

1.  **深度的影响存在边际效应**：从1层增加到2层带来巨大性能提升，但此后每增加一层所带来的收益迅速递减，尤其是在模型规模较小时（参数少于10^7时）。
2.  **并非所有参数都等价**：**嵌入层的参数** 在决定模型性能上的“效率”远低于**非嵌入层**（non-embedding）的参数。因此，衡量模型规模时，应更关注**非嵌入参数**的数量。这与专家混合模型中的思想一脉相承。
3.  **模型形状具有惊人的灵活性**：在总非嵌入参数量保持不变的情况下，模型的**深度与宽度的比例（纵横比）**、**前馈网络与注意力层的维度比**等“形状”超参数，对最终性能的影响相对微小。这意味着架构设计师拥有很大的灵活性，无需过度纠结于寻找一个“完美”的形状。

### 图表解释

![Depth/Width](https://pic1.zhimg.com/v2-5083a7230b6be55c7196d2c89d1e7720_1440w.jpg)

#### 图表1：深度（层数）的影响
*   **解读**：该图展示了不同层数的模型，其测试损失随总参数量变化的缩放曲线。
*   **关键发现**：
    *   **1层 vs 2层**：两条曲线分离明显，表明从单层模型变为两层模型带来**质的飞跃**。
    *   **2层以上**：2层、3层、6层及更多层的曲线非常接近，尤其是在参数量较少（<10^7）的区域。这表明**超过2层后，单纯增加深度带来的收益递减**。
    *   **核心结论**：模型的**表示能力**主要来自于具备一定深度（至少2层），但在此之后，**增加参数（无论是通过加深还是加宽）比单纯增加深度更重要**。

#### 图表2：参数的非等价性（嵌入层 vs. 非嵌入层）
*   **解读**：该对比图说明了为何在缩放定律中要使用“非嵌入参数”。
*   **左图（含嵌入层参数）**：不同层数的模型曲线分离度较大，显得混乱。这是因为嵌入层参数量巨大但“贡献”较低，扭曲了真实的能力对比。
*   **右图（非嵌入参数）**：曲线变得规整，不同层数的模型按照其真实能力排序。这表明，**非嵌入参数的数量是衡量模型真实计算能力和潜力的更好指标**。

#### 图表3：其他Transformer超参数的灵活性
*   **解读**：这些图表研究了在固定总非嵌入参数量的前提下，调整模型形状对性能的影响。
*   **前馈网络比例/纵横比/注意力头维度**：图表显示，**在一个非常宽的取值范围内**，模型的测试损失只有微小的百分比变化（通常只有几个百分点）。
*   **核心结论**：例如，纵横比（深度与宽度之比）即使变化40倍，对性能的影响也很小。这意味着，只要总计算预算（参数量）固定，你可以根据工程需求（如训练速度、内存占用）相对自由地选择模型形状，而无需过分担心会严重影响最终性能的极限。**这为模型架构设计提供了极大的灵活性**。

总而言之，这三张图共同传达了一个信息：在模型设计中，**规模（参数量/计算量）是比形状（深度/宽度等）更强大的杠杆**。一旦确保了最低限度的深度，追求更大的规模比精细调整形状超参数更为重要。

## 6.3 Batch size: Critical batch size

![Critical batch size](https://pic3.zhimg.com/v2-ae656b80e7f1916ec55685b2ee5ad324_1440w.jpg)

### 内容概况

这三张幻灯片构成了一个关于批量大小选择的完整论述：
1.  **第一张图** 从概念上引入了**临界批量大小** 的定义，并解释了批量大小与训练效率之间的关系，揭示了其存在的“边际效益递减”效应。
2.  **第二张图** 通过实证研究展示了临界批量大小并非固定不变，而是与模型性能（损失值）目标紧密相关，并给出了量化的幂律公式。
3.  **第三张图** 基于前面的理论，探讨了在实际训练中（尤其是在计算预算和模型规模不断增长时）如何选择最优批量大小的策略。

---

### 要点总结

1.  **核心概念：临界批量大小**
    *   批量大小对训练效率的影响存在一个临界点。在临界点之前，增大批量大小能近乎线性地提升训练速度（**数据并行效率高**）；超过临界点后，收益急剧递减，增大批量对加速训练的效果微乎其微。

2.  **临界批量与性能目标相关**
    *   临界批量大小不是一个固定值。**性能目标越高（目标损失值越小），所需的临界批量就越大**。这意味着训练越到后期（追求更高精度），可以且应该使用越大的批量。
    *   The smaller the loss target, The bigger the batch.

3.  **存在最优训练策略**
    *   当计算预算和模型规模扩大时，有两种策略：
        *   **策略A**：使用巨大批量，保持训练步数不变。
        *   **策略B**：保持批量大小不变，增加训练步数。
    *   理论分析表明，存在一个**最优的批量大小**，它随计算预算的增长而缓慢增长。采用这个最优批量可以最小化达到特定性能所需的总计算量。

4.  **对分布式训练的启示**
    *   当计算预算和模型规模扩大时，有两种策略：策略A：使用巨大批量，保持训练步数不变。策略B：保持批量大小不变，增加训练步数。
    *   理论分析表明，**存在一个最优的批量大小，它随计算预算的增长而缓慢增长。采用这个最优批量可以最小化达到特定性能所需的总计算量**。


## 6.4 Learning rates: muP and scale-aware LR choices

![Learning rates](https://pic4.zhimg.com/v2-1c378baf7b132aa6b48786d345a17e9b_1440w.jpg)

### 内容概况

这张幻灯片的主题是“**学习率：μP与尺度感知的学习率选择**”。它通过对比传统做法与作者提出的新方法，揭示了一个核心问题：当模型规模（如宽度）扩大时，**最优学习率并非固定不变**。传统方法下，最优学习率会随模型规模变化而偏移，导致调优困难。幻灯片重点介绍了一种称为“**μP**”的尺度感知方法，该方法通过特定的**参数初始化**和**学习率缩放规则**，使得最优学习率在模型规模变化时保持稳定，从而极大简化了超参数调优并提升了训练稳定性。

---

### 二、要点总结

1.  **核心问题**：**“天真地”扩大模型规模会导致最优学习率依赖于模型尺度**。这意味着，每当改变模型宽度时，都需要重新进行昂贵的学习率网格搜索，效率极低。
2.  **解决方案**：需要**尺度感知的初始化和学习率缩放**策略。μP方法正是为此设计。
3.  **方法对比**：
    *   **传统做法（左图）**：不同宽度的模型有其独特且互不重叠的“U型”损失曲线。随着宽度增加，最优学习率变小且曲线谷底变平缓，难以精确锁定。
    *   **μP方法（右图）**：不同宽度的模型的损失曲线几乎完全重叠，共享一个清晰且稳定的最优学习率点。这使得我们可以用小规模模型的搜索结果直接指导大规模模型的训练。
4.  **实施关键**：μP方法对不同类型（如“类矩阵”参数和“其他”参数）的**初始化方差**和**优化器学习率**应用了不同的缩放因子（与宽度扩大倍数 $r$ 相关），这是实现尺度不变性的技术核心。

    *   **参数分类**：
        *   **类矩阵**：指维度会随宽度无限增大的参数（如全连接层的权重矩阵）。
        *   **其他**：指维度固定或随宽度变化方式不同的参数（如嵌入层、偏置项）。
        *   **输出**：特指将无限维度映射到有限维度的层（如语言模型最后的$lm_head$层）。
    *   **缩放规则**：
        *   **类矩阵参数的学习率 (AdamW lr)**：从 $l$ 缩放为 $l / r$。这是最关键的一条规则，意味着宽度越大，此类参数的学习率应设置得越小。
        *   **类矩阵参数的初始化方差**：从 $σ$ 缩放为 $σ / r$。这与学习率缩放协同作用，共同保证训练动态的稳定性。
        *   **其他参数**：其学习率和初始化方差**保持不变**。
        *   **输出层乘子**：从 $τ$ 缩放为 $τ / r$。

## 6.5 Caution – scaling behaviors can differ downstream

### 内容概况
这张幻灯片标核心在于揭示一个关键现象：**模型在预训练阶段表现出的稳定、可预测的缩放规律，在下游特定任务上可能失效**。

### 要点总结
1.  **核心警示：下游扩展规律存在不确定性**
    *   幻灯片明确指出，此前讨论的“缩放主要取决于参数规模”这一可预测规律，在下游任务（如SuperGLUE基准中的语言理解任务）上**可能不再成立**。下游性能的提升路径更为复杂和不可预测。

2.  **预训练与下游任务表现的脱节**
    *   **左图（预训练）**：展示了典型的缩放定律，模型性能（负对数困惑度）与参数规模呈平滑、稳定的幂律关系，表明在预训练阶段，扩大模型规模是提升性能的可靠途径。
    *   **右图（下游任务）**：显示相同的模型在SuperGLUE任务上的准确率与参数规模关系**更为分散**。这意味着，参数量的增长并不能保证在下游任务上获得一致的性能提升，某些小模型可能表现优于参数更多的大模型。

3.  **对模型开发与评估的启示**
    *   这一发现强调，**不能仅凭预训练损失或参数规模来简单判断一个模型在下游任务中的最终效能**。在选择模型或规划扩展路径时，必须针对具体下游任务进行直接评估和验证。

4.  **研究方向的指向**
    *   它引出了一个重要的研究问题：**是什么因素主导了下游任务的扩展行为？** 可能是模型架构、训练数据的性质、微调方法，或是任务本身的内在难度。理解这些因素将是实现更全面、可靠扩展定律的关键。

## 6.6 Some surprising takeaways

### 内容概况
这张幻灯片揭示一个大语言模型研究中的重要发现：**大规模语言模型的关键超参数效果可以在投入巨大成本进行完整训练之前被预测**。幻灯片进一步将此发现转化为一个实用的、系统的模型设计流程，该流程基于“缩放定律(scaling law)”，能够通过小规模实验来指导大规模训练时的最优超参数选择。

---

### 要点总结

1.  **核心发现：超参数效果具有可预测性**
    *   幻灯片提出了一个反直觉的惊人结论：像**优化器选择、模型深度、架构选择**这类对最终性能有重大影响的关键超参数，其效果并非必须通过训练完整大模型才能知晓。

2.  **提供了一套科学的设计方法论**
    *   **第一步：小规模实验**。无需直接训练巨型模型，而是先训练多个较小、成本较低的模型。
    *   **第二步：建立缩放定律**。基于小模型的实验结果，拟合出性能随模型规模（如参数量、计算量）变化的规律（即缩放定律）。
    *   **第三步：外推预测与决策**。利用建立的缩放定律，外推预测不同超参数设置在大规模模型上可能达到的性能，从而科学地选择最优配置。

3.  **具有重大的实践指导价值**
    *   这一方法极大地降低了模型研发的不确定性和成本。它使得研究人员和工程师能够在投入大量计算资源之前，**“预览”不同设计选择的长期效果**，从而做出更优决策，显著提升研发效率。

## 7.0 One important use of scaling laws

### 内容概况

这张幻灯片探讨了机器学习中一个极其重要的实际问题：**当目标是提升模型性能时，我们应优先扩大模型规模，还是优先收集更多数据？** 幻灯片指出，小模型无法有效利用海量数据（造成浪费），进而引出了“联合缩放定律”的概念。
---

### 要点总结

1.  **核心问题**：提出了资源分配的核心权衡——在有限的预算下，是应该用来打造更大的模型，还是用来获取更多的训练数据？
2.  **关键观察**：明确指出“小模型会浪费大量数据”。这意味着，如果模型容量不足，仅仅增加数据量带来的性能收益会迅速递减。
3.  **解决方案**：引入“**联合缩放定律**”，其目的是建立一个统一的框架，来**同时描述模型规模（n）和数据规模（m）与泛化误差之间的定量关系**。
4.  **实用价值**：这些定律能帮助我们：
    *   **理解现状**：通过拟合公式，理解当前模型和数据集的配置处于什么样的水平。
    *   **预测未来**：预测如果扩大模型或增加数据，性能将如何提升。
    *   **优化分配**：为如何最有效地分配资源以实现特定性能目标提供科学指导。

---

### 解释公式

幻灯片中提供了两个不同但思路相似的联合缩放定律公式。

#### 公式一：Rosenfeld et al. 2020
$$ \text{Error} = n^{-\alpha} + m^{-\beta} + C $$

*   **公式含义**：这个公式将总误差分解为三个来源的**简单加和**。
*   **符号解释**：
    *   $Error$：模型的泛化误差。
    *   $n$：模型规模（例如参数量）。
    *   $m$：训练数据集大小（例如样本数或token数）。
    *   $n^{-α}$：**模型误差**。该项表示由于模型容量有限（即使有无限数据）而引入的误差。随着模型规模 $n$ 增大，此项误差以幂律形式衰减。
    *   $m^{-β}$：**数据误差**。该项表示由于训练数据有限（即使模型容量无限）而引入的误差。随着数据量 $m$ 增大，此项误差以幂律形式衰减。
    *   $C$：**不可约误差**。一个常数项，代表由任务本身固有噪声或模型家族限制所决定的理论上无法消除的误差下限。
*   **直观理解**：总误差是“模型不够大”的误差、“数据不够多”的误差和一个固定偏差的总和。这个模型非常直观地分离了误差的不同来源。

#### 公式二：Kaplan et al. 2020
$$ \text{Error} = [m^{-\alpha} + n^{-1}]^{\beta} $$

*   **公式含义**：这个公式采用了**先加和后缩放**的形式。它假设模型误差和数据误差以一种更耦合的方式共同影响最终结果。
*   **符号解释**：
    *   $m^{-α}$：**数据误差项**。与Rosenfeld公式中的类似，随数据量增加而衰减。
    *   $n^{-1}$：**模型误差项**。注意，这里将模型误差的指数固定为 $-1$（而非一个可拟合的参数 $β$），这可能源于理论推导。
    *   $[ ... ]^{\beta}$：**外部缩放**。将模型误差和数据误差的加和作为一个整体，再进行一次幂律缩放。$β$ 是一个关键的拟合参数，它控制了联合误差衰减的整体速率。
*   **直观理解**：这个模型认为，模型规模和数据集大小共同决定了一个“基础误差水平”，而这个水平最终以 $β$ 次方的速率影响我们观测到的总误差。它可能在某些场景下具有更好的拟合能力。

## 7.1 Model-data joint scaling is accurate

![Model-data joint scaling is accurate](https://pica.zhimg.com/v2-7fae2f894a68d8bf0fb2c16caeaa01f8_1440w.jpg)

### 内容概况

这张幻灯片旨在证明一个强大的方法论：**仅需在小模型、小数据上进行实验，拟合出缩放指数，即可非常准确地预测出大模型、大数据下的性能**。幻灯片通过一个示意图和两个在不同任务（ImageNet图像分类、WikiText-103语言建模）上的实证外推预测，生动展示了该方法的有效性。底部则给出了基于该定律进行资源最优分配的数学公式。

---

### 要点总结

1.  **核心方法论**：提出了一种高效预测模型性能的方法。其流程是：1）在**小规模**（小模型、小子集数据）上训练；2）拟合出联合缩放定律的指数（α, β）；3）利用拟合的定律**外推预测**大规模下的性能。
2.  **定律准确性**：图表显示，外推预测（虚线）与大规模下的实际观测结果（实心圆点）高度吻合。这表明联合缩放定律具有很强的普适性和预测能力，打破了必须进行昂贵大规模实验才能知悉结果的限制。
3.  **实践指导价值**：该方法为资源分配提供了科学依据。研究人员可以在投入巨大成本前，通过小型实验来“预览”不同模型与数据组合的潜力，从而做出最优决策。
4.  **通用性**：在ImageNet（计算机视觉任务）和WikiText-103（自然语言处理任务）上都取得了成功，证明该方法适用于多种机器学习领域。

## 7.2 Compute tradeoffs

### 内容概况
这张幻灯片主题为"计算权衡"，核心探讨在固定计算预算下如何最优分配资源的关键问题。

### 要点总结
1. **核心问题**：在固定计算预算约束下，面临"模型规模"与"训练程度"的根本权衡——选择大规模模型但训练不足，还是小规模模型但充分训练。

2. **权衡本质**：计算预算同时影响模型规模（参数量）和训练数据量，二者存在此消彼长的关系。缩放定律为这一权衡提供了量化分析框架。

3. **图表验证**：通过不同来源的实证研究显示，**存在一个计算预算的最优分配点，使得模型性能最大化, 盲目增大模型或单纯增加训练都非最优策略**。

4. **实践价值**：缩放定律能够精确指导如何在特定计算预算下，找到模型规模与训练数据量的最佳平衡点，避免资源浪费。

## 8.0 Caution – ‘Optimal’ scaling laws are hard to get

### 内容概况

这两张幻灯片共同探讨了构建和验证“最优”缩放定律的**复杂性、挑战和关键细节**。

*   **第一张图** 揭示了不同研究团队（Kaplan vs. Hoffman/Chinchilla）在预测最优模型-数据配比上存在的显著分歧，并指出获得精确的“最优”缩放定律是困难的。
*   **第二张图** 则深入探讨了一个被早期简化模型忽略的关键细节——**学习率衰减计划**，并证明了考虑该因素后，新的缩放定律预测与真实训练结果高度吻合。

### 要点总结

1.  **“最优”缩放定律并非绝对**：第一张图的核心警示是，虽然缩放定律的概念很强大，但基于有限数据拟合出的具体公式可能存在较大偏差。Chinchilla的工作表明，早期定律可能严重低估了数据需求，导致模型训练不足。
2.  **模型-数据配比是核心争议点**：不同研究的分歧在于，在固定计算预算下，多少资源应分配给模型规模，多少应分配给数据量。这直接影响了大模型训练的效率和最终性能。
3.  **细节决定预测准确性**：第二张图强调，一个鲁棒的缩放定律必须考虑实际训练中的关键超参数，如**学习率衰减计划**。忽略这些细节会导致预测失准。
4.  **从理论到实践的演进**：这两张图反映了该领域从提出简单的理论定律，到不断考虑更多实际因素、进行修正和完善的过程，使其能更精准地指导实践。

## 7.3 Chinchilla in depth – 3 methods

### 内容概况
这四张图表深入探讨了Chinchilla研究中用于确定最优模型规模与数据配比的三种核心方法。研究旨在解决在固定计算预算下，如何最优分配资源给模型参数量（N）和训练数据量（D）的问题，挑战了Kaplan等人早期认为应优先扩大模型规模的观点。图表系统地展示了对数线性拟合、等计算量曲线和参数化建模三种方法的实证过程与结果。

### 要点总结
1.  **核心挑战**：早期缩放定律（如Kaplan）可能高估模型规模收益，低估数据规模价值。Chinchilla研究通过更严谨方法重新校准。
2.  **方法对比**：
    - **方法1（训练曲线包络minimum over runs）**：汇集大量实验，直接寻找不同计算预算下的最佳性能点。
    - **方法2（等计算量曲线IsoFLOPS）**：固定计算量，系统调整模型参数量以寻找损失最低点。
    - **方法3（参数化联合拟合Joint fits）**：拟合损失函数曲面，数学推导最优前沿。
3.  **一致结论**：三种方法均支持新缩放律（N与D应平衡增长，指数a≈0.5, b≈0.5），显著区别于Kaplan律（a=0.73, b=0.27）。
4.  **实践指导**：基于Gopher的计算预算，新律预测最优模型应为约400亿参数（而非更大模型），并需相应增加数据量。

### 图表解释
**图1：三种方法系数对比表**
- 表格对比三种方法得出的计算分配指数a和b（满足$N_opt ∝ C^a$, $D_opt ∝ C^b$）。
- **关键发现**：方法1和2结果高度一致（a≈0.50, b≈0.50），方法3略偏向数据（a=0.46, b=0.54）。三者均显著不同于Kaplan结果（a=0.73, b=0.27），证明应更平衡地分配计算预算。

![minimum over runs](https://picx.zhimg.com/v2-5bbbb754a4b37a88333568b0bde7182b_1440w.jpg)

**图2：方法1 – 训练曲线包络法**
- **左图**：展示不同规模模型（70M至10B参数）的训练损失曲线。从中提取每条曲线在特定计算量下的最小损失点。
- **中图与右图**：将提取的最优点分别映射为最优参数量（中）和最优token数（右）与计算量的关系。绿色点标示基于Gopher算力预算的预测，显示应训练约400亿参数模型并使用更多数据。

![IsoFLOPS](https://pic4.zhimg.com/v2-d2d7a81918f099ef7c306456c5b3a2ff_1440w.jpg)

**图3：方法2 – 等计算量曲线法**
- **左图**：固定多个计算量级别，改变参数量进行训练，形成U形损失曲线。曲线谷底即该计算量下的最优参数量。
- **中图与右图**：将这些谷底点连接起来，发现最优参数量（中）和最优token数（右）与计算量呈清晰的幂律关系。绿色点再次确认Gopher算力下最优模型约为400亿参数。

**图4：方法3 – 参数化联合拟合法**
- **左图（等高线图）**：基于网格实验数据拟合损失函数曲面L(N,D)。蓝色“有效前沿”线连接**每个等损失线上计算效率最高的点**，其在对数坐标下呈直线。
- **右图（等计算量切片）**：展示固定计算量下，损失随参数量变化的切片视图。曲线谷底位置共同定义了最优配置路径。
- **结论**：该方法同样预测，在Gopher的计算预算下，训练约400亿参数的模型是最优解。

## 8.0 Important note – train-optimal may not be what you want


### 内容概况

本部分旨在揭示一个在模型部署中至关重要的**权衡**：虽然**Chinchilla扩展法则**指导我们如何在固定训练计算预算下获得性能最好的模型（即“训练最优”），但在实际生产环境中，由于**推理成本**通常远高于一次性训练成本，盲目追求“训练最优”可能并非最经济的选择。图片通过对比不同模型在训练时消耗的`tokens/param`（每参数token数）这一关键指标，论证了为了降低长期推理成本，进行“过度训练”是合理且必要的策略。

---

### 要点总结

1.  **核心矛盾：训练最优 vs. 部署最优**
    *   **训练最优**：由Chinchilla法则定义，目标是**最小化训练成本**，以得到最佳性能模型。这通常意味着为给定规模的模型寻找一个恰好的数据量，避免“训练不足”或“过度训练”。
    *   **部署最优**：考虑到现实世界中，一个模型会被调用数百万甚至数十亿次，**总推理成本 = 单次推理成本 × 调用次数**。因此，降低单次推理成本（例如，使用更小、更高效的模型）可能比节省一次性训练成本更重要。

2.  **关键策略：“过度训练”**
    *   图片提出，为了获得更小、性能更强的模型以降低推理成本，我们应该有意地**“过度训练”**。即，在远超过Chinchilla最优数据量的数据上训练一个模型，使其性能饱和，从而得到一个在更小参数量下就能达到同等性能的“精炼”模型。

3.  **量化指标：tokens/param**
    *   图片用`tokens/param`（训练总token数 / 模型参数量）来量化训练强度。
    *   **趋势**：从GPT-3到Llama 3，这个比值急剧上升（从2上升到215），表明业界趋势正是通过大幅增加训练数据来打造参数更少、性能更强、推理更高效的模型。
        - GPT3 – 2 tokens / param
        - Chinchilla – 20 tokens / param
        - LLaMA65B – 22 tokens / param
        - Llama 2 70B – 29 tokens / param
        - Mistral 7B – 110 tokens / param
        - Llama 3 70B – 215 tokens / param
    

4.  **决策框架：预期使用量决定策略**
    *   图片最后给出了决策逻辑：**预期的模型使用量越大，前期投入更高的训练成本以换取长期更低的推理成本就越值得**。对于一个小众应用，使用一个“训练最优”的模型可能更经济；但对于一个面向海量用户的核心产品，投资“过度训练”一个高效模型将是明确的选择。

## 8.1 Scaling laws for models and compute

### 1. **核心特性：可预测的对数线性关系**
模型性能（如损失）与关键资源（如**模型参数量**和**总计算量**）之间存在着稳定的**对数线性关系**（即幂律关系）。这是所有缩放定律的基础，使得性能预测成为可能。

### 2. **核心方法论：基于小规模实验的预测**
无需投入巨资训练最终的大模型，而是通过**训练一系列小模型**进行实验，拟合出缩放曲线，进而**外推预测**大规模下的模型性能、优化器效果、架构优劣等，从而大幅降低决策成本和风险。

### 3. **核心应用：指导关键决策与权衡**
缩放定律为以下关键决策提供了定量依据：
*   **架构与配置选择**：如优化器（Adam vs. SGD）、模型架构（Transformer vs. LSTM）、模型深度和宽度等。
*   **资源权衡**：最经典的即 **“大模型”与“更多数据”之间的权衡**。缩放定律可以回答：在固定计算预算下，是训练一个参数更多的模型，还是用更多数据训练一个参数稍少的模型更优？

### 4. **核心价值：理论、成本与战略意义**
幻灯片从三个层面总结了缩放定律的巨大价值：
*   **理论价值**：提供了关于**数据如何影响模型**的清晰理论框架，将学习过程系统化。
*   **工程价值**：能**极大降低训练成本**，避免资源浪费，实现高效开发。
*   **战略价值**：作为一种**预测工具**，帮助研究者理解哪些问题可以通过扩大规模（“暴力破解”）来解决，从而规划长远的技术路线。