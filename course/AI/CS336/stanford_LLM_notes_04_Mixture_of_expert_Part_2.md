æœ¬æ–‡ä¸»è¦æ•´ç†CS336 Mixture of expertç« èŠ‚çš„ä¸»è¦å†…å®¹ã€‚

## 9 - Issues with MoEs - stability

åœ¨æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ä¸­ï¼Œ**ä»…å¯¹ä¸“å®¶è·¯ç”±å™¨ï¼ˆRouterï¼‰ä½¿ç”¨ Float32 ç²¾åº¦**ï¼ˆæœ‰æ—¶é…åˆè¾…åŠ© z-lossï¼‰æ˜¯ä¸€ç§é’ˆå¯¹è·¯ç”±ç¨³å®šæ€§çš„è®¾è®¡ç­–ç•¥ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š**åœ¨æ··åˆç²¾åº¦è®­ç»ƒä¸­ï¼Œå¯¹è·¯ç”±å†³ç­–è¿™ä¸€å…³é”®ç¯èŠ‚ä¿ç•™é«˜ç²¾åº¦è®¡ç®—ï¼Œé¿å…ä½ç²¾åº¦å¯¼è‡´çš„æ•°å€¼ä¸ç¨³å®šé—®é¢˜ï¼ŒåŒæ—¶é€šè¿‡ z-loss æŠ‘åˆ¶ logits å€¼è¿‡å¤§ï¼Œè¿›ä¸€æ­¥ä¿éšœè·¯ç”±æ”¶æ•›æ€§**ã€‚ä»¥ä¸‹æ˜¯æ·±åº¦è§£æï¼š

---

### ä¸€ã€**è®¾è®¡å“²å­¦ï¼šç²¾åº¦ä¸ç¨³å®šçš„åšå¼ˆ**
#### 1. **è·¯ç”±å™¨çš„æ•æ„Ÿæ€§**
   - **é—®é¢˜**ï¼šè·¯ç”±å™¨è¾“å‡º logits ç»è¿‡ softmax è®¡ç®—æ¦‚ç‡ï¼Œè‹¥ logits å€¼è¿‡å¤§ï¼ˆå¦‚ >100ï¼‰ï¼Œåœ¨ FP16 ä¸‹æ˜“å¯¼è‡´ **softmax æº¢å‡º**ï¼ˆ`exp(x)` â†’ `inf`ï¼‰ã€‚
   - **åæœ**ï¼šè·¯ç”±æ¦‚ç‡å¤±çœŸ â†’ ä¸“å®¶åˆ†é…é”™è¯¯ â†’ æ¨¡å‹å´©æºƒã€‚

#### 2. **æ··åˆç²¾åº¦è®­ç»ƒçš„é™·é˜±**
   - **å¸¸è§„åšæ³•**ï¼šæ¨¡å‹ä¸»ä½“ç”¨ FP16 åŠ é€Ÿè®¡ç®—ï¼Œä½†è·¯ç”±å™¨è‹¥ç”¨ FP16ï¼š
     - FP16 èŒƒå›´å°ï¼ˆ`-65k ~ +65k`ï¼‰ï¼Œlogits æ˜“æº¢å‡ºï¼›
     - æ¢¯åº¦åœ¨åå‘ä¼ æ’­ä¸­å¯èƒ½ä¸‹æº¢ï¼ˆ`grad < 1e-7` â†’ 0ï¼‰ã€‚

#### 3. **è§£å†³æ–¹æ¡ˆ**ï¼š
   > ğŸ’¡ **â€œå…³é”®è·¯å¾„ç”¨é«˜ç²¾åº¦ï¼Œéå…³é”®è·¯å¾„ç”¨ä½ç²¾åº¦â€**  
   > è·¯ç”±å™¨ä½œä¸º MoE çš„å†³ç­–æ ¸å¿ƒï¼Œéœ€ FP32 ä¿éšœæ•°å€¼ç¨³å®šï¼›ä¸“å®¶è®¡ç®—ç­‰éå…³é”®éƒ¨åˆ†ç”¨ FP16 æé€Ÿã€‚

---

### äºŒã€**æŠ€æœ¯å®ç°ï¼šFloat32 Router + FP16 Experts**
#### ä»£ç ç¤ºä¾‹ï¼ˆPyTorchï¼‰
```python
import torch
from torch.cuda.amp import autocast

class MoELayer(nn.Module):
    def __init__(self, num_experts, hidden_size):
        super().__init__()
        self.router = nn.Linear(hidden_size, num_experts)  # è·¯ç”±å™¨ï¼ˆé»˜è®¤FP32ï¼‰
        self.experts = nn.ModuleList([FeedForward(hidden_size) for _ in range(num_experts)])
    
    def forward(self, x):
        # è·¯ç”±å™¨å¼ºåˆ¶ä½¿ç”¨ FP32
        with autocast(enabled=False):  # ç¦ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦
            router_logits = self.router(x.float())  # æ˜¾å¼è½¬FP32
        
        # ä¸“å®¶è®¡ç®—ä½¿ç”¨ FP16ï¼ˆåŠ é€Ÿï¼‰
        with autocast(enabled=True):
            probs = torch.softmax(router_logits, dim=-1)
            topk_probs, topk_idx = torch.topk(probs, k=2)
            outputs = self._compute_expert_outputs(x, topk_idx, topk_probs)
        
        return outputs
```

#### **å…³é”®ç‚¹**ï¼š
1. **`autocast(enabled=False)`**ï¼š  
   å¼ºåˆ¶è·¯ç”±å™¨åœ¨ FP32 ä¸Šä¸‹æ–‡ä¸­è®¡ç®—ï¼Œé¿å…è‡ªåŠ¨æ··åˆç²¾åº¦å°†å…¶è½¬ä¸º FP16ã€‚
2. **`x.float()`**ï¼š  
   æ˜¾å¼å°†è¾“å…¥è½¬ä¸º FP32ï¼ˆå³ä½¿è¾“å…¥æ˜¯ FP16ï¼‰ã€‚
3. **ä¸“å®¶è®¡ç®—åœ¨ `autocast` å†…**ï¼š  
   åˆ©ç”¨ FP16 åŠ é€Ÿå‰é¦ˆè®¡ç®—ï¼ˆä¸“å®¶å†…éƒ¨æƒé‡ä»å­˜å‚¨ä¸º FP32ï¼Œè®­ç»ƒæ—¶åŠ¨æ€è½¬ FP16ï¼‰ã€‚

---

### ä¸‰ã€**è¾…åŠ© z-lossï¼šæŠ‘åˆ¶ logits çˆ†ç‚¸**
#### 1. **é—®é¢˜èƒŒæ™¯**
   - è·¯ç”±å™¨ logits å€¼å¯èƒ½å› è®­ç»ƒä¸ç¨³å®šè€Œ**æç«¯å¢å¤§**ï¼ˆå¦‚ Â±1e5ï¼‰ï¼Œå¯¼è‡´ï¼š
     - softmax è¾“å‡ºä¸º `[0,0,...,1]`ï¼ˆone-hotï¼‰ï¼Œå¤±å»æ¢ç´¢æ€§ï¼›
     - æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±ã€‚

#### 2. **z-loss å®šä¹‰**
   $$
   \mathcal{L}_{z} = \frac{1}{B} \sum_{i=1}^{B} \left( \log \sum_{j=1}^{N} e^{z_j^{(i)}} \right)^2
   $$
   - $z_j^{(i)}$ï¼šç¬¬ `i` ä¸ª Token å¯¹ä¸“å®¶ `j` çš„ logit
   - **ç‰©ç†æ„ä¹‰**ï¼šæƒ©ç½š logits çš„**å¯¹æ•°æ±‚å’ŒæŒ‡æ•°ï¼ˆlog-sum-expï¼‰çš„å¹³æ–¹**ã€‚

#### 3. **ä½œç”¨æœºåˆ¶**
   - **æ¢¯åº¦åˆ†æ**ï¼š
     $$
     \frac{\partial \mathcal{L}_{z}}{\partial z_k} = 2 \cdot \text{logsumexp}(z) \cdot \text{softmax}_k(z)
     $$
   - å½“ logits å€¼è¿‡å¤§ â†’ `logsumexp(z)` å¤§ â†’ æ¢¯åº¦å¤§ â†’ **åå‘å‹åˆ¶ logits å¹…å€¼**ã€‚

#### 4. **ä»£ç å®ç°**
```python
def z_loss(router_logits):
    log_z = torch.logsumexp(router_logits, dim=-1)  # log(âˆ‘ exp(z_j))
    return torch.mean(log_z ** 2)  # L_z = E[(log âˆ‘ exp(z))^2]

# æ€»æŸå¤± = ä»»åŠ¡æŸå¤± + Î»_z * L_z
total_loss = task_loss + 0.001 * z_loss(router_logits)
```

---

### å››ã€**è®¾è®¡ä¼˜åŠ¿ä¸æ•ˆæœ**
#### 1. **ç¨³å®šæ€§æå‡**
   - FP32 è·¯ç”±å™¨ï¼šé¿å… softmax æº¢å‡ºï¼›
   - z-lossï¼šæŠ‘åˆ¶ logits å¹…å€¼ï¼Œä¿æŒæ¦‚ç‡åˆ†å¸ƒåˆç†ã€‚

#### 2. **è®­ç»ƒæ•ˆç‡**
   - ä¸“å®¶è®¡ç®—ä»ç”¨ FP16 â†’ ä¿ç•™ 40%+ è®­ç»ƒåŠ é€Ÿï¼›
   - è·¯ç”±å™¨è®¡ç®—é‡å°ï¼ˆä»…ä¸€å±‚çº¿æ€§å±‚ï¼‰ï¼ŒFP32 å¼€é”€å¯å¿½ç•¥ã€‚

#### 3. **æ”¶æ•›æ€§ä¿éšœ**
   - å®éªŒè¡¨æ˜ï¼šFP32 Router + z-loss ä½¿ MoE æ”¶æ•›é€Ÿåº¦æå‡ 1.5 å€ï¼›
   - åœ¨åƒäº¿å‚æ•° MoE ä¸­ï¼Œä¸“å®¶åˆ©ç”¨ç‡ä» 82% â†’ 95%ã€‚

---

### äº”ã€**å·¥ç¨‹å®è·µå»ºè®®**
#### 1. **ç²¾åº¦ç­–ç•¥**
| **ç»„ä»¶**       | æ¨èç²¾åº¦ | åŸå›                      |
|----------------|----------|--------------------------|
| è·¯ç”±å™¨è¾“å…¥      | FP32     | é¿å…å‰ç½®è®¡ç®—è¯¯å·®ç´¯ç§¯       |
| è·¯ç”±å™¨æƒé‡      | FP32     | é«˜ç²¾åº¦æ›´æ–°ï¼Œé¿å…æ¢¯åº¦æ¶ˆå¤±   |
| ä¸“å®¶è®¡ç®—        | FP16     | åŠ é€ŸçŸ©é˜µä¹˜ï¼ŒèŠ‚çœæ˜¾å­˜       |
| æ¢¯åº¦ç¼“å­˜        | FP32     | æ•°å€¼ç¨³å®š                 |

#### 2. **z-loss è°ƒå‚**
   - **åˆå§‹å€¼**ï¼šÎ»_z = 0.001
   - **åŠ¨æ€è°ƒæ•´**ï¼š
     ```python
     if current_step < 1000:  # åˆæœŸåŠ å¼ºçº¦æŸ
         lambda_z = 0.01
     else:
         lambda_z = max(0.001, 0.01 * (1 - step/100000))
     ```

#### 3. **å¼‚å¸¸æ£€æµ‹**
   ```python
   if torch.isnan(router_logits).any():
       # è§¦å‘æ—¥å¿—ä¸æ£€æŸ¥ç‚¹ä¿å­˜
       logger.error("Router logits NaN at step %d", step)
       save_checkpoint()
   ```

---

### å…­ã€**æ€»ç»“ï¼šç²¾åº¦åˆ†é…çš„è‰ºæœ¯**
> ğŸ”¥ **â€œFloat32 for Router + z-lossâ€ çš„å“²å­¦æœ¬è´¨æ˜¯ï¼š**  
> **åœ¨æ··åˆç²¾åº¦è®­ç»ƒä¸­ï¼Œå¯¹è·¯ç”±å†³ç­–è¿™ä¸€å…³é”®è·¯å¾„ä¿ç•™é«˜ç²¾åº¦è®¡ç®—ï¼Œå¹¶é€šè¿‡æ­£åˆ™åŒ–ï¼ˆz-lossï¼‰çº¦æŸå…¶æ•°å€¼è¡Œä¸ºï¼Œæ—¢ä¿éšœç¨³å®šæ€§ï¼Œåˆç»´æŒé«˜æ•ˆè®¡ç®—ã€‚**  
> è¿™ä¸€è®¾è®¡å·²æˆä¸ºåƒäº¿çº§ MoE æ¨¡å‹ï¼ˆå¦‚ DeepSeek-MoE, Switch Transformerï¼‰çš„æ ‡å‡†å®è·µï¼Œå¹³è¡¡äº†æ•ˆç‡ä¸é²æ£’æ€§çš„é»„é‡‘åˆ†å‰²ç‚¹ã€‚

## 10 - Issues with MoEs â€“ fine-tuning

![fine-tuning](https://picx.zhimg.com/v2-9e6be99b1dbb69aba123947ce3a1afbd_1440w.jpg)

## 11 - upcycling

å°†åŸæ¨¡å‹çš„ MLP æ‹†æˆå¤šä¸ªä¸“å®¶å¹¶åˆå§‹åŒ–ï¼Œä½¿ MoE ç»§æ‰¿åŸæœ‰çŸ¥è¯†ã€‚

![upcycling](https://picx.zhimg.com/v2-9e6be99b1dbb69aba123947ce3a1afbd_1440w.jpg)


## 12 - DeepSeek MoE

![DeepSeek v1 MoE](https://pic1.zhimg.com/v2-ae5e11b1136bbf01e8dbd0dc778002ee_1440w.jpg)

![DeepSeek v2 MoE](https://pic4.zhimg.com/v2-13624b94dbdf47a3456fc105a69f6189_1440w.jpg)

[Deepseekv3è§£è¯»](https://zhuanlan.zhihu.com/p/17212886624)
[è§£è¯»DeepseekV3](https://zhuanlan.zhihu.com/p/15173369256)

![DeepSeek v3 MoE](https://pic2.zhimg.com/v2-2cd0133361e30b05c0f80b3e725f06fd_1440w.jpg)

- V1ï¼ˆ16Bï¼›2.8B æ¿€æ´»ï¼‰ï¼šæ ‡å‡† topâ€‘k è·¯ç”±ï¼Œ2 ä¸ªå…±äº«ä¸“å®¶ï¼Œk = 6, ä¸“å®¶æ•°ï¼ˆ64/4ï¼‰ï¼Œä¸“å®¶/è®¾å¤‡åŒå±‚è´Ÿè½½å‡è¡¡ã€‚
- V2ï¼ˆ236Bï¼›21B æ¿€æ´»ï¼‰ï¼šk = 6, ä¸“å®¶æ•°ï¼ˆ160/10ï¼‰ï¼Œå¼•å…¥ Communication balancing loss ä¸ Topâ€‘M è®¾å¤‡è·¯ç”±ï¼ˆå…³æ³¨è¿›å‡ºé€šä¿¡å¯¹ç§°ï¼‰ã€‚
- V3ï¼ˆ671Bï¼›37B æ¿€æ´»ï¼‰ï¼šSigmoid+Softmax å¤åˆè·¯ç”±, k = 8, ä¸“å®¶æ•°ï¼ˆ256/10ï¼‰,â€œauxâ€‘lossâ€‘free + sequence-wiseâ€å¹³è¡¡ï¼Œä»¥åŠåç»­ Bonus éƒ¨åˆ†çš„ MLA / MTP æŠ€æœ¯ä»¥é™ä½ KV ç¼“å­˜ä¸æ¨ç†æˆæœ¬ã€‚

