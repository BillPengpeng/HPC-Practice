æœ¬æ–‡ä¸»è¦æ•´ç†CS336 Mixture of expertç« èŠ‚çš„ä¸»è¦å†…å®¹ã€‚

## 1 - MoEç»“æ„ã€éMoEç»“æ„åŒºåˆ«

![MoE](https://pic1.zhimg.com/v2-d356729ca9fb57095bd86250cd772c18_r.jpg)


| ç‰¹å¾           | éMoEï¼ˆç¨ å¯†æ¨¡å‹ï¼‰                         | MoEï¼ˆæ··åˆä¸“å®¶ï¼‰                                      |
| -------------- | ------------------------------------------ | ---------------------------------------------------- |
| **æ ¸å¿ƒæ€æƒ³**   | æ‰€æœ‰å‚æ•°å¤„ç†æ‰€æœ‰Token                      | æ¯ä¸ªTokenç”±å°‘æ•°å‡ ä¸ªä¸“å®¶å¤„ç†                      |
| **æ¿€æ´»**       | ç¨ å¯†ï¼ˆæ‰€æœ‰å‚æ•°ç”¨äºæ¯ä¸ªTokenï¼‰               | **ç¨€ç–ï¼ˆä»…å°‘é‡ä¸“å®¶ç”¨äºæ¯ä¸ªTokenï¼‰**                    |
| **æ¨¡å‹å®¹é‡ï¼ˆæ€»å‚æ•°é‡ï¼‰** | æœ‰é™å¢åŠ ä¼šå¯¼è‡´è®¡ç®—æˆæœ¬æ€¥å‰§ä¸Šå‡               | **å¯æå¤§å¹…åº¦æå‡ï¼ˆæ•°åƒäº¿è‡³ä¸‡äº¿ï¼‰ï¼Œä»£ä»·è¾ƒä½**            |
| **å•ä¸ªTokenè®¡ç®—æˆæœ¬ï¼ˆç›¸å¯¹ï¼‰** | é«˜ï¼ˆä¸æ¨¡å‹æ€»å®¹é‡æˆæ­£æ¯”ï¼‰                 | **ä½ï¼ˆä»…ä¸å°‘é‡ä¸“å®¶å®¹é‡ç›¸å…³ï¼Œçº¦ä¸ºç¨ å¯†æ¨¡å‹çš„1.5-3å€ï¼‰** |
| **æ¨ç†æ•ˆç‡ï¼ˆåå/å»¶è¿Ÿï¼‰** | è¾ƒä½ï¼ˆæ— æ³•åˆ©ç”¨ç¨€ç–æ€§ï¼‰                     | **ç†è®ºä¸Šé«˜ï¼ˆä»…è®¡ç®—å°‘é‡ä¸“å®¶ï¼‰ï¼Œä½†å—é€šä¿¡/æ˜¾å­˜ç­‰é™åˆ¶**    |
| **æ˜¾å­˜å ç”¨**   | ç›¸å¯¹ä½ï¼ˆä¸æ¨¡å‹å‚æ•°è§„æ¨¡ç›¸å½“ï¼‰               | **éå¸¸é«˜ï¼ˆéœ€åŠ è½½æ‰€æœ‰ä¸“å®¶å‚æ•°ï¼Œè¿œè¶…è®¡ç®—æˆæœ¬æ‰€éœ€ï¼‰**      |
| **è®­ç»ƒå¤æ‚åº¦** | ç›¸å¯¹ç®€å•ã€æˆç†Ÿ                           | **å¤æ‚ï¼ˆè·¯ç”±éš¾è®­ç»ƒï¼Œè´Ÿè½½å¹³è¡¡ï¼Œé€šä¿¡å¼€é”€å¤§ï¼‰**         |
| **ä¸»è¦ä¼˜åŠ¿**   | ç®€å•ã€ç¨³å¥ã€æ˜“éƒ¨ç½²                         | **åœ¨å¯æ§è®¡ç®—æˆæœ¬ä¸‹è¾¾åˆ°æé«˜æ¨¡å‹å®¹é‡å’Œæ½œåŠ›æ€§èƒ½**        |
| **æ ¸å¿ƒæŒ‘æˆ˜**   | æå‡å®¹é‡å¯¼è‡´è®¡ç®—æˆæœ¬å‰§å¢                   | **æ˜¾å­˜éœ€æ±‚ã€é€šä¿¡å¼€é”€ã€è®­ç»ƒç¨³å®šæ€§ï¼ˆè·¯ç”±ã€è´Ÿè½½å¹³è¡¡ï¼‰** |

**ç®€å•æ¥è¯´ï¼š**

*   **éMoEæ¨¡å‹ï¼š** å°±åƒä¸€ä¸ªå¤§å‹å§”å‘˜ä¼šï¼Œæ¯ä¸ªäººï¼ˆå‚æ•°ï¼‰æ¯æ¬¡ä¼šè®®ï¼ˆå¤„ç†æ¯ä¸ªTokenï¼‰éƒ½å¿…é¡»å·¥ä½œå‘è¨€ï¼ˆå‚ä¸è®¡ç®—ï¼‰ï¼Œæ•ˆç‡ä¸é«˜ã€‚
*   **MoEæ¨¡å‹ï¼š** åƒä¸€ä¸ªæ‹¥æœ‰å¤§é‡ä¸“å®¶ï¼ˆå¯èƒ½å‡ ç™¾ä¸ªï¼‰çš„å…¬å¸ï¼Œæ¯å°é‚®ä»¶ï¼ˆæ¯ä¸ªTokenï¼‰è¿›æ¥æ—¶ï¼Œä¸€ä¸ªæ™ºèƒ½è·¯ç”±å™¨ï¼ˆé—¨æ§ï¼‰ä¼šå¿«é€Ÿå†³å®šè¿™å°é‚®ä»¶æœ€é€‚åˆäº¤ç»™å“ª1-2ä¸ªä¸“å®¶å¤„ç†ã€‚è¿™æ ·ç»å¤§éƒ¨åˆ†ä¸“å®¶åœ¨ç»å¤§éƒ¨åˆ†æ—¶é—´éƒ½åœ¨ä¼‘æ¯ï¼ˆä¸æ¿€æ´»ï¼‰ï¼Œå…¬å¸æ•´ä½“æ•ˆç‡é«˜ï¼ˆè®¡ç®—å°‘ï¼‰ï¼Œæ‹¥æœ‰çš„çŸ¥è¯†åº“ï¼ˆæ€»å‚æ•°é‡ï¼‰å´å¯ä»¥éå¸¸åºå¤§ã€‚**æ ¸å¿ƒæ˜¯â€œèƒ½åŠ›æŒ‰éœ€åˆ†é…â€ã€‚**

MoEæ¨¡å‹çš„å‡ºç°æ˜¯ä¸ºäº†çªç ´æ¨¡å‹å®¹é‡ï¼ˆå‚æ•°é‡ï¼‰ä¸è®¡ç®—æˆæœ¬/æ•ˆç‡ä¹‹é—´çš„ç“¶é¢ˆï¼Œä½¿å¾—æ„å»ºä¸‡äº¿å‚æ•°çº§åˆ«çš„æ¨¡å‹åœ¨å¯æ¥å—çš„è®¡ç®—å¼€é”€ä¸‹æˆä¸ºå¯èƒ½ã€‚ç„¶è€Œï¼Œè¿™ä¹Ÿå¸¦æ¥äº†æ˜¾è‘—çš„æ˜¾å­˜å’Œç³»ç»Ÿå·¥ç¨‹æŒ‘æˆ˜ã€‚

## 2 - Top-K Routing / Hash Routing

![Top-K Routing / Hash Routing](https://pica.zhimg.com/v2-2481439c1ce4719846c37e4ade67b466_r.jpg)

![Top-K Routing](https://picx.zhimg.com/v2-663ce5d61316a5e242740a2cbf7c94b5_1440w.jpg)

| ç‰¹æ€§              | Top-K Routing (è½¯è·¯ç”±)                       | Hash Routing (ç¡¬è·¯ç”±)                         |
|------------------|---------------------------------------------|----------------------------------------------|
| **æ ¸å¿ƒåŸç†**      | â€¢ å¯å­¦ä¹ é—¨æ§ç½‘ç»œè®¡ç®—ä¸“å®¶æƒé‡(Softmax) <br>â€¢ é€‰æ‹© Top-K <br>â€¢ ä¸“å®¶åŠ æƒè¾“å‡º | â€¢ å›ºå®šå“ˆå¸Œå‡½æ•°å¤„ç† `token_id`/`position_id`<br>â€¢ å“ˆå¸Œå€¼å–æ¨¡ `% N` åˆ†é…ä¸“å®¶ <br>â€¢ å›ºå®šåˆ†é…å•ä¸€ä¸“å®¶è¾“å‡º |
| **è®¾è®¡å“²å­¦**      | **æ™ºèƒ½åŒ¹é…ã€ä¸“ä¸šåŒ–ä¼˜å…ˆã€å¯æ§ç¨€ç–** <br>â€¢ å­¦ä¹  Token è¯­ä¹‰ä¸ä¸“å®¶èƒ½åŠ›åŒ¹é… <br>â€¢ `K` æ§åˆ¶ç¨€ç–åº¦ä¸é²æ£’æ€§ <br>â€¢ è¿½æ±‚æœ€å¤§åŒ–æ•´ä½“æ¨¡å‹è´¨é‡ä¸è¡¨è¾¾èƒ½åŠ› | **æè‡´ç®€å•ã€å‡è¡¡ä¼˜å…ˆã€é›¶å¼€é”€è·¯ç”±** <br>â€¢ è·¯ç”±è§„åˆ™é¢„å®šä¹‰ä¸”é›¶å­¦ä¹ æˆæœ¬ <br>â€¢ ä¾èµ–å“ˆå¸Œæ•°å­¦ç‰¹æ€§å¤©ç„¶å‡è¡¡ <br>â€¢ è¿½æ±‚æœ€å°è·¯ç”±å¼€é”€ä¸æœ€å¤§è®¡ç®—åˆ©ç”¨ç‡ |
| **å…³é”®ä¼˜åŠ¿**      | â€¢ æ™ºèƒ½è·¯ç”±ï¼Œä¸“å®¶å¯ä¸“ä¸šåŒ– <br>â€¢ è¡¨è¾¾æ½œåŠ›å¤§ <br>â€¢ é²æ£’æ€§å¥½ (`K>1`)    | â€¢ è·¯ç”±é€Ÿåº¦æå¿«ï¼Œé›¶å­¦ä¹ å¼€é”€ <br>â€¢ å¤©ç„¶è´Ÿè½½å‡è¡¡ï¼ˆç†æƒ³åˆ†å¸ƒä¸‹ï¼‰<br>â€¢ å®ç°å¼‚å¸¸ç®€å• <br>â€¢ è´Ÿè½½ç»å¯¹å‡è¡¡ (ç†æƒ³æƒ…å†µ) |
| **æ ¸å¿ƒç¼ºç‚¹**      | â€¢ è·¯ç”±ç½‘ç»œéœ€å­¦ä¹ ï¼Œéš¾ä¼˜åŒ– <br>â€¢ è´Ÿè½½å‡è¡¡æ˜¯é‡å¤§æŒ‘æˆ˜ (éœ€é¢å¤–çº¦æŸ) <br>â€¢ é—¨æ§è®¡ç®—æœ‰å°å¼€é”€ | â€¢ **æ— æ³•å®ç°ä¸“å®¶ä¸“ä¸šåŒ–ï¼ˆæœ€å¤§ç¼ºç‚¹ï¼ï¼‰**<br>â€¢ è·¯ç”±åƒµåŒ–ï¼Œä¸è¯­ä¹‰æ— å…³ <br>â€¢ æ¨¡å‹æ½œåŠ›ä¸Šé™ä½ <br>â€¢ æ€§èƒ½ä¾èµ–è¾“å…¥åˆ†å¸ƒå‡è®¾ |
| **ä¸“å®¶è§’è‰²**      | ä¸“ä¸šåˆ†åŒ–ï¼Œå„æœ‰æ‰€é•¿                           | åŸºæœ¬ç­‰åŒï¼ˆæˆ–éšæœºå·®å¼‚ï¼‰ï¼Œä»…ä¸ºå¹¶è¡Œè®¡ç®—å•å…ƒ           |
| **è´Ÿè½½å‡è¡¡**      | ä¸¥é‡æŒ‘æˆ˜ï¼Œéœ€è®¾è®¡ä¿è¯æœºåˆ¶ (è¾…åŠ©æŸå¤±/Capacity)     | å¤©ç„¶è¾ƒå‡è¡¡ï¼ˆä¾èµ–å“ˆå¸Œå‡åŒ€æ€§ï¼‰ï¼Œæ— éœ€é¢å¤–æœºåˆ¶          |
| **è·¯ç”±ç±»å‹**      | **è½¯è·¯ç”±** (å«æƒé‡èåˆ)                      | **ç¡¬è·¯ç”±** (å•ä¸€ä¸“å®¶è¾“å‡º)                     |
| **è®¡ç®—å¼€é”€**      | æœ‰ï¼ˆé—¨æ§ç½‘ç»œè®¡ç®—ï¼Œä½†é€šå¸¸è¾ƒå°ï¼‰                 | å‡ ä¹ä¸ºé›¶                                     |
| **ç³»ç»Ÿå¤æ‚åº¦**    | è¾ƒé«˜ (åŠ¨æ€è·¯ç”±ï¼Œéœ€é€šä¿¡ä¼˜åŒ–)                   | è¾ƒä½ (è§„åˆ™ç®€å•ï¼Œæ˜“äºé¢„åˆ†é…)                   |
| **ä»£è¡¨åœºæ™¯**      | ç°ä»£ä¸»æµ LLM MoE (å¦‚ Mixtral 8x7Bã€DeepSeek-MoEã€GPT-MoE) | æ—©æœŸæ¢ç´¢ã€æåº¦è¿½æ±‚é€Ÿåº¦/æç®€å®ç°è€Œç‰ºç‰²æ€§èƒ½çš„åœºæ™¯ã€ç‰¹å¾å·¥ç¨‹ä¸ºä¸»çš„ç³»ç»Ÿ |

---

### ğŸ¯ æ€»ç»“ä¸€å¥è¯ç²¾é«“

*   **`Top-K Routing`:** ğŸ’¡ **â€œä¸ºæ¯ä¸ª Token åŠ¨æ€ã€æ™ºèƒ½åœ°é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸¤ä¸ªä¸“å®¶ï¼ˆKä¸ªï¼‰ï¼Œç›®æ ‡æ˜¯æœ€å¤§ç¨‹åº¦æå‡æ¨¡å‹è´¨é‡å’Œä¸“ä¸šåˆ†å·¥æ½œåŠ›ã€‚â€**
*   **`Hash Routing`:** âš¡ **â€œä»¥æœ€å¿«é€Ÿåº¦ã€é›¶å¼€é”€ã€å®Œå…¨å…¬å¹³åœ°å°† Token éšæœºåˆ†é…ï¼ˆK=1ï¼‰ç»™ä¸“å®¶è¿è¡Œï¼Œç›®æ ‡æ˜¯æœ€å¤§åŒ–ç³»ç»Ÿååå’Œè®¡ç®—åˆ©ç”¨ç‡ã€‚â€**

> é€‰æ‹©å“ªæ¡è·¯ï¼Œå–å†³äºä½ çš„ **æ ¸å¿ƒç›®æ ‡**ï¼š
> * ç›®æ ‡æ˜¯æ‰“é€  *æœ€æœ‰æ½œåŠ›çªç ´æ€§èƒ½æé™* çš„å¤§æ¨¡å‹ï¼Ÿé€‰ **`Top-K` è·¯ç”±**ï¼ˆå°½ç®¡è®­ç»ƒæŒ‘æˆ˜å¤§ï¼‰ã€‚
> * ç›®æ ‡æ˜¯ *åœ¨ç‰¹å®šç³»ç»Ÿé™åˆ¶ä¸‹è·‘å¾—æœ€å¿«*ï¼Ÿé€‰ **`Hash è·¯ç”±`**ï¼ˆä½†éœ€æ¥å—æ€§èƒ½å¤©èŠ±æ¿ï¼‰ã€‚

## 3 - Shared experts

![Shared experts](https://pic2.zhimg.com/v2-e42c56107573a1e06d9f1742a4a97f15_1440w.jpg)

![Shared experts](https://pic2.zhimg.com/v2-9ceae9a6039edfc9f972d55a8050c6eb_1440w.jpg)

## 4 - Noisy Top-K Gating

åœ¨ MoE å‘å±•å†ç¨‹ä¸­ï¼Œ**Shazeer et al. 2017 æå‡ºçš„ã€ŒNoisy Top-K Gatingã€** æ˜¯å¥ åŸºæ€§å·¥ä½œä¹‹ä¸€ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š**åœ¨è·¯ç”±åˆ†æ•°ä¸­æ·»åŠ é«˜æ–¯å™ªå£°ï¼Œä»¥æå‡æ¨¡å‹æ¢ç´¢èƒ½åŠ›å¹¶ç¼“è§£è´Ÿè½½ä¸å‡è¡¡é—®é¢˜**ï¼Œæˆä¸ºç°ä»£ MoE è·¯ç”±æ ‡å‡†è®¾è®¡çš„èµ·ç‚¹ã€‚ä¸‹é¢ä»**åŸç†æœ¬è´¨ã€è®­ç»ƒç›®æ ‡ã€å®ç°ç»†èŠ‚**è¿›è¡Œæ·±å…¥å‰–æï¼š

---

### ğŸ§  ä¸€ã€æ ¸å¿ƒè®¾è®¡åŸç†

#### 1. **åŸºæœ¬ç›®æ ‡ï¼šè§£å†³ MoE è®­ç»ƒä¸¤å¤§ç—›ç‚¹**
   - **æ¢ç´¢ä¸è¶³ï¼ˆExplorationï¼‰**ï¼šè·¯ç”±ç½‘ç»œæ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼ˆæ€»æ˜¯é€‰æŸå‡ ä¸ªä¸“å®¶ï¼‰ï¼Œå…¶ä»–ä¸“å®¶æœªè¢«è®­ç»ƒï¼ˆâ€œæ­»ä¸“å®¶â€é—®é¢˜ï¼‰ã€‚
   - **è´Ÿè½½ä¸å‡è¡¡ï¼ˆLoad Imbalanceï¼‰**ï¼šå°‘æ•°ä¸“å®¶è¢«è¿‡åº¦æ¿€æ´»ï¼Œå¤šæ•°ä¸“å®¶é—²ç½®ã€‚

#### 2. **æ ¸å¿ƒåˆ›æ–°ï¼šå¸¦å™ªåˆ†æ•° = è·¯ç”±ä¿¡å· + é«˜æ–¯å™ªå£°**
   - è·¯ç”±å†³ç­–ä»ä¾èµ– **Top-K é€‰æ‹©**ï¼Œä½†è®¡ç®—åˆ†æ•°æ—¶å¼•å…¥æ‰°åŠ¨ï¼š
     $$ \tilde{s}_i = \frac{s_i + \epsilon_i \cdot W_{\text{noise}}}{\text{temperature}} $$
     - $s_i$ï¼šåŸå§‹è·¯ç”±åˆ†æ•°ï¼ˆ`router_network(x)`)
     - $\epsilon_i \sim \mathcal{N}(0, 1)$ï¼šç‹¬ç«‹é«˜æ–¯å™ªå£°
     - $W_{\text{noise}}$ï¼š**å¯å­¦ä¹ çš„å™ªå£°ç¼©æ”¾å› å­**ï¼ˆå…³é”®ï¼ï¼‰
     - $\text{temperature}$ï¼šè½¯åŒ–å‚æ•°ï¼ˆâ‰ˆ1.0ï¼‰

#### 3. **å™ªå£°çš„ä½œç”¨æœºåˆ¶ï¼š**
   - **è®­ç»ƒåˆæœŸ**ï¼š$W_{\text{noise}}$ è¾ƒå¤§ â†’ å™ªå£°æ˜¾è‘— â†’ è·¯ç”±é€‰æ‹©æœ‰**å¼ºéšæœºæ€§**ï¼ˆå¢åŠ æ¢ç´¢ï¼‰ã€‚
   - **è®­ç»ƒåæœŸ**ï¼šæ¨¡å‹å­¦ä¹ é™ä½ $W_{\text{noise}}$ â†’ å™ªå£°å‡å¼± â†’ è·¯ç”±æ”¶æ•›è‡³**ç¡®å®šæ€§ç­–ç•¥**ï¼ˆæ›´å¥½åˆ©ç”¨ä¸“å®¶ï¼‰ã€‚
   - **è´Ÿè½½å‡è¡¡å¼•å¯¼**ï¼šå™ªå£°ä½¿ã€Œè¿‡åº¦çƒ­é—¨ä¸“å®¶ã€çš„åˆ†æ•°å‘ç”Ÿæ³¢åŠ¨ï¼Œå¶å°”è¢«æŠ‘åˆ¶ï¼Œè®©å†·é—¨ä¸“å®¶æœ‰æœºä¼šè¢«é€‰ä¸­ã€‚

#### 4. **æ•°å­¦ç›®æ ‡ï¼šè‡ªåŠ¨å­¦ä¹ æ¢ç´¢å¼ºåº¦**
   $$ \min_{\theta, W_{\text{noise}}} \mathbb{E} \left[ \mathcal{L}_{\text{task}} + \lambda \cdot \text{Load\_Loss} \right] $$
   - é€šè¿‡æ¢¯åº¦ä¸‹é™å­¦ä¹  $W_{\text{noise}}$ï¼Œ**è®©æ¨¡å‹è‡ªè¡Œå†³å®šä½•æ—¶éœ€å™ªå£°ã€ç”¨å¤šå¤§å™ªå£°**ã€‚

---

### âš™ï¸ äºŒã€å…·ä½“å®ç°æ­¥éª¤ï¼ˆä»£ç çº§æ‹†è§£ï¼‰

ä»¥ä¸‹æ˜¯ **Shazeer et al. 2017** çš„ Noisy Top-K Routing çš„å®Œæ•´è®­ç»ƒæµç¨‹å®ç°ï¼ˆä»¥ PyTorch é£æ ¼ä¸ºä¾‹ï¼‰ï¼š

#### æ­¥éª¤ 1: å®šä¹‰è·¯ç”±å™¨åŠå™ªå£°å‚æ•°
```python
class NoisyTopKRouter(nn.Module):
    def __init__(self, input_dim, num_experts, k=2, init_noise=1.0):
        super().__init__()
        self.k = k
        self.w_gate = nn.Linear(input_dim, num_experts, bias=False) # è·¯ç”±æƒé‡
        self.w_noise = nn.Parameter(torch.ones(1) * init_noise)   # å¯å­¦å™ªå£°ç¼©æ”¾å› å­

    def forward(self, x, train_mode=True):
        # x: [batch_size, seq_len, hidden_dim]
        s = self.w_gate(x)  # [batch, seq_len, num_experts]
        
        if not train_mode:
            # æ¨ç†æ—¶ï¼šæ— å™ªå£°ï¼Œç›´æ¥ Top-K
            probs = torch.softmax(s, dim=-1)
            topk_probs, topk_idx = probs.topk(self.k, dim=-1)
            return topk_probs, topk_idx
        
        # ============= è®­ç»ƒæ—¶ï¼šæ³¨å…¥é«˜æ–¯å™ªå£° =============
        # ç”Ÿæˆä¸ s åŒå½¢çš„æ ‡å‡†é«˜æ–¯å™ªå£° (ç‹¬ç«‹åŒåˆ†å¸ƒ)
        eps = torch.randn_like(s)  # Ïµ ~ N(0,1)
        
        # å™ªå£°ç¼©æ”¾ï¼šsÌƒ_i = s_i + w_noise * Ïµ_i
        s_noisy = s + self.w_noise * eps
        
        # è®¡ç®—å¸¦å™ªå£°çš„ softmax æ¦‚ç‡
        probs_noisy = torch.softmax(s_noisy, dim=-1)
        
        # é€‰ Top-K ä¸ªä¸“å®¶åŠå…¶åŸå§‹åˆ†æ•°ï¼ˆéå™ªå£°åˆ†æ•°ï¼ï¼‰
        topk_probs, topk_idx = probs_noisy.topk(self.k, dim=-1)
        
        return topk_probs, topk_idx  # è¿”å›å™ªå£°æ¦‚ç‡ & ä¸“å®¶ç´¢å¼•
```

#### æ­¥éª¤ 2ï¼šå‰å‘ä¼ æ’­æ—¶è°ƒç”¨è·¯ç”±å™¨ â†’ è®¡ç®— MoE å±‚è¾“å‡º
```python
def moe_layer(x, router, experts):
    # è®­ç»ƒæ¨¡å¼ï¼šè°ƒç”¨å¸¦å™ªå£°çš„è·¯ç”±
    topk_probs, topk_idx = router(x, train_mode=True)  # probs: [B, S, K], idx: [B, S, K]
    batch_size, seq_len, _ = x.shape
    
    # æ„é€ æ‰å¹³åŒ–è¾“å…¥ï¼ˆæ–¹ä¾¿å¹¶è¡Œè®¡ç®—ï¼‰
    x_flat = x.view(-1, x.shape[-1])                 # [B*S, D]
    topk_idx_flat = topk_idx.view(-1, topk_idx.shape[-1]) # [B*S, K]
    
    # ä¸ºæ¯ä¸ªTokenè®¡ç®— K ä¸ªä¸“å®¶çš„è¾“å‡ºï¼ˆå¹¶è¡Œæ‰€æœ‰ä¸“å®¶ï¼‰
    expert_inputs = x_flat.unsqueeze(1).repeat(1, router.k, 1) # [B*S, K, D]
    
    # æ”¶é›†é€‰ä¸­çš„ä¸“å®¶ç´¢å¼• -> æ˜ å°„ä¸ºä¸“å®¶æ¨¡å—è®¡ç®—
    expert_outputs = []
    for k in range(router.k):
        expert_k = topk_idx_flat[:, k]  # ç¬¬kä¸ªä¸“å®¶ç´¢å¼• [B*S]
        # å°†è¾“å…¥è·¯ç”±ç»™è¯¥ä¸“å®¶å¤„ç†ï¼ˆéœ€é«˜æ•ˆå®ç°ï¼Œå¦‚ group_by æˆ– scatterï¼‰
        out_k = expertsexpert_inputs[:, k, :]
        expert_outputs.append(out_k)
    # â†’ è¾“å‡º [B*S, K, D_out]

    # åŠ æƒèåˆï¼šy = âˆ‘(weight_k * output_k)
    weights = topk_probs.view(-1, router.k).unsqueeze(-1) # [B*S, K, 1]
    y_flat = torch.sum(weights * expert_outputs, dim=1)    # [B*S, D_out]
    
    # æ¢å¤åºåˆ—ç»“æ„
    y = y_flat.view(batch_size, seq_len, -1)
    return y
```

#### æ­¥éª¤ 3ï¼šæ·»åŠ è´Ÿè½½å‡è¡¡æŸå¤±ï¼ˆLoad Balancing Lossï¼‰ååŒä¼˜åŒ–
```python
def load_balancing_loss(router_probs, expert_idx):
    # router_probs: [batch, seq, K] é€‰å„ä¸“å®¶çš„æ¦‚ç‡
    # expert_idx:   [batch, seq, K] é€‰çš„ä¸“å®¶ID
    
    # è®¡ç®—æ¯ä¸ªä¸“å®¶çš„ã€Œè¢«é€‰æ¦‚ç‡ã€ï¼ˆbatchå†…å¹³å‡ï¼‰
    batch, seq, k = router_probs.shape
    num_experts = router.num_experts
    
    # æ„é€ ä¸“å®¶è´Ÿè½½æŒ‡ç¤ºçŸ©é˜µï¼ˆç¨€ç– â†’ ç¨ å¯†ï¼‰
    expert_mask = torch.zeros(batch * seq, num_experts, device=x.device) # [B*S, E]
    expert_mask.scatter_(1, expert_idx.view(-1, k), 1.0)  # [B*S, E] â†’ 1è¡¨ç¤ºè¢«é€‰ä¸­
    
    # æ¯ä¸ªTokençš„Kä¸ªä¸“å®¶æƒé‡ä¹‹å’Œ = 1ï¼Œå› æ­¤æŒ‰Tokenå¹³å‡å³è´Ÿè½½æœŸæœ›
    load_per_expert = expert_mask.mean(dim=0)  # [E]
    
    # æŸå¤±ï¼šL_balance = (è´Ÿè½½æœŸæœ›)çš„å¹³æ–¹å’Œ â†’ é¼“åŠ±å‡åŒ€åˆ†é…
    balancing_loss = torch.sum(load_per_expert ** 2) * num_experts
    return balancing_loss

# æ€»æŸå¤± = ä»»åŠ¡æŸå¤± + Î» * å‡è¡¡æŸå¤±
total_loss = loss_task + 0.01 * load_balancing_loss(topk_probs, topk_idx)
```

#### å…³é”®è®­ç»ƒåŠ¨æ€ç¤ºæ„ï¼š
```text
          è®­ç»ƒæ—©æœŸ                                    è®­ç»ƒåæœŸ
s_i    :  [1.0, 0.5, -0.1]                     [2.1, 0.2, 0.1]
W_noise:  1.0 (åˆå§‹)                            0.01 (å­¦ä¹ æ”¶æ•›)
Ïµ_i    :  [1.3, -0.7, 0.5] (éšæœºé‡‡æ ·)            [0.01, -0.02, 0.001] (å¾®å°å™ªå£°)
sÌƒ_i    :  [2.3, -0.2, 0.4]                     [2.11, 0.18, 0.101] 
â†’ ä¸“å®¶é€‰æ‹©ï¼šæ³¢åŠ¨å¤§ï¼ˆExploreï¼‰                     â†’ ç¨³å®šé€‰æ‹©ç¬¬ä¸€ä¸ªä¸“å®¶ï¼ˆExploitï¼‰
```

---

### ğŸ“Œ ä¸‰ã€å·¥ç¨‹ä¼˜åŒ–è¦ç‚¹ï¼ˆç°ä»£æ¼”è¿›ï¼‰

1. **é—¨æ§ç®€åŒ–**ï¼šåç»­å·¥ä½œï¼ˆå¦‚ Switch Transformerï¼‰å°†é—¨æ§ç½‘ç»œç®€åŒ–ä¸º â†’ `s = x @ W_gate`ï¼ˆæ— åç½®é¡¹ï¼‰ã€‚
2. **å™ªå£°å‚æ•°å…±äº«**ï¼šä¸€ä¸ª `W_noise` æ§åˆ¶æ‰€æœ‰ä¸“å®¶çš„å™ªå£°å¼ºåº¦ã€‚
3. **åˆ†ä¸“å®¶å™ªå£°**ï¼šæ›´ç²¾ç»†åšæ³•æ˜¯æ¯ä¸ªä¸“å®¶ç‹¬ç«‹å­¦ `w_noise_i`ï¼ˆå‚æ•°é‡å¢ä½†æ›´çµæ´»ï¼‰ã€‚
4. **ç»“åˆ Gumbel**ï¼šåæœŸå°†é«˜æ–¯å™ªå£°æ”¹ä¸º **Gumbelå™ªå£°**ï¼ˆæ”¯æŒç²¾å‡† Top-K é‡‡æ ·ï¼‰ï¼Œå½¢æˆå½“å‰ä¸»æµæ–¹æ³•ã€‚
5. **æ¸©åº¦é€€ç«**ï¼šä¸ Gumbel-softmax ç±»ä¼¼ï¼Œè®¾ç½®é™æ¸©ç­–ç•¥ `temperature = max(0.1, 1 - step/10000)`ã€‚

---

### ğŸ’ å››ã€æ€»ç»“ï¼šNoise in Routing çš„ä»·å€¼

> ğŸ”¥ **Shazeer çš„ã€Œå™ªå£°è·¯ç”±ã€æœ¬è´¨æ˜¯å°†ã€Œæ¢ç´¢-åˆ©ç”¨å›°å¢ƒã€å»ºæ¨¡ä¸ºå¯å­¦ä¹ è¿‡ç¨‹ï¼š  
> â€ƒâ€ƒâ€”â€” è®­ç»ƒåˆæœŸä»¥é«˜æ–¯å™ªå£°æ³¨å…¥å¼ºæ¢ç´¢ï¼Œæ‰“ç ´ä¸“å®¶å†·å¯åŠ¨ï¼›  
> â€ƒâ€ƒâ€”â€” è®­ç»ƒåæœŸå™ªå£°è¡°å‡ï¼Œè·¯ç”±æ”¶æ•›åˆ°é«˜æ•ˆç¡®å®šæ€§ç­–ç•¥ï¼›  
> â€ƒâ€ƒâ€”â€” å¯å­¦çš„ `W_noise` è®©æ¨¡å‹è‡ªå·±æŒæ¡æ¢ç´¢èŠ‚å¥ï¼Œ  
> â€ƒâ€ƒâ€”â€” è´Ÿè½½æŸå¤±è¿«ä½¿ä¸“å®¶è´Ÿè½½åˆ†å¸ƒæ›´å‡è¡¡ã€‚**

è¿™ç§è®¾è®¡æ€æƒ³åœ¨ **GShardã€Switch Transformerã€GLaMã€T5-MoE** ä¸­å‡è¢«ç»§æ‰¿ä¸æå‡ï¼Œå¥ å®šäº†ä¸‡äº¿çº§ç¨€ç–å¤§æ¨¡å‹çš„åŸºç¡€ã€‚å¦‚æœä½ æ­£å¤ç°ç»å…¸MoEæˆ–è®¾è®¡æ–°å‹è·¯ç”±å™¨ï¼ŒShazeer 2017 ä»æ˜¯å¿…ç»ä¹‹è·¯ï¼ğŸš€

## 5 - Stochastic Jitter

Fedus ç­‰äººåœ¨ 2022 å¹´ Switch Transformer å·¥ä½œä¸­æå‡ºçš„ **Stochastic Jitterï¼ˆéšæœºæŠ–åŠ¨ï¼‰** æ˜¯ä¸€ç§æ–°é¢–çš„è·¯ç”±æ‰°åŠ¨ç­–ç•¥ï¼Œæ—¨åœ¨ç¼“è§£ä¸“å®¶è„†å¼±æ€§å¹¶æå‡æ¨¡å‹é²æ£’æ€§ã€‚ä¸ Shazeer çš„åŠ æ€§é«˜æ–¯å™ªå£°ä¸åŒï¼ŒStochastic Jitter é‡‡ç”¨**ä¹˜æ³•å¼å‡åŒ€æ‰°åŠ¨**å®ç°æ›´å¯æ§çš„æ¢ç´¢æœºåˆ¶ã€‚ä»¥ä¸‹ä»**è®¾è®¡åŸç†ã€æ•°å­¦æœ¬è´¨åˆ°ä»£ç å®ç°**æ·±å…¥è§£æå…¶å·¥ä½œæµç¨‹ï¼š

---

### ğŸ” ä¸€ã€æ ¸å¿ƒè®¾è®¡åŸç†ä¸ç›®æ ‡

#### ğŸ§  è®¾è®¡èƒŒæ™¯ï¼š
- **é—®é¢˜ï¼š** MoE è·¯ç”±æ˜“æ”¶æ•›è‡³**å°‘æ•°å›ºå®šä¸“å®¶ç»„åˆ**ï¼ˆBrittle Expertsï¼‰ï¼Œå¯¼è‡´ï¼š
  1. **ä¸“å®¶åˆ©ç”¨ä¸è¶³**ï¼ˆUnderutilizationï¼‰
  2. **è´Ÿè½½ä¸¥é‡å¤±è¡¡**
  3. **æ¨¡å‹æ˜“å—è¾“å…¥æ‰°åŠ¨å½±å“**
- **ç›®æ ‡ï¼š** åœ¨**ä¸æ˜¾è‘—å¢åŠ è®¡ç®—å¼€é”€**å‰æä¸‹ï¼Œå‘è·¯ç”±å†³ç­–æ³¨å…¥**å¯æ§éšæœºæ€§**ä»¥æå‡é²æ£’æ€§ã€‚

#### âš¡ åˆ›æ–°ç‚¹ï¼š**å‡åŒ€åˆ†å¸ƒä¹˜æ³•æ‰°åŠ¨**
- **æ‰°åŠ¨å…¬å¼**ï¼š
  $$
  \tilde{s}_i = s_i \times (1 + \epsilon_i)
  $$
  - åŸå§‹è·¯ç”±åˆ†æ•° $s_i$ï¼ˆè·¯ç”±å±‚è¾“å‡ºï¼‰
  - $\epsilon_i \sim \text{Uniform}(-c, +c)$ï¼š**å‡åŒ€åˆ†å¸ƒå™ªå£°**ï¼Œ$c$ ä¸ºæ‰°åŠ¨å¹…åº¦ï¼ˆå¦‚ 0.5ï¼‰
- **æœ¬è´¨**ï¼šå¯¹è·¯ç”±åˆ†æ•°è¿›è¡Œ**æ¯”ä¾‹ç¼©æ”¾**è€ŒéåŠ å‡å¼åç§»

#### ğŸ’¡ å…³é”®ç‰¹æ€§ï¼š
| **ç»´åº¦**        | **Stochastic Jitter**                     | **Shazeer Gaussian Noise**          |
|-----------------|-------------------------------------------|-------------------------------------|
| **å™ªå£°ç±»å‹**     | âŒ å‡åŒ€åˆ†å¸ƒï¼ˆUniformï¼‰ä¹˜æ³•æ‰°åŠ¨              | âœ… é«˜æ–¯åˆ†å¸ƒï¼ˆGaussianï¼‰åŠ æ³•æ‰°åŠ¨       |
| **æ‰°åŠ¨æ–¹å‘**     | â•â– åˆ†æ•°æŒ‰æ¯”ä¾‹ç¼©æ”¾ï¼ˆScalingï¼‰                | â•â– åˆ†æ•°çº¿æ€§åç§»ï¼ˆOffsetï¼‰           |
| **å‚æ•°æ€§è´¨**     | âš ï¸ å›ºå®šå¹…åº¦ $c$ï¼ˆè¶…å‚ï¼‰                     | âœ… å¯å­¦ä¹ å™ªå£°æƒé‡ $W_{\text{noise}}$ |
| **å½±å“èŒƒå›´**     | ğŸ”„ åˆ†æ•°è¶Šé«˜ï¼Œæ‰°åŠ¨ç»å¯¹å¹…åº¦è¶Šå¤§ï¼ˆç›¸å¯¹ç¨³å®šï¼‰      | ğŸ”„ æ‰€æœ‰åˆ†æ•°åŒç­‰å¹…åº¦éœ‡è¡              |

> ğŸ”¥ **è®¾è®¡å“²å­¦ï¼š**  
> **â€œé€šè¿‡æ¯”ä¾‹æ‰°åŠ¨ä¿ç•™åˆ†æ•°é—´ç›¸å¯¹å…³ç³»ï¼Œé¿å…ä½åˆ†ä¸“å®¶è¢«éšæœºå™ªå£°è¿‡åº¦æ¿€æ´»ï¼Œä½¿æ¢ç´¢è¿‡ç¨‹æ›´å…·æ–¹å‘æ€§â€**

---

### âš™ï¸ äºŒã€å·¥ä½œæµç¨‹ä¸å…·ä½“å®ç°

#### ğŸ“œ ä¼ªä»£ç æµç¨‹ï¼š
```
è¾“å…¥ï¼štoken å‘é‡ x, æŠ–åŠ¨å¹…åº¦ c, ä¸“å®¶æ•° N
1. s = router_network(x)                   // è®¡ç®—åŸå§‹è·¯ç”±åˆ†æ•° [s1, s2, ..., sN]
2. å¯¹æ¯ä¸ª s_i ç”Ÿæˆæ‰°åŠ¨å™ªå£°ï¼š
      Îµ_i = Uniform(-c, +c)               // å‡åŒ€é‡‡æ ·å™ªå£°
      sÌƒ_i = s_i * (1 + Îµ_i)                // ä¹˜æ³•æ‰°åŠ¨
3. p_i = Softmax(sÌƒ_i)                      // è®¡ç®—å¸¦æ‰°åŠ¨æ¦‚ç‡
4. é€‰å– Top-K ä¸“å®¶ç´¢å¼•ï¼ˆåŸºäº p_iï¼‰
5. åŠ æƒè®¡ç®—ä¸“å®¶è¾“å‡ºï¼šy = âˆ‘(w_i * Expert_i(x))
```

#### ğŸ Python å®ç°ï¼ˆPyTorchï¼‰
```python
class StochasticJitterRouter(nn.Module):
    def __init__(self, input_dim, num_experts, k=1, jitter_ratio=0.5):
        super().__init__()
        self.k = k
        self.jitter_ratio = jitter_ratio  # æ‰°åŠ¨æ¯”ä¾‹ c (e.g. 0.5)
        self.router = nn.Linear(input_dim, num_experts)  # è·¯ç”±å±‚

    def forward(self, x, training=True):
        # åŸå§‹è·¯ç”±åˆ†æ•° [batch, seq_len, num_experts]
        s = self.router(x)  
        
        if not training:
            # æ¨ç†æ¨¡å¼ï¼šæ— æ‰°åŠ¨
            probs = torch.softmax(s, dim=-1)
            return probs.topk(self.k, dim=-1)  # topk_probs, topk_indices
        
        # ========== è®­ç»ƒæ¨¡å¼ï¼šæ³¨å…¥Stochastic Jitteræ‰°åŠ¨ ==========
        # ç”Ÿæˆå‡åŒ€å™ªå£°ï¼šèŒƒå›´ [-c, +c], å½¢çŠ¶ä¸ s ç›¸åŒ
        eps = torch.empty_like(s).uniform_(-self.jitter_ratio, self.jitter_ratio)
        
        # ä¹˜æ³•æ‰°åŠ¨ï¼šsÌƒ_i = s_i * (1 + Îµ_i)
        s_tilde = s * (1 + eps)
        
        # è®¡ç®—æ‰°åŠ¨åæ¦‚ç‡åˆ†å¸ƒ
        probs = torch.softmax(s_tilde, dim=-1)
        
        # é€‰æ‹© Top-K ä¸“å®¶ï¼ˆæ¦‚ç‡ä¸ç´¢å¼•ï¼‰
        topk_probs, topk_idx = probs.topk(self.k, dim=-1)
        return topk_probs, topk_idx
```

#### ğŸ§© MoE å±‚æ•´åˆè°ƒç”¨ï¼š
```python
def switch_moe_layer(x, router, experts):
    batch, seq_len, d_model = x.shape
    x_flat = x.reshape(-1, d_model)  # [batch*seq_len, d_model]
    
    # è·å–è·¯ç”±å†³ç­–ï¼ˆå«æ‰°åŠ¨ï¼‰
    probs, expert_idx = router(x_flat)  # probs: [B*S, K], expert_idx: [B*S, K]
    
    outputs = torch.zeros_like(x_flat)  # å‡†å¤‡è¾“å‡º
    
    # ä¸ºæ¯ä¸ª token å¤„ç†æ‰€é€‰ä¸“å®¶
    for k in range(router.k):
        # åˆ›å»ºä¸“å®¶é€‰æ‹©æ©ç 
        mask = (torch.arange(experts.num_experts, device=x.device)[None,:] 
                == expert_idx[:, k].unsqueeze(1))  # [B*S, E]
        
        # è®¡ç®—æ¯ä¸ªä¸“å®¶å¤„ç†çš„æ•°æ®å­é›†
        for exp_i in range(experts.num_experts):
            token_idx = mask[:, exp_i].nonzero(as_tuple=True)[0]  # é€‰è¯¥ä¸“å®¶çš„token
            if len(token_idx) > 0:
                # è°ƒç”¨ä¸“å®¶å¤„ç†å…¶åˆ†é…åˆ°çš„ token
                expert_in = x_flat[token_idx]  # ä¸“å®¶è¾“å…¥
                expert_out = expertsexpert_in  # ä¸“å®¶è¾“å‡º
                
                # åŠ æƒè¾“å‡º (ä¹˜ä»¥å¯¹åº”è·¯ç”±æƒé‡)
                kth_weight = probs[token_idx, k].unsqueeze(1)  # [tokens, 1]
                outputs[token_idx] += kth_weight * expert_out
    
    # æ¢å¤åŸå§‹å½¢çŠ¶
    return outputs.view(batch, seq_len, d_model)
```

---

### ğŸ“Š ä¸‰ã€åŠ¨æ€æ•ˆæœåˆ†æä¸å‚æ•°è®¾å®š

#### âš–ï¸ æ‰°åŠ¨å¹…åº¦ $c$ çš„å½±å“ï¼š
| **å¹…åº¦ c** | æ¨¡å‹è¡Œä¸º                                                                 | é€‚ç”¨åœºæ™¯                 |
|------------|--------------------------------------------------------------------------|--------------------------|
| **0.0**    | âŒ æ— æ‰°åŠ¨ï¼Œé€€åŒ–è‡³åŸå§‹è·¯ç”±                                                 | åŸºå‡†æµ‹è¯•                 |
| **0.1**    | âš ï¸ å¼±æ‰°åŠ¨ï¼Œä¸“å®¶é€‰æ‹©ç¨³å®šæ€§é«˜                                              | é«˜ç²¾åº¦æ•æ„Ÿä»»åŠ¡           |
| **0.3~0.5**| âœ… æ¨èèŒƒå›´ï¼šå¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨                                               | Switch Transformer é»˜è®¤  |
| **>0.7**   | ğŸ§ª å¼ºæ‰°åŠ¨ï¼Œè·¯ç”±ä¸¥é‡éšæœºåŒ–ï¼ˆå¯èƒ½æŸå®³æ€§èƒ½ï¼‰                                   | éœ€é…åˆæ­£åˆ™é¡¹æ¢ç´¢å®éªŒ     |

#### ğŸ”§ å·¥ç¨‹å»ºè®®ï¼š
1. **æ— éœ€å­¦ä¹ å‚æ•°**ï¼š$c$ å›ºå®šä¸ºè¶…å‚ï¼ˆç®€åŒ–å®ç°ï¼‰
2. **æ¿€æ´»ä½ç½®**ï¼šåœ¨ softmax **å‰**æ–½åŠ æ‰°åŠ¨
3. **åˆ†å¸ƒé€‰æ‹©**ï¼šå‡åŒ€åˆ†å¸ƒï¼ˆUniformï¼‰æ¯”é«˜æ–¯åˆ†å¸ƒæ›´ä¸æ˜“äº§ç”Ÿæç«¯å€¼
4. **ç»„åˆæŠ€å·§**ï¼šä¸ **Load Balancing Loss** é…åˆä½¿ç”¨æ•ˆæœæ›´ä½³ï¼ˆè¯¦è§ä¸‹æ–‡ï¼‰

---

### ğŸ”— å››ã€ä¸è´Ÿè½½å‡è¡¡çš„ååŒä¼˜åŒ–

Stochastic Jitter é€šå¸¸éœ€é…åˆè´Ÿè½½å‡è¡¡æŸå¤±ä½¿ç”¨ï¼š
```python
def load_balancing_loss(router_logits, expert_indices):
    num_experts = router_logits.shape[-1]
    
    # è®¡ç®—æ¯ä¸ªtokenå¯¹å„ä¸“å®¶çš„æ€»æƒé‡è´¡çŒ®
    router_probs = torch.softmax(router_logits, dim=-1)  # [B*S, E]
    selection_mask = torch.zeros_like(router_probs)      # [B*S, E]
    
    # æ ‡è®°è¢«é€‰ä¸­çš„ä¸“å®¶ä½ç½®
    selection_mask.scatter_(1, expert_indices, 1.0)      # [B*S, E]
    
    # ä¸“å®¶è¢«é€‰ä¸­æ¦‚ç‡çš„æœŸæœ›å€¼ï¼ˆæ²¿batchç»´å¹³å‡ï¼‰
    load_per_expert = selection_mask.mean(dim=0)         # [E]
    
    # ä¸“å®¶æƒé‡æœŸæœ›å€¼ï¼ˆé‡è¦æ€§åŠ æƒï¼‰
    importance_per_expert = router_probs.mean(dim=0)      # [E]
    
    # å…³é”®å…¬å¼ï¼šè´Ÿè½½å‡è¡¡æŸå¤± = æ–¹å·®(æœŸæœ›è´Ÿè½½) * ä¸“å®¶æ•°
    loss_balance = torch.var(load_per_expert) * num_experts
    
    # å¯é€‰ï¼šå¢åŠ é‡è¦æ€§æ–¹å·®é¡¹ï¼ˆå‡è½»é«˜åˆ†ä¸“å®¶è¢«é¢‘ç¹é€‰æ‹©ï¼‰
    loss_importance = torch.var(importance_per_expert) * num_experts
    
    return 0.5 * (loss_balance + loss_importance)

# è°ƒç”¨ (åœ¨è®­ç»ƒå¾ªç¯ä¸­)
total_loss = task_loss + 0.01 * load_balancing_loss(s, expert_idx)
```

---

### ğŸ’ äº”ã€æ€»ç»“ï¼šä»·å€¼ä¸å±€é™

#### âœ… æ ¸å¿ƒè´¡çŒ®ï¼š
1. **çªç ´ä¸“å®¶è„†å¼±æ€§**ï¼šé€šè¿‡æ¯”ä¾‹æ‰°åŠ¨ä½¿è·¯ç”±æ›´é²æ£’
2. **è®¡ç®—é›¶å¼€é”€**ï¼šä»…å¢åŠ å‡åŒ€é‡‡æ ·æ“ä½œï¼Œä¸å½±å“å¹¶è¡Œ
3. **æ— éœ€å­¦ä¹ å™ªå£°å‚æ•°**ï¼šè¶…å‚åŒ–ç®€åŒ–è®­ç»ƒæµç¨‹
4. **ä¿ç•™åˆ†æ•°åˆ†å¸ƒç‰¹æ€§**ï¼šä¹˜æ³•æ‰°åŠ¨ç»´æŒåˆ†æ•°å…³ç³»ç¨³å®š

#### âš ï¸ æ½œåœ¨å±€é™ï¼š
- æ‰°åŠ¨å¹…åº¦ $c$ éœ€äººå·¥è°ƒä¼˜ï¼ˆæ— è‡ªé€‚åº”èƒ½åŠ›ï¼‰
- ç¼ºä¹ç±»ä¼¼ $W_{noise}$ çš„è‡ªè¡°å‡æœºåˆ¶
- æç«¯åœºæ™¯ä¸‹å¯èƒ½æŠ‘åˆ¶é«˜åˆ†ä¸“å®¶ï¼ˆ$1+\epsilon_i$å¯èƒ½ä½¿ $s_i$ ä¸ºè´Ÿï¼‰

> ğŸ”¥ **ç»ˆæå“²å­¦ï¼š**  
> **Stochastic Jitter å°†è·¯ç”±é²æ£’æ€§è½¬åŒ–ä¸ºã€Œåˆ†æ•°ç©ºé—´çš„æ¯”ä¾‹æŠ–åŠ¨ã€ï¼Œé€šè¿‡å‡åŒ€åˆ†å¸ƒçš„ä¹˜æ³•æ‰°åŠ¨åœ¨é«˜æ•ˆæ€§ï¼ˆé›¶å‚/è®¡ç®—è½»é‡ï¼‰ä¸æœ‰ç”¨æ€§ï¼ˆæ‰“ç ´ä¸“å®¶å›ºåŒ–ï¼‰é—´å–å¾—åˆ›æ–°å¹³è¡¡ï¼Œæˆä¸ºç°ä»£å¤§è§„æ¨¡ç¨€ç–æ¨¡å‹è®­ç»ƒçš„åŸºçŸ³ç»„ä»¶ä¹‹ä¸€ã€‚**

è¯¥æ–¹æ³•åœ¨ **Google Switch Transformerã€T5-XL-MoE** ç­‰åƒäº¿çº§æ¨¡å‹ä¸­å®è¯æœ‰æ•ˆã€‚å¦‚éœ€åœ¨è‡ªå®šä¹‰ MoE ä¸­å®ç°ï¼Œæ¨èå…ˆå°è¯• $c=0.4$ é…åˆè´Ÿè½½æŸå¤±ä½¿ç”¨ï¼ˆå®Œæ•´ä»£ç è§ä¸Šæ–‡ï¼‰ã€‚

## 6 - Heuristic balancing losses (switch transformer)

![switch transformer](https://pic3.zhimg.com/v2-45360579ff1c6ae63596a06855a699e6_1440w.jpg)

```python
def load_balancing_loss_func(
    gate_logits: Union[torch.Tensor, Tuple[torch.Tensor], None],
    num_experts: Optional[int] = None,
    top_k=2,
    attention_mask: Optional[torch.Tensor] = None,
) -> Union[torch.Tensor, int]:
    r"""
    Computes auxiliary load balancing loss as in Switch Transformer - implemented in Pytorch.

    See Switch Transformer (https://arxiv.org/abs/2101.03961) for more details. This function implements the loss
    function presented in equations (4) - (6) of the paper. It aims at penalizing cases where the routing between
    experts is too unbalanced.

    Args:
        gate_logits:
            Logits from the `gate`, should be a tuple of model.config.num_hidden_layers tensors of
            shape [batch_size X sequence_length, num_experts].
        num_experts:
            Number of experts
        top_k:
            The number of experts to route per-token, can be also interpreted as the `top-k` routing
            parameter.
        attention_mask (`torch.Tensor`, *optional*):
            The attention_mask used in forward function
            shape [batch_size X sequence_length] if not None.

    Returns:
        The auxiliary loss.
    """
    if gate_logits is None or not isinstance(gate_logits, tuple):
        return 0

    if isinstance(gate_logits, tuple):
        compute_device = gate_logits[0].device
        concatenated_gate_logits = torch.cat([layer_gate.to(compute_device) for layer_gate in gate_logits], dim=0)

    routing_weights = torch.nn.functional.softmax(concatenated_gate_logits, dim=-1)

    _, selected_experts = torch.topk(routing_weights, top_k, dim=-1)

    expert_mask = torch.nn.functional.one_hot(selected_experts, num_experts)

    if attention_mask is None:
        # Compute the percentage of tokens routed to each experts
        tokens_per_expert = torch.mean(expert_mask.float(), dim=0)

        # Compute the average probability of routing to these experts
        router_prob_per_expert = torch.mean(routing_weights, dim=0)
    else:
        batch_size, sequence_length = attention_mask.shape
        num_hidden_layers = concatenated_gate_logits.shape[0] // (batch_size * sequence_length)

        # Compute the mask that masks all padding tokens as 0 with the same shape of expert_mask
        expert_attention_mask = (
            attention_mask[None, :, :, None, None]
            .expand((num_hidden_layers, batch_size, sequence_length, top_k, num_experts))
            .reshape(-1, top_k, num_experts)
            .to(compute_device)
        )

        # Compute the percentage of tokens routed to each experts
        tokens_per_expert = torch.sum(expert_mask.float() * expert_attention_mask, dim=0) / torch.sum(
            expert_attention_mask, dim=0
        )

        # Compute the mask that masks all padding tokens as 0 with the same shape of tokens_per_expert
        router_per_expert_attention_mask = (
            attention_mask[None, :, :, None]
            .expand((num_hidden_layers, batch_size, sequence_length, num_experts))
            .reshape(-1, num_experts)
            .to(compute_device)
        )

        # Compute the average probability of routing to these experts
        router_prob_per_expert = torch.sum(routing_weights * router_per_expert_attention_mask, dim=0) / torch.sum(
            router_per_expert_attention_mask, dim=0
        )

    overall_loss = torch.sum(tokens_per_expert * router_prob_per_expert.unsqueeze(0))
return overall_loss * num_experts
```

è¿™æ®µä»£ç å®ç°äº† Switch Transformer ä¸­æå‡ºçš„è´Ÿè½½å‡è¡¡æŸå¤±å‡½æ•°ã€‚è®©æˆ‘ä»¬é€è¡Œè§£æå…¶å·¥ä½œåŸç†å’Œå®ç°ç»†èŠ‚ï¼š

### ğŸ§  æ ¸å¿ƒåŸç†
è´Ÿè½½å‡è¡¡æŸå¤±çš„ç›®æ ‡æ˜¯æƒ©ç½šè·¯ç”±å†³ç­–ä¸å‡è¡¡çš„æƒ…å†µï¼Œç¡®ä¿æ‰€æœ‰ä¸“å®¶éƒ½èƒ½è¢«å……åˆ†åˆ©ç”¨ã€‚å…¬å¼ä¸ºï¼š
```
loss = num_experts * Î£(ä¸“å®¶içš„ä»¤ç‰Œæ¯”ä¾‹ * ä¸“å®¶içš„å¹³å‡è·¯ç”±æ¦‚ç‡)
```

### ğŸ“ ä»£ç è§£æ

#### 1. è¾“å…¥å¤„ç†
```python
if gate_logits is None or not isinstance(gate_logits, tuple):
    return 0
```
- å¦‚æœæ²¡æœ‰é—¨æ§ logits æˆ–ä¸æ˜¯å…ƒç»„ï¼ˆå¤šå±‚ï¼‰ï¼Œç›´æ¥è¿”å› 0

#### 2. æ•°æ®å‡†å¤‡
```python
if isinstance(gate_logits, tuple):
    compute_device = gate_logits[0].device
    concatenated_gate_logits = torch.cat([layer_gate.to(compute_device) 
                                         for layer_gate in gate_logits], dim=0)
```
- å°†æ‰€æœ‰å±‚çš„é—¨æ§ logits æ‹¼æ¥æˆä¸€ä¸ªå¤§çŸ©é˜µ
- ç¡®ä¿æ‰€æœ‰å¼ é‡éƒ½åœ¨åŒä¸€è®¾å¤‡ä¸Š

#### 3. è·¯ç”±è®¡ç®—
```python
routing_weights = torch.nn.functional.softmax(concatenated_gate_logits, dim=-1)
_, selected_experts = torch.topk(routing_weights, top_k, dim=-1)
expert_mask = torch.nn.functional.one_hot(selected_experts, num_experts)
```
1. è®¡ç®—è·¯ç”±æƒé‡ï¼ˆsoftmax æ¦‚ç‡ï¼‰
2. é€‰æ‹©æ¯ä¸ª token çš„ top_k ä¸“å®¶
3. åˆ›å»ºä¸“å®¶æ©ç ï¼ˆone-hot ç¼–ç ï¼‰

#### 4. æ— æ³¨æ„åŠ›æ©ç æƒ…å†µ
```python
if attention_mask is None:
    # è®¡ç®—æ¯ä¸ªä¸“å®¶è¢«é€‰ä¸­çš„ä»¤ç‰Œæ¯”ä¾‹
    tokens_per_expert = torch.mean(expert_mask.float(), dim=0)
    
    # è®¡ç®—æ¯ä¸ªä¸“å®¶çš„å¹³å‡è·¯ç”±æ¦‚ç‡
    router_prob_per_expert = torch.mean(routing_weights, dim=0)
```
- `tokens_per_expert`: æ¯ä¸ªä¸“å®¶è¢«é€‰ä¸­çš„å¹³å‡æ¯”ä¾‹
- `router_prob_per_expert`: æ¯ä¸ªä¸“å®¶çš„å¹³å‡è·¯ç”±æ¦‚ç‡

#### 5. æœ‰æ³¨æ„åŠ›æ©ç æƒ…å†µ
```python
else:
    batch_size, sequence_length = attention_mask.shape
    num_hidden_layers = concatenated_gate_logits.shape[0] // (batch_size * sequence_length)
    
    # æ‰©å±•æ³¨æ„åŠ›æ©ç ä»¥åŒ¹é…ä¸“å®¶æ©ç å½¢çŠ¶
    expert_attention_mask = (...).reshape(-1, top_k, num_experts)
    
    # è®¡ç®—åŠ æƒä»¤ç‰Œæ¯”ä¾‹
    tokens_per_expert = torch.sum(expert_mask.float() * expert_attention_mask, dim=0) / 
                        torch.sum(expert_attention_mask, dim=0)
    
    # æ‰©å±•æ³¨æ„åŠ›æ©ç ä»¥åŒ¹é…è·¯ç”±æƒé‡å½¢çŠ¶
    router_per_expert_attention_mask = (...).reshape(-1, num_experts)
    
    # è®¡ç®—åŠ æƒè·¯ç”±æ¦‚ç‡
    router_prob_per_expert = torch.sum(routing_weights * router_per_expert_attention_mask, dim=0) / 
                             torch.sum(router_per_expert_attention_mask, dim=0)
```
- è€ƒè™‘æ³¨æ„åŠ›æ©ç ï¼Œå¿½ç•¥å¡«å…… token
- è®¡ç®—åŠ æƒå¹³å‡å€¼è€Œéç®€å•å¹³å‡

#### 6. æŸå¤±è®¡ç®—
```python
overall_loss = torch.sum(tokens_per_expert * router_prob_per_expert.unsqueeze(0))
return overall_loss * num_experts
```
- è®¡ç®—ä¹˜ç§¯å’Œï¼šÎ£(ä»¤ç‰Œæ¯”ä¾‹ Ã— è·¯ç”±æ¦‚ç‡)
- ä¹˜ä»¥ä¸“å®¶æ•°é‡è¿›è¡Œç¼©æ”¾

### ğŸ§© å…³é”®è®¾è®¡ç‚¹

1. **å¤šå±‚èšåˆ**ï¼š
   - å°†æ‰€æœ‰å±‚çš„è·¯ç”±å†³ç­–åˆå¹¶è®¡ç®—
   - ç¡®ä¿å…¨å±€è´Ÿè½½å‡è¡¡

2. **æ³¨æ„åŠ›æ©ç å¤„ç†**ï¼š
   - ç²¾ç»†å¤„ç†å¡«å…… token
   - é¿å…æ— æ•ˆ token å½±å“è´Ÿè½½è®¡ç®—

3. **åŒæŒ‡æ ‡ä¹˜ç§¯**ï¼š
   - åŒæ—¶è€ƒè™‘å®é™…åˆ†é…æ¯”ä¾‹(tokens_per_expert)
   - å’Œè·¯ç”±åå¥½å¼ºåº¦(router_prob_per_expert)

4. **å½’ä¸€åŒ–å¤„ç†**ï¼š
   - ä½¿ç”¨å‡å€¼è€Œéæ€»å’Œ
   - ç¡®ä¿æŒ‡æ ‡ä¸ batch å¤§å°æ— å…³

### âš–ï¸ æ•°å­¦åŸç†

æŸå¤±å‡½æ•°æœ€å°åŒ–ä»¥ä¸‹è¡¨è¾¾å¼ï¼š
$$
L_{balance} = N \times \sum_{i=1}^{N} \left( \frac{\text{count}_i}{T} \right) \times \left( \frac{1}{T} \sum_{t=1}^{T} p_i^{(t)} \right)
$$
å…¶ä¸­ï¼š
- $N$ï¼šä¸“å®¶æ•°é‡
- $\text{count}_i$ï¼šåˆ†é…ç»™ä¸“å®¶ $i$ çš„ token æ•°é‡
- $T$ï¼šæ€» token æ•°é‡ï¼ˆè€ƒè™‘æ©ç ï¼‰
- $p_i^{(t)}$ï¼štoken $t$ åˆ†é…ç»™ä¸“å®¶ $i$ çš„æ¦‚ç‡

### ğŸš€ å·¥ç¨‹ä¼˜åŒ–å»ºè®®

1. **æ•°å€¼ç¨³å®šæ€§**ï¼š
   ```python
   # æ·»åŠ å°å€¼é˜²æ­¢é™¤é›¶
   tokens_per_expert = ... / (torch.sum(...) + 1e-8)
   ```

2. **åˆ†å¸ƒå¼è®¡ç®—**ï¼š
   ```python
   # è·¨è®¾å¤‡èšåˆç»Ÿè®¡æ•°æ®
   if torch.distributed.is_initialized():
       # èšåˆ tokens_per_expert å’Œ router_prob_per_expert
       ...
   ```

3. **ç¨€ç–ä¼˜åŒ–**ï¼š
   ```python
   # ä½¿ç”¨ç¨€ç–æ“ä½œå‡å°‘å†…å­˜
   expert_mask = expert_mask.to_sparse()
   ```

4. **æ··åˆç²¾åº¦æ”¯æŒ**ï¼š
   ```python
   with torch.cuda.amp.autocast():
       # åœ¨è‡ªåŠ¨æ··åˆç²¾åº¦ä¸Šä¸‹æ–‡ä¸­è®¡ç®—
       ...
   ```

è¿™æ®µä»£ç å®ç°äº† Switch Transformer è®ºæ–‡ä¸­æè¿°çš„è´Ÿè½½å‡è¡¡æœºåˆ¶ï¼Œé€šè¿‡æƒ©ç½šä¸å‡è¡¡çš„è·¯ç”±å†³ç­–ï¼Œé¼“åŠ±æ¨¡å‹æ›´å‡åŒ€åœ°ä½¿ç”¨æ‰€æœ‰ä¸“å®¶èµ„æºã€‚

## 7 - Heuristic balancing losses (Deepseek V1-V2)

![Deepseek V1-V2](https://pic4.zhimg.com/v2-e097120cb312e1e3692e74a0a2d78069_1440w.jpg)

## 8 - per-expert biases (Deepseek V3)

![Deepseek V3](https://pic2.zhimg.com/v2-08f82f7e7f3ab378b3a27b639679a9ff_1440w.jpg)

![Deepseek V3](https://pic4.zhimg.com/v2-03cb1dd4c8265b5ffbb16afad7282e15_1440w.jpg)