本文主要整理10-414/714 lecture6 - Optimization的要点。

## 2.2 Momentum

### 内容概括  
两张幻灯片围绕**动量（Momentum）优化方法**展开：第一张介绍动量的核心动机、数学公式及参数含义，提出其作为梯度下降与牛顿法之间的“中间方法”；第二张通过可视化对比（等高线图与目标函数曲线），演示动量在深度网络训练中的实际效果（加速收敛但可能引发振荡）。  

### 要点总结  

#### **第一张：动量的原理与公式**  
1. **核心动机**：  
   提出问题——能否找到一种优化方法，既像梯度下降一样计算简便（仅需一阶梯度），又能像牛顿法一样考虑“全局结构”（利用历史梯度信息）？动量（Momentum）是这一问题的常见解决方案。  

2. **数学公式**：  
   动量通过**移动平均**整合多个历史梯度，降低梯度噪声的影响，其迭代规则分为两步：  
   - **动量项更新**：$u_{t+1} = \beta u_t + (1 - \beta)\nabla_{\theta}f(\theta_t)$  
     （$u_t$ 是第 $t$ 步的动量项，$\beta$ 是动量平均参数，控制历史梯度的权重；$\nabla_{\theta}f(\theta_t)$ 是当前梯度）  
   - **参数更新**：$\theta_{t+1} = \theta_t - \alpha u_{t+1}$  
     （$\alpha$ 是步长，与传统梯度下降的步长一致）  

3. **参数说明与形式偏好**：  
   - $\alpha$（步长）：与传统梯度下降的步长含义相同，控制每一步的更新幅度。  
   - $\beta$（动量参数）：取值范围通常为 $[0,1)$，$\beta$ 越大，历史梯度的权重越高（如 $\beta=0.9$ 表示当前梯度仅占10%，历史90%的梯度被保留）。  
   - 作者偏好当前形式（含 $(1-\beta)$ 系数），原因是保持动量项 $u_t$ 与当前梯度 $\nabla_{\theta}f(\theta_t)$ 的“尺度一致”（避免因 $\beta$ 过大导致 $u_t$ 幅度异常）。  

4. **其他常见形式**：  
   动量的公式可能有变体（如 $u_{t+1} = \beta u_t + \nabla_{\theta}f(\theta_t)$ 或 $u_{t+1} = \beta u_t + \alpha\nabla_{\theta}f(\theta_t)$），但作者强调当前形式更利于参数尺度的稳定性。  


#### **第二张：动量的实际效果与局限性**  
1. **核心效果：加速收敛**：  
   通过对比实验（左侧 $\beta=0$ 无动量 vs 右侧 $\beta=0.7$ 有动量）可视化动量的作用：  
   - **无动量（$\beta=0$）**：梯度下降的路径较“抖”，目标函数曲线需约20次迭代才趋于稳定（收敛慢）。  
   - **有动量（$\beta=0.7$）**：梯度下降的路径更“平滑”，目标函数曲线仅需约10次迭代即可稳定（收敛速度显著提升）。  

2. **潜在问题：振荡与非下降行为**：  
   动量通过平均历史梯度平滑了下降步骤，但也可能引入其他形式的振荡（如在峡谷地形中来回震荡）或短暂的“非下降”现象（目标函数值暂时上升）。不过实际训练中，这些问题通常可通过调整 $\beta$ 或步长 $\alpha$ 缓解，因此动量仍是深度网络训练的常用技巧。  

#### **总结关联**  
两张幻灯片从理论（动机的提出、公式设计）到实践（效果可视化与局限性），完整呈现了动量优化方法的核心价值：通过整合历史梯度信息，在保持计算简便性的同时，加速梯度下降的收敛过程，是深度学习中平衡效率与性能的重要技术。

## 2.3 “Unbiasing” momentum terms

要理解“除以 $ 1-\beta^{t+1} $ 是否每次都会放大”，需结合**动量的累积特性**和**无偏化的数学逻辑**分析：  


### 1. 动量项的累积偏差根源  
动量项 $ u_t $ 通常定义为**指数加权平均**（以常见初始化 $ u_0=0 $ 为例）：  
$$ u_{t+1} = \beta \cdot u_t + (1-\beta) \cdot g_t $$  
其中 $ \beta $ 是动量系数（$ 0<\beta<1 $），$ g_t $ 是当前梯度。  

由于初始 $ u_0=0 $，**早期迭代（$ t $ 小）的 $ u_t $ 会因“历史梯度累积不足”而偏小**。例如：  
- $ t=0 $ 时，$ u_1 = (1-\beta)g_1 $（仅依赖当前梯度，无历史累积）；  
- $ t=1 $ 时，$ u_2 = \beta \cdot u_1 + (1-\beta)g_2 = (1-\beta)(\beta g_1 + g_2) $（仍受初始0的影响，累积有限）。  


### 2. 修正项 $ \frac{1}{1-\beta^{t+1}} $ 的作用逻辑  
无偏化更新式为：  
$$ \theta_{t+1} = \theta_t - \alpha \cdot \frac{u_{t+1}}{1 - \beta^{t+1}} $$  

#### （1）数学上：补偿“早期动量不足”  
由于 $ 0<\beta<1 $，$ \beta^{t+1} $ 随 $ t $ 增大**指数衰减**，因此 $ 1-\beta^{t+1} $ 随 $ t $ 增大**趋近于1**。  

- **早期迭代（$ t $ 小）**：$ \beta^{t+1} $ 较大（如 $ t=0 $ 时，$ \beta^{1}=\beta $），故 $ 1-\beta^{t+1} $ 较小。此时 $ u_{t+1} $ 因累积不足而偏小，**除以较小的 $ 1-\beta^{t+1} $ 会将 $ u_{t+1} $ 放大**，弥补初始动量的“弱势”。  
  （例：$ t=0 $ 时，$ u_1=(1-\beta)g_1 $，修正后 $ \frac{u_1}{1-\beta^1} = \frac{(1-\beta)g_1}{1-\beta} = g_1 $，直接恢复为当前梯度大小。）  

- **后期迭代（$ t $ 大）**：$ \beta^{t+1} $ 趋近于0，故 $ 1-\beta^{t+1} $ 趋近于1。此时 $ u_{t+1} $ 已充分累积历史梯度，**除以接近1的数几乎不改变其大小**，避免后期更新过度放大。  


#### （2）统计上：让各次更新的“期望幅度一致”  
动量的本质是**对历史梯度的加权平均**，初始化偏差会导致“早期更新的期望幅度 < 后期更新的期望幅度”。  

修正项 $ \frac{1}{1-\beta^{t+1}} $ 的核心作用是**对“期望幅度”做动态缩放**：  
- 早期：通过放大 $ u_{t+1} $，让更新期望幅度向后期对齐；  
- 后期：缩放因子趋近于1，维持更新期望幅度的稳定性。  

最终实现**所有迭代的更新期望幅度相等**，解决“初始化导致的更新幅度偏差”问题。  


### 3. 直观结论：“放大”是**早期补偿**，后期趋近稳定  
除以 $ 1-\beta^{t+1} $ 并非“每次都盲目放大”，而是**针对性补偿早期动量不足**，后期则自然收敛到“无偏”的更新幅度。  

这种设计让动量更新的“力度”在迭代全程更均衡，既避免了早期更新太弱导致收敛慢，也防止了后期更新过强引发震荡，最终提升训练稳定性与效率。

## 2.4 Nesterov Momentum

### 内容概括与要点总结  

#### 1. 核心概念  
Nesterov Momentum（或 Nesterov 加速）是**优化算法**中利用“动量”思想加速收敛的一种技巧，核心是在**“下一个参数点”**处计算梯度来更新动量项，而非仅依赖当前点的梯度。  


#### 2. 数学公式（动量更新逻辑）  
Nesterov Momentum 通过两步实现参数更新：  
- **动量项更新**：\( u_{t+1} = \beta u_t + (1-\beta) \nabla_\theta f(\theta_t - \alpha u_t) \)  
  （先基于“当前动量 \( u_t \)”预测下一个参数点 \( \theta_t - \alpha u_t \)，再在该预测点计算梯度，结合历史动量 \( \beta u_t \) 得到新动量 \( u_{t+1} \)。）  
- **参数点更新**：\( \theta_{t+1} = \theta_t - \alpha u_{t+1} \)  
  （用更新后的动量 \( u_{t+1} \) 以学习率 \( \alpha \) 调整参数 \( \theta \)。）  


#### 3. 关键优势  
- 对**凸优化问题**效果显著；  
- （有时）能提升**深度神经网络**的训练效率（如加速收敛、缓解震荡等）。  


#### 4. 公式参数含义  
- \( \alpha \)：**学习率**，控制每次参数更新的步长；  
- \( \beta \)：**动量系数**，控制历史动量对当前更新的影响程度（例如图中取 \( \beta=0.7 \)）。  


#### 5. 可视化验证（图表信息）  
- **等高线图**：对比不同优化方法的迭代路径（橙色为普通方法，绿色为 Nesterov Momentum），可见 Nesterov 的路径更高效地逼近最优解；  
- **目标函数迭代曲线**：Nesterov Momentum（绿色）的目标函数 \( f(\theta) \) 随迭代次数下降更快，收敛性更优。  


简言之，Nesterov Momentum 通过“预测下一个点的梯度”来调整动量，实现了更高效的参数更新，在凸优化和深度学习场景中均展现出加速收敛的价值。

## 2.5 Adam

### 内容概括  
两张幻灯片围绕**Adam优化算法**展开：第一张介绍Adam的核心原理（结合动量与自适应规模估计）、数学公式及设计背景；第二张通过理论讨论与可视化示例（等高线图、目标函数曲线），说明Adam在深度学习中的实践表现及争议。  


### 要点总结  

#### **第一张：Adam的原理与公式**  
1. **背景与动机**：  
   深度学习中，不同参数、网络层或层类型的梯度规模差异显著（如某些层梯度大，某些层梯度小）。自适应梯度方法通过**估计梯度规模**并动态调整更新步长，解决传统梯度下降对学习率敏感、收敛效率低的问题。  

2. **Adam的核心设计**：  
   Adam是深度学习中最广泛使用的自适应梯度方法，**结合了动量（Momentum）与自适应规模估计**，通过以下两步优化：  
   - **动量项（一阶矩估计）**：$u_{t+1} = \beta_1 u_t + (1-\beta_1)\nabla_\theta f(\theta_t)$  
     （$\beta_1$ 控制历史梯度权重，$(1-\beta_1)$ 为无偏校正系数，确保动量项的期望与当前梯度一致。）  
   - **自适应规模项（二阶矩估计）**：$v_{t+1} = \beta_2 v_t + (1-\beta_2)(\nabla_\theta f(\theta_t))^2$  
     （$\beta_2$ 控制历史平方梯度的权重，通过平方项捕捉梯度规模的波动。）  
   - **参数更新**：$\theta_{t+1} = \theta_t - \alpha \cdot \frac{u_{t+1}}{\sqrt{v_{t+1}} + \epsilon}$  
     （$\alpha$ 为学习率，$\epsilon$ 为小常数防止除零错误；通过 $\sqrt{v_{t+1}}$ 缩放梯度，使更新步长自适应于历史梯度规模。）  


#### **第二张：Adam的实践表现与争议**  
1. **理论与实践的争议**：  
   尽管深度学习界对Adam是否“最优”存在持续争论（如是否应采用无偏校正、绝对值平均替代平方平均、引入Nesterov加速等变体），但其在实际训练中**表现稳健**，是多数场景下的首选优化器。  

2. **可视化示例**：  
   - **左侧等高线图**：展示Adam在二维函数上的优化路径（灰色椭圆为等高线，绿色路径从右下向中心收敛），直观体现其通过自适应调整步长，高效逼近全局最小值点的能力。  
   - **右侧目标函数曲线**：以超参数 $\alpha=0.6, \beta_1=0.7, \beta_2=0.8$ 为例，目标函数值随迭代次数（0-30次）迅速下降，约15次后趋于平稳（接近0），验证了Adam的**快速收敛性**。  


### 核心结论  
Adam通过结合动量（捕捉梯度方向的历史信息）与自适应规模估计（动态调整步长以适配梯度波动），在深度学习中实现了高效、稳健的优化。尽管存在理论争议，但其实际表现使其成为广泛应用的标准优化器。

## 2.6 Stochastic variants

### 内容概括  
两张幻灯片围绕**随机优化方法**展开：第一张介绍随机变体（Stochastic variants）的核心思想，对比批量更新与随机变体的选择，并引出经验期望损失的小批量梯度估计；第二张聚焦随机梯度下降（SGD）算法，详细说明其数学定义、核心优势（廉价噪声步骤替代昂贵无噪声步骤），并通过可视化展示不同学习率下的优化效果。  


### 要点总结  

#### **第一张：随机变体的背景与原理**  
1. **优化选择的转变**：  
   传统优化示例多采用“批量更新”（Batch Update），但随机变体（Stochastic variants）是更关键的优化选择，其核心是利用“随机性”提升效率。  

2. **机器学习优化问题的定义**：  
   目标是最小化**经验期望损失**（Empirical Expectation Loss），公式为：  
   $$
   \underset{\theta}{\operatorname{minimize}} \frac{1}{m} \sum_{i=1}^{m} \ell\left(h_{\theta}\left(x^{(i)}\right), y^{(i)}\right)
   $$  
   其中 $m$ 是样本总数，$\ell$ 是单样本损失函数，$h_{\theta}(x^{(i)})$ 是模型对第 $i$ 个样本的预测值，$y^{(i)}$ 是真实标签。  

3. **小批量梯度估计的无偏性**：  
   随机变体的核心操作是**仅用一个小批量（Minibatch）样本 $B \subset \{1,\dots,m\}$ 计算梯度**，得到对真实梯度的**无偏但含噪声的估计**（Noisy but Unbiased Gradient Estimate）。噪声源于小批量与全集的差异，但无偏性保证了长期优化的正确性。  


#### **第二张：随机梯度下降（SGD）的算法与优势**  
1. **SGD的数学定义**：  
   SGD通过**重复对小批量 $B$ 计算梯度并更新参数**实现优化，迭代公式为：  
   $$
   \theta_{t+1} = \theta_t - \frac{\alpha}{|B|} \sum_{i \in B} 
   \nabla_{\theta} \ell\left(h_{\theta}(x^{(i)}), y^{(i)})\right)
   $$  
   其中 $\alpha$ 是学习率，$|B|$ 是小批量大小，$\nabla_{\theta} \ell$ 是损失函数对参数 $\theta$ 的梯度。  

2. **核心优势：廉价噪声步骤替代昂贵无噪声步骤**：  
   传统批量梯度下降（Batch GD）需计算全集梯度的“昂贵无噪声步骤”（计算成本高但稳定），而SGD通过“许多廉价有噪声步骤”（计算成本低但梯度含噪声）实现更强的**计算性能**（Compute Performance），尤其在高维、大数据场景中优势显著。  

3. **可视化辅助（四张子图）**：  
   - **左侧参数空间轨迹图**：展示不同学习率下SGD的优化路径（可能包括震荡或平稳收敛的对比）；  
   - **右侧目标函数曲线图**：展示目标函数值随迭代次数的变化（可能体现SGD初期快速下降、后期稳定的特性，或不同学习率对收敛速度的影响）。  


### 总结关联  
两张幻灯片从“随机变体的理论基础”（第一张）到“SGD的具体实现与优势”（第二张），完整呈现了随机优化方法的核心逻辑：通过小批量梯度估计降低计算成本，利用噪声梯度的无偏性保证长期收敛，最终在深度学习等大规模任务中实现高效的参数优化。

## 2.6 无偏但含噪声的估计,这里的无偏怎么理解?

要理解“无偏但含噪声的估计”中的“无偏”，需要结合**统计学中的无偏估计定义**和**机器学习中梯度估计的具体场景**来分析。以下是详细解释：  


### **1. 统计学中的“无偏估计”定义**  
在统计学中，若一个**估计量**（Estimator）的**期望值**等于被估计的**总体参数**（True Parameter），则称该估计量是“无偏的”（Unbiased）。数学上表示为：  
$$
\mathbb{E}[\hat{\theta}] = \theta
$$  
其中 $\hat{\theta}$ 是估计量，$\theta$ 是总体参数的真实值。  


### **2. 机器学习中的“梯度估计”场景**  
在机器学习的优化问题中，我们的目标是**最小化经验期望损失**（Empirical Expectation Loss）：  
$$
\underset{\theta}{\operatorname{minimize}} \frac{1}{m} \sum_{i=1}^{m} \ell\left(h_{\theta}(x^{(i)}), y^{(i)}\right)
$$  
其中 $m$ 是训练集总样本数，$\ell$ 是单样本损失函数，$h_{\theta}(x^{(i)})$ 是模型对第 $i$ 个样本的预测值，$y^{(i)}$ 是真实标签。  

要优化这个目标，需要计算**全批量梯度**（Full Batch Gradient）：  
$$
\nabla_{\theta} \left( \frac{1}{m} \sum_{i=1}^{m} \ell\left(h_{\theta}(x^{(i)}), y^{(i)}\right) \right) = \frac{1}{m} \sum_{i=1}^{m} 
\nabla_{\theta} \ell\left(h_{\theta}(x^{(i)}), y^{(i)}\right)
$$  
全批量梯度是**总体梯度的精确值**（无噪声），但计算成本极高（需遍历所有 $m$ 个样本）。  


### **3. 小批量梯度的“无偏性”**  
随机优化方法（如SGD）选择用**小批量样本**（Minibatch，记为 $B \subset \{1,\dots,m\}$，大小为 $|B|$）的梯度来估计全批量梯度，得到：  
$$
\hat{g}_B = \frac{1}{|B|} \sum_{i \in B} 
\nabla_{\theta} \ell\left(h_{\theta}(x^{(i)}), y^{(i)}\right)
$$  

#### 为什么说 $\hat{g}_B$ 是“无偏”的？  
小批量梯度 $\hat{g}_B$ 的**期望值**等于全批量梯度：  
$$
\mathbb{E}[\hat{g}_B] = \mathbb{E}\left[ \frac{1}{|B|} \sum_{i \in B} 
\nabla_{\theta} \ell\left(h_{\theta}(x^{(i)}), y^{(i)}\right) \right] = \frac{1}{m} \sum_{i=1}^{m} 
\nabla_{\theta} \ell\left(h_{\theta}(x^{(i)}), y^{(i)}\right)
$$  

**关键逻辑**：  
- 小批量 $B$ 是从全量样本中**随机均匀采样**的（无偏采样）；  
- 每个样本 $i$ 被选入 $B$ 的概率是 $|B|/m$，因此对每个样本的梯度 $\nabla_{\theta} \ell(x^{(i)}, y^{(i)})$ 来说，其在 $\hat{g}_B$ 中的权重期望是 $1/m$（与全批量梯度一致）；  
- 因此，$\hat{g}_B$ 的期望值等于全批量梯度，满足无偏性。  


### **4. 小批量梯度的“含噪声”特性**  
尽管 $\hat{g}_B$ 是无偏的，但其**单次实现值**（具体某一次小批量计算出的梯度）与全批量梯度之间存在**随机波动**，这种波动就是“噪声”（Noise）。  

#### 噪声的来源：  
- 小批量 $B$ 是随机采样的，不同 $B$ 包含的样本不同，导致 $\hat{g}_B$ 的具体值随机变化；  
- 即使 $B$ 固定，样本的梯度 $\nabla_{\theta} \ell(x^{(i)}, y^{(i)})$ 本身也可能因数据噪声（如标签误差、特征噪声）而存在波动。  


### **5. 无偏性与噪声的实际意义**  
无偏性保证了**长期优化的正确性**：尽管单次小批量梯度可能有噪声（偏离全批量梯度），但通过多次迭代（多次采样不同小批量），噪声会相互抵消，其平均效果会趋近于全批量梯度的真实方向。  

相比之下，若梯度估计是“有偏的”（即 $\mathbb{E}[\hat{g}_B] \neq$ 全批量梯度），则长期优化会系统性地偏离真实最小值点，导致算法失败。  


### **总结**  
“无偏但含噪声的估计”中的“无偏”指：**小批量梯度的期望值等于全批量梯度的真实值**（满足统计学无偏性）；“含噪声”指：**单次小批量梯度的具体值与全批量梯度存在随机波动**（因采样和小批量内样本的随机性）。  

无偏性是随机优化算法（如SGD）能收敛到正确解的理论基础，而噪声则是随机优化的“代价”——通过多次迭代的噪声平均，最终实现高效、正确的参数优化。

## 2.7 The most important takeaways

### 内容概括与要点总结  
这段内容围绕**优化方法的关键认知**展开，给出三个核心要点：  

1. **应用形式**：目前已讲解的优化方法，在实际场景中仅以“随机形式（stochastic form）”被使用。  
- All the optimization methods you have seen thus far presented are only actually 
used in their stochastic form.
2. **直觉认知局限**：仅通过“简单优化问题（凸问题、二次问题）”来建立对这些方法的**有效直觉（valid intuition）**，能获得的信息是有限的。
- The amount of valid intuition about these optimization methods you will get from 
looking at simple (convex, quadratic) optimization problems is limited.  
3. **实践必要性**：若想理解这些优化方法对“不同类型深度网络”的实际影响，必须持续开展实验（constantly experiment）。  
- You need to constantly experiment to gain an understanding / intuition of how 
these methods actually affect deep networks of different types.
这些要点强调了优化方法的实际应用形态、理论学习与实践认知的差距，以及实验在深度网络优化理解中的核心作用。