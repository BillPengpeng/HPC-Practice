本文主要整理Chapter 6 Locking的要点。

## 6.0 前言

1.  **并发的必然性与来源：**
    *   内核活动（如进程、中断）的执行通常是**交错（Interleaved）** 进行的。
    *   **主要来源有三个：**
        *   **多处理器硬件 (Multiprocessor)**：多个CPU核（如xv6的RISC-V CPU）独立执行，**共享物理RAM和内核数据结构**。
        *   **线程切换 (Thread Switching)**：即使是单处理器，内核也会在多个线程间切换CPU。
        *   **中断 (Interrupts)**：设备中断处理程序可能会打断正在执行的代码。
    *   所有这些场景都统称为 **“并发”（Concurrency）**，即多个指令流交错执行。

2.  **并发访问共享数据的问题：**
    *   内核中存在大量**共享数据结构**需要被并发访问（如多个CPU同时调用 `kalloc` 操作空闲内存链表）。
    *   如果缺乏精心设计（即缺乏并发控制），这种并行访问可能导致：
        *   一个CPU在读取数据时，另一个CPU正在修改它（读到了中间状态或无效数据）。
        *   多个CPU同时尝试更新同一个数据（如同时修改链表头）。
    *   后果是 **不正确的计算结果** 或 **损坏的数据结构**。

3.  **并发控制的必要性：**
    *   内核设计者需要**允许多并发以提升性能**（利用多核并行）和**响应性**。
    *   但与此同时，必须确保**正确性（Correctness）**。
    *   因此，需要采用 **并发控制技术（Concurrency Control Techniques）** 来管理对共享资源的并发访问。

4.  **锁作为核心并发控制机制：**
    *   **锁（Lock）** 是其中一种广泛使用的技术。
    *   **核心功能是提供互斥（Mutual Exclusion）**：在任意时刻，只能有一个CPU持有（获得）某个特定的锁。
    *   **保护数据的方式**：程序员为每个需要保护的共享数据项关联一个锁，任何访问该数据项的代码段在使用数据前必须先获取该锁，使用完后释放锁。
    *   **作用效果**：通过互斥锁机制，保证了被锁保护的共享数据项在任一时刻**只被一个CPU访问和修改**。
    *   **优点**：锁是一种**概念相对简单易懂（easy-to-understand）** 的并发控制原语。

5.  **锁的性能权衡（Trade-off）：**
    *   **主要缺点**：锁会**限制性能（limit performance）**。
    *   **原因**：锁通过互斥访问**强制将原本可以并发的操作序列化（serialize concurrent operations）**，同一时刻只允许一个执行流操作被保护的数据/资源。这会降低并行度。

6.  **后续内容：**
    *   本段落的后续部分将详细解释：
        *   **为什么 xv6 需要锁？**（结合具体场景分析风险）
        *   **xv6 是如何实现锁的？**（硬件支持、软件实现细节）
        *   **xv6 是如何使用锁的？**（在哪些地方加锁保护哪些数据）

## 6.1 Races

本节通过一个 **具体示例（`wait` 调用 `kfree` 释放子进程内存）** 生动地解释了在多处理器环境中 **为什么需要锁**，以及缺乏锁如何导致 **竞态条件（Race Condition）** 和数据破坏。核心在于 **内核内存分配器（kalloc/kfree）** 使用的 **共享空闲页链表**。

1.  **核心示例：并发 `kfree`/`push` 导致链表更新丢失：**
    *   两个 CPU 同时调用 `kfree` (类比 `push`) 向共享空闲链表释放内存页（添加元素）。
    *   若 `push` 无锁：在执行 `l->next = list` (步1) 后、`list = l` (步2) 前发生并发（如图 6.2），第二个 CPU 的 `list = l` 会覆盖第一个 CPU 的设置，导致**第一个 CPU 添加的元素丢失**。

2.  **竞态条件（Race Condition）：**
    *   **定义：** 多个执行流（CPU）并发访问（读/写）同一共享内存位置，且至少有一个是写操作。
    *   **后果：** 可能导致**更新丢失、读取到不一致的数据结构**。
    *   **特征：** 结果**非确定性**，**难以重现和调试**（受编译器、时序、内存系统排序等影响）。

3.  **锁（Lock）作为解决方案：**
    *   **机制：** 提供**互斥访问（Mutual Exclusion）**。
    *   **操作：** 在访问受保护的共享资源/数据结构的**关键代码段（临界区）** 前调用 `acquire(&lock)`，在之后调用 `release(&lock)`。
    *   **效果：** 确保同一时刻最多只有一个 CPU 能进入同一个锁保护的临界区。在上例中，保护了修改链表指针 `l->next` 和 `list` 的代码。

4.  **锁保护的本质：数据不变量（Invariants）：**
    *   锁不仅保护数据本身，更重要的是保护**数据结构固有的正确状态属性**（不变量），例如：链表头指针有效、元素间链接关系正确。
    *   临界区内的操作**可能暂时违反不变量** (如：`l->next` 已指向旧链表头，但 `list` 还未指向新元素 `l`)。
    *   **锁的核心作用：** 确保临界区执行时（不变量可能被暂时破坏），其他 CPU **无法访问** 依赖于这些不变量的代码或数据，从而维持了**对外的逻辑一致性**。锁保证只有当前持有锁的CPU能在临界区内操作，当它离开临界区时，不变量必须恢复。

5.  **锁的代价与挑战：锁争用（Contention）：**
    *   **性能瓶颈：** 锁通过**序列化**并发操作来保证正确性，但**会限制并行性**。
    *   **争用（Contention）：** 当多个 CPU **同时请求同一个锁**时发生。
    *   **设计挑战：** 内核设计的一大目标是**减少锁争用，提升并行度**。策略包括：使用更细粒度的锁、无锁数据结构、或为不同CPU维护独立的数据结构（如每CPU空闲链表），仅在必要时“偷取”资源。

6.  **锁的范围（位置）影响性能：**
    *   将锁的范围（`acquire/release` 之间的区域）设得**过宽**（如过早加锁）会将原本可以并行执行的操作（如独立的 `malloc` 调用）**不必要地串行化**，降低性能。
    *   需要**在正确性的前提下，尽可能缩小临界区范围**，仅将*真正需要互斥访问共享数据*的操作置于其中。

## 6.2 Code: Locks

本节详细讲解了**xv6中自旋锁（Spinlock）的具体实现**，重点在于解决**如何在多处理器环境下原子性地获取锁**的核心问题。

*   **xv6的锁类型：** xv6 有两种锁：**自旋锁（Spinlocks）** 和 **睡眠锁（Sleep-locks）**。本节聚焦于自旋锁。
*   **自旋锁结构：** 自旋锁由 `struct spinlock` 表示 (kernel/spinlock.h:2)，其核心字段是 **`locked`**：0 表示锁空闲，非0 (通常是1) 表示锁已被持有。
*   **天真实现的缺陷 (非原子操作)：** 一个简单的 `acquire` 函数 (循环检查 `locked == 0` 后设为1) 在**多处理器下无效**。可能有两个 CPU *同时* 检测到 `locked` 为0，并都将其设为1持有锁，这**违反了互斥性**。关键问题在于检查 `locked` 和设置 `locked` 这两个操作不是**原子（Atomic）**的。
*   **硬件原子指令解决方案：**
    *   多核处理器提供**专用原子指令**来解决此问题。
    *   **RISC-V 的 `amoswap` 指令：** 该指令原子性地执行 **交换（Swap）**：读取内存地址 `a` 的值写入寄存器 `r`，同时将寄存器 `r` 的原始值写入内存地址 `a`。它保证读和写之间没有其他CPU能插入使用该内存地址。
*   **xv6 的实际 `acquire` 实现 (kernel/spinlock.c:22)：**
    *   使用 C 标准库函数 `__sync_lock_test_and_set()`。在 RISC-V 上，它编译为 **`amoswap` 指令**。
    *   函数的**核心逻辑**：在一个循环中，**原子性地将值“1”与锁的 `locked` 字段进行交换**。
        *   **返回值是交换前的值（旧值）。**
        *   **如果旧值为 0：** 表示锁原先是空闲的，当前 CPU 成功获得了锁（因为交换操作同时把 `locked` 设为了 1）。
        *   **如果旧值为 1：** 表示锁已被其他 CPU 持有（交换操作再次设成了 1，锁的状态未变），则当前 CPU 在循环中**持续尝试（自旋/Spin）** 直到锁可用。
    *   获取锁后，记录持有锁的 CPU (写入 `lk->cpu` 字段，用于调试)。这个字段受到锁自身的保护，只能在持有锁期间修改。
*   **xv6 的 `release` 实现 (kernel/spinlock.c:47)：**
    *   先清除 `lk->cpu` 字段（表示当前释放锁的 CPU 不再持有它）。
    *   **原子地释放锁：**
        *   不能简单地用 `lk->locked = 0`，因为 C 语言中一个赋值操作**可能被编译器分解为多个指令，不是原子的**。
        *   使用 C 标准库函数 `__sync_lock_release()`。在 RISC-V 上，它也编译为 **`amoswap` 指令**，能**原子地将 `lk->locked` 设置为 0**。

**要点总结：**

```c
// Acquire the lock.
// Loops (spins) until the lock is acquired.
void
acquire(struct spinlock *lk)
{
  push_off(); // disable interrupts to avoid deadlock.
  if(holding(lk))
    panic("acquire");
  // On RISC-V, sync_lock_test_and_set turns into an atomic swap:
  //   a5 = 1
  //   s1 = &lk->locked
  //   amoswap.w.aq a5, a5, (s1)
  while(__sync_lock_test_and_set(&lk->locked, 1) != 0) {
  }

  // Tell the C compiler and the processor to not move loads or stores
  // past this point, to ensure that the critical section's memory
  // references happen strictly after the lock is acquired.
  // On RISC-V, this emits a fence instruction.
  __sync_synchronize();

  // Record info about lock acquisition for holding() and debugging.
  lk->cpu = mycpu();
}

// Release the lock.
void
release(struct spinlock *lk)
{
  if(!holding(lk))
    panic("release");

  lk->cpu = 0;

  // Tell the C compiler and the CPU to not move loads or stores
  // past this point, to ensure that all the stores in the critical
  // section are visible to other CPUs before the lock is released,
  // and that loads in the critical section occur strictly before
  // the lock is released.
  // On RISC-V, this emits a fence instruction.
  __sync_synchronize();

  // Release the lock, equivalent to lk->locked = 0.
  // This code doesn't use a C assignment, since the C standard
  // implies that an assignment might be implemented with
  // multiple store instructions.
  // On RISC-V, sync_lock_release turns into an atomic swap:
  //   s1 = &lk->locked
  //   amoswap.w zero, zero, (s1)
  __sync_lock_release(&lk->locked);

  pop_off();
}
```

1.  **自旋锁核心结构与状态：**
    *   结构体 `struct spinlock`。
    *   `locked` 字段：**状态标志** (0: 空闲, 非0/1: 已持有)。
    *   `cpu` 字段：**记录当前持有锁的 CPU** (用于调试)，**该字段受锁自身保护**。

2.  **天真实现的失败原因：**
    *   **检查 `locked == 0` 和设置 `locked = 1` 的操作组合不是原子的。**
    *   可能发生**多个 CPU 同时发现锁空闲并都尝试持有**，导致**互斥性失效**。

3.  **硬件原子指令 (`amoswap`) 是关键：**
    *   **多核处理器提供原子指令（如 RISC-V 的 `amoswap`）** 来实现真正的原子测试并设置。
    *   `amoswap` 指令在**单个不可中断的操作中完成内存位置的读取和写入**。

4.  **`acquire` 函数工作原理：**
    *   使用 `__sync_lock_test_and_set(&lk->locked, 1)` 实现（映射到 `amoswap`）。
    *   **在循环中不断尝试交换操作**。
    *   **判断返回值（交换前的旧值）：**
        *   **0**：**成功获取锁** (交换操作将锁设为了1)，退出循环。
        *   **1**：锁被他人持有，**继续自旋重试**。
    *   获取锁后，记录持有者 CPU (`lk->cpu`)。

5.  **`release` 函数工作原理：**
    *   清除持有者记录 (`lk->cpu = 0`)。
    *   使用 `__sync_lock_release(&lk->locked)` 实现（映射到 `amoswap`）。
    *   此函数**原子地将锁状态 `locked` 设置为 0**，释放锁以供其他 CPU 获取。
    *   **必须使用原子操作**：避免因 C 赋值的潜在非原子性（多指令实现）而导致问题。

6.  **C 库函数的抽象：**
    *   xv6 通过 `__sync_lock_test_and_set` 和 `__sync_lock_release` **可移植地访问底层的硬件原子指令**。
    *   这些函数屏蔽了具体硬件（如 RISC-V 的 `amoswap`）的实现细节。

## 6.3 Code: Using locks

本节讨论了在xv6内核中**如何实际地使用锁**，重点关注锁的使用策略、原则以及在性能与正确性之间的权衡。

*   **锁的广泛应用：** xv6在**许多地方使用锁**（如之前讨论的`kalloc`和`kfree`）来**避免竞态条件（Races）**。
*   **锁错误的隐蔽性：** 即使去掉这些锁（如习题1,2所示），可能也难以立即触发错误行为。这**凸显了可靠地检测锁错误和竞态的难度**，暗示xv6中可能仍存在未发现的竞态问题。
*   **核心挑战：锁的粒度和范围：**
    *   使用锁最困难的部分是决定**需要使用多少锁、每个锁应该保护哪些数据和不变量**。
    *   基本原则：
        *   **必要性（什么时候需要锁）：**
            1.  **任何被多个CPU并发访问（读或写）的共享变量**都需要锁保护（防止访问重叠）。
            2.  **保护不变量：** 如果一个**不变量（Invariant）涉及多个内存位置**，通常需要**一个锁**来保护所有相关位置，以确保整体不变量不被破坏。
        *   **非必要性（什么时候可以不用锁）与性能考虑：** 为了效率，**不要过度加锁**，因为锁会**序列化操作，降低并行度，损害性能**。
*   **性能与锁粒度的权衡：**
    *   **低并行需求：** 如果并行不重要，可以用简单方法如“**大内核锁（Big Kernel Lock, BKL）**”：整个内核只用一个锁，进内核加锁，出内核解锁（效率低，牺牲了多核能力）。
    *   **追求高性能：** 需要更**细粒度（Fine-grained）的锁设计**，允许多个CPU在内核中并行执行。
*   **锁粒度示例：**
    *   **粗粒度锁（Coarse-grained）示例：** xv6的`kalloc.c`内存分配器。它只有**一个空闲页链表**和**一个锁**保护它。所有CPU分配/释放内存时竞争这把锁，可能因**自旋等待（Spinning）浪费大量CPU时间**。
        *   **优化思路：** 如采用**每CPU空闲链表**，每个链表有自己的锁，可显著提升分配并行性。
    *   **细粒度锁（Fine-grained）示例：** xv6**为每个文件（`struct file`）分配一把锁**。操作不同文件的进程通常不需等待同一把锁。
        *   **更细粒度的可能：** 如果允许进程同时写同一文件的不同区域，可以为文件的不同区域（如块）加锁，进一步提升并行度。
*   **锁决策的关键：** 锁的**最佳粒度选择**需要平衡**性能需求（测量争用情况）** 和**实现的复杂性**。

**要点总结：**

1.  **锁是避免竞态的核心工具：** xv6广泛使用锁来保护内核中的共享数据，确保正确性（如`kalloc`/`kfree`保护空闲链表）。
2.  **锁错误的隐蔽性挑战：** 去除锁后问题可能不立刻显现，使得**全面检测并发错误（Races）非常困难**。内核中可能存在潜在未发现的竞态。
3.  **锁使用的核心原则：**
    *   **何时需要锁？ (必要性准则)**
        *   对**共享的、可写内存位置**的并发访问（读且至少有一个写）。
        *   保护涉及**多个数据项**的**不变量（Invariants）**。
    *   **锁的关键作用：** 确保在临界区内操作时（可能临时违反不变量），其他CPU无法观察到中间状态或修改被保护的数据项。
4.  **锁的成本与粒度权衡：**
    *   **锁的代价：** 强制串行化（Serialization），**限制并行度（Performance Bottleneck）**。
    *   **避免过度加锁：** 只在必要时加锁，减小锁范围以维持性能。
    *   **大内核锁的极端：** 单一全局锁简单但性能差（仅单CPU执行内核代码）。
5.  **锁粒度（Granularity）是性能关键：**
    *   **粗粒度锁：** 覆盖范围广（如整个子系统或大型结构的一个锁），**实现简单**，但**竞争（Contention）风险高**，可能导致CPU在**自旋等待（Spinning）中浪费资源**（如xv6原版`kalloc`）。
    *   **细粒度锁：** 覆盖范围小（如单个数据结构或结构的一部分），**降低竞争风险**，**提升并行性**（如xv6每个文件的独立锁），但**实现更复杂**，**获取/释放多个锁时死锁风险增加**。
6.  **粒度选择依据：**
    *   **性能测量：** 分析锁**争用（Contention）** 程度（CPU等待时间）。
    *   **系统目标：** 对性能要求高的场景倾向更细粒度。
    *   **复杂度管理：** 更细粒度的锁设计带来更高的实现和调试复杂度。

## 6.4 Deadlock and lock ordering

本节探讨了在内核编程中，当代码路径需要**同时持有多个锁**时，可能引发的**死锁（Deadlock）** 风险以及其核心的解决方案——**强制全局锁获取顺序（Global Lock Acquisition Order）**。

*   **死锁场景：**
    *   假设代码路径 1 以顺序 **A -> B** 获取锁。
    *   代码路径 2 以顺序 **B -> A** 获取锁。
    *   线程 T1 (执行路径1) 持有锁 A，请求锁 B。
    *   线程 T2 (执行路径2) 持有锁 B，请求锁 A。
    *   结果：T1 等待 T2 释放 B，T2 等待 T1 释放 A，**双方无限阻塞，形成死锁**。
*   **核心解决方案：全局锁顺序：**
    *   必须规定一个**全局所有代码路径都必须遵守的锁获取顺序**。
    *   例如：总要先获取锁 X，再获取锁 Y。
    *   这要求**锁的顺序成为函数契约**的一部分：调用者必须按约定顺序调用函数或获取锁。
*   **xv6 中的实践与挑战：**
    *   **两锁链示例（涉及进程锁）：** 常见于如 `sleep`/`wakeup` 机制。例如：
        *   `consoleintr` (处理中断输入) 持有 `cons.lock`，然后在调用 `wakeup` 时需要获取目标进程自身的锁 (`p->lock`)。
        *   **规则：** `cons.lock` 必须**在进程锁 (`p->lock`) 之前**获取。
    *   **最长锁链示例（文件系统）：** 文件操作（如创建文件）可能需同时持有：
        *   目录锁 -> 新文件inode锁 -> 磁盘块缓冲区锁 -> 磁盘驱动锁 (`vdisk_lock`) -> 调用进程自身锁 (`p->lock`)。
        *   **规则：** 文件系统代码**严格遵循上述定义顺序**获取锁。
*   **遵守全局顺序的困难性：**
    *   **与逻辑结构冲突：** 锁顺序可能要求先获取子模块的锁，再获取调用者模块的锁，这与自然调用流程相反 (如 M1 调 M2，但需先拿 M2 锁再拿 M1 锁)。
    *   **动态锁识别（锁名未知）：** 下一把要获取的锁的*身份*可能需要持有当前锁才能确定。例如：
        *   文件系统查找路径名 (`namei`)：逐级解析路径组件，每级需要锁定当前目录才能确定下一级目录/文件的 inode (其锁)。
        *   `wait`/`exit`：在进程表中查找子进程时，遍历需要锁保护，找到具体子进程后才能获取其特定锁。
    *   **锁粒度与死锁风险的权衡：** **增加锁数量（提高粒度）通常会增加锁交互的复杂性，从而增加死锁的可能性**。避免死锁是内核设计中限制锁粒度和提高复杂性的**主要因素**。

**要点总结：**

```c
void
consoleintr(int c)
{
  acquire(&cons.lock);

  switch(c){
  // ...
  default:
    if(c != 0 && cons.e-cons.r < INPUT_BUF_SIZE){
      // ...

      if(c == '\n' || c == C('D') || cons.e-cons.r == INPUT_BUF_SIZE){
        // wake up consoleread() if a whole line (or end-of-file)
        // has arrived.
        cons.w = cons.e;
        wakeup(&cons.r);
      }
    }
    break;
  }
  
  release(&cons.lock);
}
```

1.  **死锁核心原因：**
    *   多个执行流（线程/CPU）以**不同的顺序（Incompatible Order）请求并持有多把锁**，形成**环状等待**（如T1等T2的B，T2等T1的A）。
2.  **核心防御策略：全局锁顺序：**
    *   唯一可靠方法：系统定义并强制要求**所有代码**以**一个固定全局顺序**获取多个锁（如总先A后B）。
    *   **锁顺序成为API契约：** 函数的设计和调用必须**明确并遵守**其内部及交互所需的锁顺序。
3.  **xv6 中的锁顺序实例：**
    *   **`consoleintr` 与进程锁：** `cons.lock` **必须早于** 任何`p->lock`。中断处理在唤醒进程时必须遵守此规则。
    *   **文件系统操作：** 包含**长锁链**（目录锁 -> 文件inode锁 -> 块缓冲区锁 -> 磁盘驱动锁 -> 进程锁），代码**严格按照此顺序获取**。这是文件系统复杂操作中避免死锁的关键。
4.  **实现全局顺序的现实挑战：**
    *   **反直觉逻辑流：** 锁顺序可能要求**先获取深层或后续模块的锁，再获取上层或调用者的锁**，违背正常代码流程。
    *   **锁身份识别依赖：** **确定“下一把锁是谁”本身可能需要持有当前锁**。这在遍历数据结构（文件路径、进程表）时尤为常见且棘手。
5.  **死锁风险对锁粒度设计的制约：**
    *   追求细粒度锁以提升并行度的同时，**锁数量的增加显著提高了锁之间发生冲突和产生环形等待的可能性（死锁风险↑）**。
    *   **避免死锁是内核锁架构设计（尤其文件系统等复杂模块）的核心约束和主要复杂度来源**。设计者必须在性能（细粒度锁）与风险（死锁概率）间谨慎权衡。

## 6.5 Re-entrant locks

本节讨论了**可重入锁（递归锁）** 的概念，并与 **xv6 采用的非可重入锁**进行了对比。核心在于解释为什么可重入锁**虽然能解决特定死锁问题**，但**破坏了锁机制的核心价值——保证临界区的原子性和隔离性**，从而可能导致更难以调试的错误，因此 xv6 选择了简单且更易于推理的**非可重入锁**。

*   **可重入锁的概念：** 允许一个**已经持有锁的线程再次请求并获得同一个锁**（内核直接允许，而不是像 xv6 那样触发 `panic`）。这可以防止**因一个线程试图重入持有锁的代码路径而导致的自身死锁**。

```c
struct spinlock lock;
int data = 0; // protected by lock
f() {
  acquire(&lock);
  if(data == 0){
    call_once();
    h();
    data = 1;
  }
  release(&lock);
}
g() {
  aquire(&lock);
  if(data == 0){
    call_once();
    data = 1;
  }
  release(&lock);
}
h() {
  ...
}
```

*   **可重入锁的隐患（示例分析）：**
    *   通过 `f()`, `g()`, `h()` 的代码示例，说明了可重入锁如何破坏程序员关于临界区原子性的直觉。
    *   **关键期望：** 锁应保证 `call_once()` **只被调用一次**（要么在`f()`的临界区内，要么在`g()`的临界区内）。
    *   **可重入锁的问题：** 如果 `h()` 调用了 `g()`，并且锁是可重入的：
        *   `f()` 获取锁，进入临界区。
        *   `f()` 调用 `h()`。
        *   `h()` 调用 `g()`。
        *   `g()` 成功获取同一个锁（因为可重入），进入 `g()` 的临界区。
        *   `g()` 发现 `data == 0`（因为 `f()` 的 `data = 1` 还未执行），于是调用了 `call_once()`。
        *   `g()` 释放锁，返回到 `h()`，再返回到 `f()`。
        *   `f()` 继续执行 `data = 1`，完成临界区。
        *   **结果：`call_once()` 被调用了两次！** 违反了程序员的意图和临界区的原子性假设。
*   **对比非可重入锁：**
    *   在 xv6（非可重入锁）中，如果 `h()` 调用 `g()`：
        *   `g()` 尝试获取已被当前线程（`f()`）持有的锁时，会导致 **`panic` (死锁或断言失败)**。
    *   **死锁 vs 错误逻辑：** `panic` 虽然也不理想（导致系统崩溃），但它**强制暴露了潜在的设计错误**。开发人员会立即注意到并修复代码（例如，确保 `h()` 不会调用 `g()`，或重构锁的使用）。相比之下，可重入锁掩盖的错误（`call_once()`调用两次）是**静默的、难以追踪的**。
*   **xv6 的设计选择：**
    *   选择**非可重入锁**，因为其更**简单直观**（临界区在持有锁期间对其他所有代码都是原子的），并**强制暴露锁的使用错误**（如不安全的嵌套调用）。
    *   开发者遵守锁的规则是关键。如果严格遵守规则，两种锁都可以工作。
*   **实现可重入锁的代价（如果 xv6 使用）：**
    *   需要在 `acquire` 中检查当前线程是否已持有该锁。
    *   需要在 `struct spinlock` 中添加一个**引用计数**（或类似 `push_off` 中断嵌套机制的结构）来跟踪嵌套深度。
    *   增加了实现的复杂性。

**要点总结：**

1.  **可重入锁（递归锁）：**
    *   **特性：** 允许**持有锁的同一个线程再次成功获取同一个锁**。
    *   **表面优势：** 可避免**自身线程尝试重入导致的死锁**（如锁保护的函数间接调用自身）。
2.  **非可重入锁：**
    *   **特性：** 禁止同一个线程重复获取同一个锁，重复尝试会导致**失败或 `panic`** (如 xv6)。
    *   **核心价值：** **无条件确保临界区的原子性和隔离性**。无论调用路径如何嵌套，一个锁保护的关键代码段不会与自身或相同锁保护的其他代码段**并发执行**。
3.  **可重入锁的核心问题：**
    *   **破坏原子性直觉：** 如示例所示，可重入锁允许在同一个线程内**嵌套进入相同锁保护的临界区**，导致该锁保护的**关键逻辑（如函数 `call_once()`）可能被意外执行多次**。
    *   **错误难以调试：** 这种由锁逻辑失效导致的错误是**静默发生的**，不引发程序停止，追溯根源非常困难。
4.  **非可重入锁的优势（xv6的选择）：**
    *   **简单性与可预测性：** 概念简单，行为明确（临界区严格隔离）。
    *   **强制暴露设计错误：** 锁的错误使用（如可能导致循环调用的不安全的嵌套锁获取）会通过**死锁或 `panic` 立即暴露**，迫使开发者修复底层设计问题。
    *   **避免静默错误：** 比静默的逻辑错误（如多次执行 `call_once()`）更容易诊断和处理。
5.  **死锁 vs 逻辑错误的权衡：**
    *   **非可重入锁的风险：** `panic`/死锁（崩溃，可发现）。
    *   **可重入锁的风险：** 静默的逻辑错误（数据破坏，难以诊断）。
    *   **xv6 的观点：** 前者（强制暴露错误）是**更可取的代价**。
6.  **实现考量：**
    *   实现可重入锁需要在锁结构中维护**持有线程标识**和**嵌套计数器**。
    *   非可重入锁的实现更简单（如 xv6 的实现）。

## 6.6 Locks and interrupt handlers

本节探讨了锁（特别是自旋锁）与**中断处理程序（Interrupt Handlers）** 交互时引发的**潜在死锁风险**，以及 **xv6 采用的解决方案：在持有锁时关闭本地 CPU 中断**。核心在于解释如何防止中断处理程序试图获取已被当前 CPU 持有的锁而导致系统冻结。

*   **共享数据问题：** 某些锁保护的数据可能被**内核线程**和**中断处理程序**同时访问（例如 `ticks` 计数器被 `sys_sleep` 读取和被 `clockintr` 更新）。
*   **中断引发的致命死锁场景：**
    1.  CPU 在某个内核线程中持有一把锁 (例如 `sys_sleep` 持有 `tickslock`)。
    2.  **该 CPU 被一个中断打断**（例如定时器中断，触发 `clockintr`）。
    3.  中断处理程序 (`clockintr`) **尝试获取同一把锁** (`tickslock`)。
    4.  中断处理程序发现锁已被持有，**开始自旋等待**。
    5.  **结果：**
        *   中断处理程序在等待锁释放，**无法返回**。
        *   持有锁的内核线程 (`sys_sleep`) 被中断打断，**无法继续执行**，也就**永远无法释放锁**。
        *   **该 CPU 完全死锁（Deadlock），系统冻结。**
*   **xv6 的核心防御策略：持锁关中断：**
    *   **规则：** 如果一个自旋锁**可能被中断处理程序使用**，那么在**持有该锁期间，其所在的 CPU 上必须禁用中断**。
    *   **xv6 的更保守策略：** 只要 CPU **获取了 *任何* 锁（无论是否会被中断处理程序访问），xv6 就立即禁用该 CPU 上的中断。**
    *   **理由：** 这保证了在当前 CPU 上执行时，持有锁的过程中**绝不会被中断打断**，从而避免了上述死锁场景。
        *   注意：**其他 CPU 上的中断依然可能发生**，其他 CPU 上的中断处理程序尝试获取锁时，如果锁被占用（可能在另一个 CPU 的线程手里），它们会**正常等待（自旋）**，不会造成跨 CPU 死锁。
*   **嵌套锁（Nested Critical Sections）的处理：`push_off` 与 `pop_off`：**
    *   **问题：** 内核代码路径可能需要嵌套持有多个锁，简单粗暴地开/关中断不可行。
    *   **计数机制：** xv6 通过 `push_off` 和 `pop_off` 维护一个**中断禁用嵌套深度计数器** (`intena` 或类似状态)。
        *   **`acquire` 调用 `push_off`：**
            *   记录*当前*的中断状态（是否开启）。
            *   然后**禁用中断**。
            *   **增加中断禁用深度计数（嵌套层数）。**
        *   **`release` 调用 `pop_off`：**
            *   **减少中断禁用深度计数。**
            *   如果计数减到 **0** (意味着这是最外层锁被释放)，则**根据记录的原状态恢复中断**（开或关）。
*   **关键时序要求：**
    *   **`acquire` 顺序至关重要：** **必须先调用 `push_off` (禁用中断)，再设置 `lk->locked = 1` (标记锁被持有)。**
        *   如果顺序反了：在 `lk->locked=1` 之后、`push_off()` 之前这个短暂窗口期，**锁已被标记持有但中断仍开启**。若此时发生中断，中断处理程序尝试获取该锁会导致上述死锁。
    *   **`release` 顺序也至关重要：** **必须先设置 `lk->locked = 0` (释放锁)，再调用 `pop_off` (可能恢复中断)。**
        *   如果顺序反了：在 `pop_off` (可能开中断) 之后、`lk->locked=0` 之前这个窗口期，**中断已开启但锁仍被标记持有**。其他 CPU 或中断处理程序看到锁仍被占用，会继续不必要地等待/自旋。

**要点总结：**

```c
void
push_off(void)
{
  int old = intr_get();

  intr_off();
  if(mycpu()->noff == 0)
    mycpu()->intena = old;
  mycpu()->noff += 1;
}

void
pop_off(void)
{
  struct cpu *c = mycpu();
  if(intr_get())
    panic("pop_off - interruptible");
  if(c->noff < 1)
    panic("pop_off");
  c->noff -= 1;
  if(c->noff == 0 && c->intena)
    intr_on();
}
```

1.  **核心冲突：锁与中断的死锁风险：**
    *   当前 **CPU 持锁** 时，若发生本地中断，且**中断处理程序试图获取同一把锁**，会导致该 CPU **永久死锁**：中断处理程序等锁释放才能返回，锁持有者（被中断线程）等中断返回才能释放锁。
2.  **xv6 的解决之道：持锁关本地中断：**
    *   严格规定：**获取任何锁时，都必须先禁用当前 CPU 的中断。** 这是 xv6 保守但安全的选择。
    *   **目标：确保在执行持有锁的代码（临界区）时，当前 CPU 不会被本地中断打断。** 彻底避免中断处理程序在本 CPU 上尝试获取已持有锁的情况。
    *   其他 CPU 的中断不受影响，它们尝试获取锁时正常自旋等待。
3.  **嵌套锁场景：`push_off`/`pop_off` 机制：**
    *   函数 `acquire` 调用 `push_off`：**保存当前中断状态、禁用中断、增加嵌套计数。**
    *   函数 `release` 调用 `pop_off`：**减少嵌套计数；当计数归零时，恢复保存的中断状态。**
    *   这确保了**只有最外层锁释放时才真正恢复中断状态**，正确处理了嵌套锁的情况（如函数A持锁调用函数B，函数B也持锁）。
4.  **关键操作的严格顺序 (Essential Ordering)：**
    *   **获取锁 (`acquire`):**
        *   **1. `push_off()` (关中断, 记录状态, 增加计数)**
        *   **2. 设置 `lk->locked = 1` (标记锁被持有)**
    *   **释放锁 (`release`):**
        *   **1. 设置 `lk->locked = 0` (释放锁)**
        *   **2. `pop_off()` (减少计数, 若到0则恢复中断)**
    *   **违反这些顺序会产生短暂的脆弱窗口期，可能引发死锁或不必要的阻塞。**
5.  **硬件支持：** `intr_off` 和 `intr_on` 函数使用 **RISC-V 指令** 实际执行中断的禁用和启用操作。

## 6.7 Instruction and memory ordering

本节揭示了程序执行中一个隐蔽但关键的问题：**源代码编写的顺序（Program Order）并不总是等价于最终执行的指令顺序（Execution Order）**。这种差异在单线程程序中通常无害，但在多线程通过共享内存交互时，会导致灾难性的后果。原因在于**编译器的优化**和**处理器的乱序执行 (Out-of-Order Execution)** 都可能改变指令的顺序。xv6 使用 **内存屏障（Memory Barrier）** 来解决这个问题。

*   **核心问题：顺序错觉的破灭**
    *   开发者直觉：代码按源码顺序执行（单线程思维）。
    *   **多线程/共享内存现实：** 源码顺序 != 实际执行顺序。
*   **指令重排的来源：**
    1.  **编译器重排：** 编译器为了优化性能，**可能改变加载（`Load`）/存储（`Store`）指令的顺序**，甚至将值缓存在寄存器而省略内存访问。
    2.  **处理器乱序执行 (OoO)：** 处理器为了提升性能，**可能提前执行那些输入已准备好且互不依赖的指令（如指令B在A之前执行）**，或者重叠执行多条指令。
*   **重排导致的并发错误（示例）：**
    *   沿用之前的 `push` 函数代码。
    *   **灾难性重排：** 如果将 `l->next = list` (第4行) 的**存储操作**，重排到 `release(&listlock)` (第6行) **之后**执行。
    *   **后果：** 在 `release` 之后、`l->next` 写入之前的**窗口期**：
        *   另一个 CPU 可以**获取锁 (`acquire`)**
        *   然后**看到 `list` 已经被更新为 `l`** (因为 `list = l` *可能* 已执行)。
        *   但 **`l->next` 却未被初始化（仍为垃圾值或旧值）**。
        *   导致另一个 CPU **访问到损坏的链表结构**。
*   **解决方案：内存屏障 (Memory Barrier)**
    *   **硬件和编译器的承诺：** 它们遵循一个标准（**内存模型 - Memory Model**），并提供**原语**帮助开发者控制重排。
    *   **`__sync_synchronize()`：** xv6 使用的内存屏障原语。
        *   **作用：** 阻止编译器**跨越屏障**对前后的加载/存储进行重排。告知 CPU **屏障前的操作必须在屏障后操作可见之前完成**（限制硬件重排和保证可见性）。
    *   **xv6 的实现：** 在 `acquire` 和 `release` 函数的**关键位置**插入 `__sync_synchronize()` 屏障。
        *   **`acquire` 屏障 (在获得锁之后)：** 确保任何**临界区内的加载/存储操作不会被重排到获取锁 *之前***。
        *   **`release` 屏障 (在释放锁之前)：** 确保任何**临界区内的加载/存储操作不会被重排到释放锁 *之后***。
*   **结合锁机制的有效性：**
    *   通过在锁操作（`acquire`/`release`）中使用屏障，并围绕共享数据的访问加锁，xv6 确保了 **临界区内的操作作为一个整体相对外界是原子的、顺序一致的**。这解决了绝大部分因重排导致的并发问题（第 9 章会讨论少数例外）。

**要点总结：**

1.  **核心挑战：指令重排（Reordering）：**
    *   **来源：** **编译器优化** 和 **CPU 乱序执行 (OoO)** 都会导致指令执行**不按源码顺序**。
    *   **危害范围：** 在多线程通过**共享内存**交互时，这种重排可能导致**严重的、难以复现的并发错误**。
2.  **危害实例：**
    *   在 `push` 操作中，若存储 `l->next` 被重排到 `release` **之后**，会造成其他 CPU **在持有锁的情况下观察到链表处于半初始化（损坏）状态**。
3.  **解决方案：内存屏障（Memory Barrier / Fence）：**
    *   **机制：** 使用屏障原语（如 `__sync_synchronize()`）**强制约束编译器和 CPU 的重排行为**。
    *   **功能：**
        *   **编译时：** 阻止编译器**跨越屏障**对内存访问指令进行重排。
        *   **运行时：** 阻止 CPU **跨越屏障**对内存访问指令进行重排（限制硬件乱序），并**确保屏障前所有内存操作的全局可见性**发生在屏障后的内存操作可见性之前。
4.  **xv6 屏障的放置：**
    *   **`acquire` 屏障（加锁后）：** 位于获取锁的操作（如 `__sync_lock_test_and_set`）**之后**，**临界区代码之前**。**确保临界区内的代码不会被“拉”到加锁操作之前执行。**
    *   **`release` 屏障（释放锁前）：** 位于**临界区代码之后**，释放锁的操作（如 `__sync_lock_release`）**之前**。**确保临界区内的代码不会被“推”到释放锁操作之后执行。**
5.  **屏障与锁的协同作用：**
    *   在 `acquire` 和 `release` **内部**结合使用内存屏障，xv6 有效地**将临界区包围起来**。
    *   这保证了从一个持有锁的 CPU 外部视角来看：
        *   在 `acquire` 成功返回前，**该 CPU 进入临界区前对共享内存的所有必要状态读取（获取锁本身也是状态）均已完成且可见。**
        *   在 `release` 调用后，**该 CPU 在临界区内对共享内存的所有修改都已完成且对其他 CPU 可见。**
    *   简而言之：**锁屏障确保临界区内的操作作为一个整体，在锁持有期间“原子地”执行并完成，对外部（其他CPU）而言，状态要么是锁持有前的，要么是锁持有后完全更新完成的**，消除了重排导致的中间状态可见性问题。
6.  **应对绝大多数场景：** 这种在锁操作中加入屏障的方式，结合正确的锁使用（保护所有共享数据访问），足以处理 xv6 中大部分的并发正确性问题（虽然存在极少数特殊情况需额外处理，见第9章）。

## 6.8 Sleep locks

```c
void
acquiresleep(struct sleeplock *lk)
{
  acquire(&lk->lk);
  while (lk->locked) {
    sleep(lk, &lk->lk);
  }
  lk->locked = 1;
  lk->pid = myproc()->pid;
  release(&lk->lk);
}

void
releasesleep(struct sleeplock *lk)
{
  acquire(&lk->lk);
  lk->locked = 0;
  lk->pid = 0;
  wakeup(lk);
  release(&lk->lk);
}
```

本节分析了自旋锁（Spinlocks）在处理**长时间操作时的局限性**，并引入**睡眠锁（Sleep-locks）** 作为解决方案：
1. **自旋锁的瓶颈**  
   当操作涉及**磁盘读写（耗时约数十毫秒）** 时，长期持有自旋锁会导致：
   - **CPU资源浪费**：其他进程需自旋等待（`spinning`），持续占用CPU却无实际进展。
   - **禁止让出CPU**：持有自旋锁时禁止进程让出CPU（`yield`），因其要求禁用中断（避免死锁），且若让出CPU可能导致锁无法释放。

2. **睡眠锁的设计动因**  
   为解决上述问题，xv6提供睡眠锁：
   - **主动让出CPU**：在等待锁时调用 `sleep` 让出CPU，释放自旋锁供他人使用。
   - **允许中断和让出**：持有睡眠锁期间**不关闭中断**，允许响应中断或主动让出CPU（适合长操作）。
   - **结构特征**：通过自旋锁保护 `locked` 状态字段，结合 `sleep` 机制实现安全等待。

3. **使用限制与场景对比**  
   - **禁用场景**：
     - ❌ **中断处理程序**（因睡眠锁不关中断，无法用于原子性要求高的中断上下文）。
     - ❌ **自旋锁临界区内**（睡眠锁可能让出CPU，违反自旋锁的原子性和禁用中断要求）。
   - **适用场景**：
     - ✅ **短临界区**：优先用自旋锁（避免进程切换开销）。
     - ✅ **长操作**（如磁盘IO）：睡眠锁更优（减少CPU浪费，允许并发）。

---

### **要点总结**
| **锁类型** | **适用场景**       | **核心机制**                      | **优点**                      | **缺点**                                      |
|------------|--------------------|-----------------------------------|-------------------------------|---------------------------------------------|
| **自旋锁** | 短临界区（微秒级） | 忙等待（`spinning`）+ 禁用中断    | 低延迟，无上下文切换          | 长期持有会浪费CPU，禁止让出CPU和响应中断       |
| **睡眠锁** | 长操作（毫秒级）   | `sleep` 让出CPU + 自旋锁保状态   | 允许让出CPU和响应中断，减少浪费 | 不可用于中断上下文；需避免嵌套在自旋锁临界区内 |

1. **睡眠锁实现关键**  
   - 内部通过**自旋锁**保护 `locked` 字段，确保状态修改的原子性。
   - 调用 `sleep` 时**原子性让出CPU并释放自旋锁**，避免竞争（详见第7章 `sleep/wakeup` 机制）。

2. **锁嵌套规则**  
   - **允许**：自旋锁嵌套在睡眠锁临界区内（自旋锁仍保证原子性）。
   - **禁止**：睡眠锁嵌套在自旋锁临界区内（违反自旋锁禁用中断和禁止让出的原则）。

3. **性能权衡**  
   - **自旋锁**：短操作更高效（无切换代价，但忙等待浪费CPU）。
   - **睡眠锁**：长操作提升系统吞吐量（允许CPU执行其他任务）。

> **关键设计思想**：睡眠锁通过牺牲原子性（允许中断和让出CPU），换取长时间操作下的系统并发性与资源利用率。它是xv6在**磁盘IO**等场景下避免自旋锁浪费的核心方案。